arX1v:2510.25626v1 [cs.CL] 29 Oct 2025

Are Language Models Efficient Reasoners?
A Perspective from Logic Programming

Andreas Opedal™:** Yanick Zengaffinen® Haruki Shirakami”> Clemente Pasti®
Mrinmaya Sachan® Abulhair Saparov’ Ryan Cotterell’ Bernhard Schélkopf®”
“ETH Ziirich °MPI for Intelligent Systems, Tiibingen
YEPFL °Idiap Research Institute ‘Purdue University

Abstract

Modern language models (LMs) exhibit strong deductive reasoning capabilities,
yet standard evaluations emphasize correctness while overlooking a key aspect
of human-like reasoning: efficiency. In real-world reasoning scenarios, much of
the available information is irrelevant, and effective deductive inference requires
identifying and ignoring such distractions. We propose a framework for assessing
LM reasoning efficiency through the lens of logic programming, introducing a
simple method to align proofs written in natural language—as generated by an
LM—vwith shortest proofs found by executing the logic program. Efficiency is
quantified by measuring how well a model avoids unnecessary inference. Empiri-
cally, we construct a dataset of math word problems injected with various number
of irrelevant axioms that vary in semantic overlap with the goal theorem. We find
that current LMs show marked accuracy declines under such conditions—even with
minimal, domain-consistent distractions—and the proofs they generate frequently
exhibit detours through irrelevant inferences.”

1 Introduction

Large language models (LMs) appear capable of solving a wide range of tasks that rely on deduc-
tive reasoning, particularly when post-trained with reinforcement learning (Lightman et al., 2024;
DeepSeek-AI, 2025) and scaled to use more compute at test time (Wang et al., 2024; Muennighoff
et al., 2025; Snell et al., 2025). However, emerging findings suggest recent reasoning models often gen-
erate more tokens than necessary to solve problems, even for simple deductive tasks (Chen et al., 2025;
Pu etal., 2025). Such findings point towards a key dimension of deductive reasoning that standard eval-
uations of LMs’ reasoning abilities fail to systematically assess—efficiency. Indeed, more abstractly,
in most real-world reasoning tasks, more information is available than is necessary to solve the prob-
lem. This spurious information is not random: it often interacts with relevant information, enabling
the derivation of true but irrelevant conclusions. Crucially, it is unknown a priori which pieces of in-
formation will be relevant for determining whether a desired conclusion is supported by the evidence.
An efficient solution to a problem uses only necessary information and takes as few steps as possible.

To characterize efficiency, we adopt a formalization of deductive reasoning based on logic
programming (Kowalski, 1974). Our perspective is that logic programming provides a clean and
flexible framework for reasoning within a well-understood proof system. Given a logic program—that
is, a set of inference rules and axioms—a proof of some goal theorem can be viewed as a path in
a hypergraph induced by the inference rules, starting from vertices corresponding to axioms and
terminating at a vertex corresponding to the goal theorem. Then, the most efficient proof is simply
a shortest such path. Using this machinery, the goal of this paper is to evaluate a language model’s
reasoning efficiency. Thus, we require an additional mechanism to bridge the gap between reasoning

“Please direct correspondence to andreas. opedal@inf.ethz.ch, ryan.cotterell@inf.ethz.ch, and
asaparov@purdue. edu.
Code for this project is available at https: //github.com/rycolab/reasoning-efficiency.

39th Conference on Neural Information Processing Systems (NeurIPS 2025).


===== PAGE BREAK =====

in logic programming and reasoning in natural language. To this end, we introduce the notion of
a verbalized logic program, in which each theorem in the logic program is associated with a set of
natural language strings. Verbalized logic programs allow us to map the deductions performed by
an LM—expressed as a natural language proof—onto deductions performed during the execution
of a logic program. While numerous recent papers use number of generated tokens as a proxy for
efficiency (Arora & Zanette, 2025; Han et al., 2025; Ma et al., 2025), doing so conflates inefficiency
stemming from two separate sources: (1) unnecessary deduction steps and (2) verbosity in the natural
language strings expressing those deduction steps. In contrast, our framework disentangles these
two factors, with our paper’s experiments emphasizing the former.

Empirically, we construct verbalized logic programs for grade school math word problems (GSM
problems; Cobbe et al., 2021; Li et al., 2024; Zhang et al., 2024), adopting methods from Opedal et al.
(2025). Our primary experimental manipulative is the injection of irrelevant axioms into these GSM
programs, which yields many possible implications that are irrelevant to a goal theorem of interest. We
experiment on problems that vary both in how much the information in the irrelevant axioms overlap
with the goal theorem, as well as in how many such axioms are injected, generalizing existing datasets
that only include a single irrelevant axiom (Shi et al., 2023; Mirzadeh et al., 2025). We first measure
accuracy, showing that current LMs are less accurate on problems containing irrelevant axioms than
on equivalent problems without them. This performance gap often persists even in the simplest
cases, where a single irrelevant axiom from the same domain is introduced, and grows larger as more
irrelevant axioms are added. We confirm that this reduction in accuracy is not due to longer inputs
alone: LMs usually perform better on control problems of equal length but without irrelevant content.

Next, we map the reasoning performed by the LM onto theorems they correspond to when executing
the logic program. We find that while the LMs predict most of the correct intermediate theorems for
the problems where they correctly generate the goal, they are often inefficient. In particular, for GSM
problems where about half of the axioms are irrelevant, about half of the model’s predicted theorems
are irrelevant too, i.e., not needed for proving the goal. The LMs are particularly inefficient when the ir-
relevant axioms overlap semantically with the query—for instance, when the question asks “how many
cats does Ryan have?” and the irrelevant axioms also mention “Ryan” or “cats”. On the other hand,
these results also suggest that the LMs’ search procedure sometimes employ a useful heuristic based on
such overlap. Our results shed some light on how LMs, albeit in natural language, perform inference.

Outline. The remainder of the paper is structured as follows: §2 situates our contributions among
related work. §3 provides relevant background on logic programming and discusses how reasoning
efficiency is measured relative to shortest proofs. §4 introduces verbalized logic programs and the
specifics of our GSM programs. §5 presents experiments and results on how LMs reason on verbalized
GSM programs with irrelevant axioms. Apps. A-D give further technical details and empirical results.

2 Related Work

Evaluating Reasoning. Most studies and benchmarks on LM reasoning evaluate correctness based
on the LM’s final answer (Hendrycks et al., 2021; Patel et al., 2021; Rein et al., 2024; Yu et al., 2024,
inter alia). However, correctness of the final answer does not guarantee correctness of the proof (Lyu
et al., 2023; Turpin et al., 2023). Some studies include more fine-grained reasoning evaluations by
verifying LM-generated proofs (Gontier et al., 2020; Frieder et al., 2023; Nguyen et al., 2024; Wang
et al., 2024; Petrov et al., 2025). While useful, many such evaluations rely either on manual scrutiny or
heuristic measures of the proof’s correctness. An alternative approach is to use proof assistants, e.g.,
Lean (de Moura & Ullrich, 2021), for formal verification (First et al., 2023; Tsoukalas et al., 2024);
however, LMs may have been trained on less amounts of such data as compared to natural language.
We perform an automatic evaluation by parsing the LM-generated output into proofs in logic programs.

Irrelevant Information in Reasoning Tasks. Our work relates to papers that evaluate LMs’ ability
to correctly solve problems with irrelevant information (or missing information; Li et al., 2025). Shi
et al. (2023) create such a dataset by appending a single irrelevant statement to problems taken from
GSM8k (Cobbe et al., 2021). Mirzadeh et al. (2025) seem to take a similar, albeit more manual ap-
proach; however, details presented are scarce and their dataset has not yet been made publicly available.
Anantheswaran et al. (2025) use a prompting-based method for augmenting problems with several ir-
relevant statements. We formalize the notion of irrelevance through logic programming and generalize
these previous approaches by generating problems that may have several, arbitrarily placed irrelevant
axioms, which can be used together in further inference. Thus, there are many implications that are ir-
relevant to the goal theorem and the challenge becomes not only to generate correct proofs, but proofs


===== PAGE BREAK =====

that only contain steps that are necessary. By generating new problems from scratch, our approach
avoids bias from memorizing the efficient solution seen during training (see, e.g., Zhang et al., 2024).

Search and Efficiency. Other studies have investigated whether and how transformers can learn
search tasks (Gandhi et al., 2023, 2024; Kazemi et al., 2023; Lehnert et al., 2024; Sanford et al.,
2024; Sel et al., 2024; Shah et al., 2024; Saparov et al., 2025). We are interested not only in whether
a transformer-based LM can perform accurate search, but in how efficient it is. Efficiency of large
(reasoning-based) LMs is a rapidly growing area of research (Sui et al., 2025), due to their often lavish
use of compute (Chen et al., 2025; Pu et al., 2025). Several methods have been proposed to make
reasoning more efficient (Han et al., 2025; Ma et al., 2025), e.g., by incorporating length rewards in
training (Arora & Zanette, 2025; Luo et al., 2025; Team et al., 2025). While these papers focus solely
on the number of tokens, we argue that it is more informative to measure efficiency based on the
natural language proof, since a long output can be explained either by unnecessary inference steps or
by “verbose” verbalizations of the proof. Moreover, an LM should avoid generating redundant tokens
(Xia et al., 2025), but it should also not skip necessary inference steps in favor of a shorter output.

3 Logic Programming and Deductive Reasoning

This section provides relevant background on logic programming (Kowalski, 1974). It also introduces
the metric we propose for scoring a proof’s efficiency in §3.2.

3.1 Typed Logic Programs with Built-ins

Basic Notions. A signature is a 3-tuple © = (X,, Uz, Uy), where ¥), is a set of predicate (or
relation) symbols, denoted p,q,r,...; “, is a set of constants, denoted a, y, z,...; Uy is a set of
variables, denoted J, Y, Z, ...> Every predicate is associated with an arity, which we denote using the
function arity ar: &,, — N, specifying how many arguments it takes. Arguments to predicates are
called terms; they can be either constants (ground terms) or variables (non-ground terms). An
atomic formula, called an atom, for short, is an expression of the form p(t, ..., tv), where p € &,, is
a predicate symbol of arity ar(p) = N and ty, ...,t” € “_U Ny are all terms. The Herbrand base H
for signature © is the set of all atoms that can be formed by terms in %z,i.e., H = {p(ti,..,tnw) | p €
Dp, ar(p) = N, ti, ...,t~ € Uz}. Subsets of the Herbrand base J C H are called interpretations.

Logic Programming. An inference rule is an expression of the form bj,...,b) 4 h, where
by, ..., 6K, h are atoms; bj, ..., bx is the body of the rule and h is the head. For example,

parent(Z, Y), ancestor(Y, Z) F ancestor(Y, Z)

is an inference rule that allows us to conclude that if X is a parent of Y and Y is an ancestor of Z, then
X is an ancestor of Z. We call by, ..., bx, i.e., parent(X, Y) and ancestor(Y, Z) in the example above,
the premises and h, i.e., ancestor(Z, Z) in the example above, the conclusion. An inference rule
is called range restricted if each variable appearing in the conclusion h also appears in at least one
atom b,, in the premise. For example, p(X) | q(J) is range restricted, while p(X) F q(J, Y) is not. In
this paper, we require all inference rules to be range restricted.’ Inference rules with a null premise,
i.e., where kK = 0, and a ground conclusion, i.e., where h € H, are called axioms. A set of axioms
is denoted A. For example, | parent(abrahkam, isaac) or, also written parent(abraham, isaac),
omitting the F symbol, is an axiom. A logic program ? over a signature © is a set of inference
rules in which all atoms are formed by symbols in ©. The following is an example logic program,
adapted from Sterling & Shapiro (1994, §5):

parent(terah, abraham)        parent(abraham, ishmael)        parent (abraham, isaac)

parent(Z, Y) F ancestor(Y, Y)     parent(Z, Y), ancestor(Y, Z) + ancestor(Y, 2)

+Many logic programming languages, e.g., Prolog (Colmerauer & Roussel, 1993; Kérner et al., 2022),
additionally have the notion of a function. Constants are then just nullary functions. Our notion of logic
programming is most similar to Datalog (Vardi, 1982; Maier et al., 1984; Ceri et al., 1989), which does not.

“In the case that the signature additionally contains a set of function symbols © yf» the Herbrand base is
defined as the set of all atoms that can be formed by all terms in the Herbrand universe, which is the smallest
set U that satisfies the equation U = 2 U {f(ti,...,tw) | f € Sy, ar(f) = N,t1,...,t~ € US.

Range restriction ensures that applying the fixpoint operator (Eq. (1)) does not create non-ground atoms.


===== PAGE BREAK =====

Types and Built-ins. Our notion of logic programming additionally includes types (Abiteboul et al.,
1995, §21.1) and built-ins (Kaminski et al., 2017), which we define here. We partition ©, and / into
T disjoint subsets, i.e., 4, = a Joes | jor and iy = oH Jeol IOt, respectively, and associate each
subset with a type. These subsets are paired index-wise, i.e., (©1, 5+), ..., (©27, U7), ensuring that the
constant and variable types match. In this paper, we consider three types: (i) natural numbers, denoted
(N,, N,), Gi) strings, (A*, A*), and (iii) sets of strings, (2° , 2°). Our introduction of types is neces-
sitated by our desire to add additional power to our notion of logic programming that is external to the
language itself. Specifically, we will introduce built-in predicates, simply called built-ins through the
exposition, that add various arithmetic and set-theoretic operations. We enumerate these operations:

X7+Y¥z=Zz             (Integer Addition),        Xgar U Yoar = Zoe                               (Set Union),
Xz— Y2=Zz,         (Integer Subtraction),        Xgar 1 Yoga = Zoax                      (Set Intersection),
XzX Yz=Zz, (Integer Multiplication),        |Xgax |=Xz,                                 (Set Cardinality),
Xz=Yz                    (Integer Equality),        Xgax = Voax                                    (Set Equality),
Xz> Vz              (Integer Comparison),        |Xoax |>Xz,             (Set Cardinality Comparison).

The truth value of grounded atoms constructed from built-in predicates is evaluated externally
to the logic program. To do so, we define the built-in evaluator eval: H — {T,F}, that maps
all ground built-ins that evaluate to true to T and all ground built-ins that evaluate to false to F.
Additionally, any element of H that is not a built-in evaluates to F. For example, eval(5+4=9) = T,
eval(5+4=10) = F, and eval(parent(abraham, isaac)) = F. For example, to illustrate the use of
built-ins in a logic program, we can extend the inference rules from the earlier example to measure
the depth of the ancestor relation (e.g., parent, grandparent, great-grandparent, etc):

parent(Xa*, Vax) F ancestor(Xa«, Yas, 1)
parent(Xa*, Ya«), ancestor(Ya», Za», Xz), Xz+1=YVz + ancestor(Xa+, Za«, Yz)

Substitutions and Semantics. To assign semantics to a logic program, we require a bit
more machinery. A substitution 0 is a finite set of pairs {(%m,tm)}M_,, where %m € Dy,
tm € UgU Dy, Xm # Xm: for all m 4 m’, and X,, ~ ty, for all m (Sterling & Shapiro, 1994, p. 14).
Additionally, a typed substitution is a substitution where, if X,, © vk, then t,, € bk U ve. We
can apply a substitution 6 to an atom b, denoted b/6, e.g., parent(X, tsaac)/{(X, abraham)} =
parent(abraham, isaac). Let O(P) be the set of all typed substitutions under P. We say that

‘,--,0% - h’ is an instantiation of 1, ..,b«% | A if there exists a substitution 0 ¢ O(P) such
that bi, ..., 0 Fh’ = b1/0,...,6« /0  h/@. If an instantiation has no variables, we call it a ground
instantiation. In addition, we say that an atom b unifies with b’ if 40 € O(P) : b/@ = b'/6. If b
unifies with b’ we write b = b'. We define a logic program P’s fixpoint operator Tp: 2% — 2” as

Tp(L) =U ({h/6 | (b1,.,bK Kh) © P, AK; (b,/0 € TV eval(b,/9)), 6 € O(P)}N HA), (1)

where J C 4H is an interpretation. The fixpoint operator Tp is inflationary, i.e., for every
interpretation J C H, we have b € I = > b © Tp(J), and monotone, i.e., for every pair of
interpretations [,, Iz C H, we have I, C Ig => Tp(I1) C Tp(I2). That Tp is monotone allows
us to employ least fixpoint semantics. To that end, we define the minimal Herbrand model as
M = T3(A) = Ur.9 T%(A), where T% denotes the n-fold application of the fixpoint operator
Tp, ie., M is Tp’s least fixpoint.® Thus, / is the subset of the Herbrand base that is true given the
axioms and inference rules in the program; we call elements of / theorems. Due to our inclusion
of built-ins that encompass basic arithmetic operations, it is undecidable to compute M (Dantsin
et al., 2001), i.e., in general, we cannot decide whether h € T3,(A) for an arbitrary h € H.

Queries. Given a logic program P, we are often interested in determining whether there exists a
theorem in ? that is an instantiation of a specific (possibly non-ground) atom. We refer to such atoms
as queries.’ For example, building on the running example drawn from Sterling & Shapiro (1994, $5),
we may wish to ask whether there exists a theorem that instantiates the atom ancestor(X, ishmael).

°Inflationarity is not needed to prove that the minimal Herbrand model M exists. Indeed, monotonicity
and the fact that interpretations of the Herbrand base form a complete lattice suffice to apply Tarski’s (1955)
theorem, which guarantees the existence of the least fixpoint. However, inflationarity does guarantee that, as
we iteratively apply Tp, convergence to the least fixpoint is monotone.

In principle, queries may also be ground; however, only the non-ground case is of theoretical interest here,
as it extends beyond what can be handled by the machinery introduced so far.


===== PAGE BREAK =====

cont ({d},3,apple,2)                                                   cont ({a,b,c},25,apple,2
“d has 3 apples”                                 cont ({a},8,apple,2)                                  “a,b, ond Bete hover Os
“a has 8 apples”

~s Goal theorem

cont ({b},8,apple,2)
“b has 8 apples”                                                           Query N

cont ({c},9,apple,2)
cont ({b},6,apple,1)                                             “c has 9 apples”           cont ({a,b,c} ,X,apple,2)

DUEBOCT HES                                                                                                                     “How many apples do a, b, and c have
transfer({b},{e},2,apple,1)                                                              together?

x   2  les to b”
SNe ES            Relevant Theorems

comp ({a}, {d},5,apple,2)
“a has 5 more apples than d”

Irrelevant Theorems

cont ({£},17,apple,2)                                     cont ({h},19,apple,2)
“€ has 17 apples”                       cont ({g}//14,apple,2)                     “h has 19 apples’                cont ({i},23,apple,2)
>          g has 14 apples         >                                                     “| has 23 apples”
comp ({£},{g},3,apple,2)         comp ({h},{g},5,apple,2)         cont ({i},19,apple,1)
“f has 3 more apples than g”                  “h has 5 more apples than g”                        i has 19 apples                           transfer ({i},{j},4,apple,1)

“j gave 4 apples to i”

Figure 1: Example of a proof P of a goal theorem for the logic program presented in Table 1, with a shortest
proof ‘* in blue and irrelevant theorems in red. We propose measuring efficiency as the size of the proof |P|
relative to the size of the shortest proof |*|, penalizing the LM’s proof for containing irrelevant theorems.
We have omitted built-in predicates from this diagram for brevity.

Answering such a query amounts to finding all substitutions for X that make the atom provable from P.
When J can take on infinitely many instantiations, more sophisticated inference mechanisms—most
notably, unification (Robinson, 1965)—are required to perform this kind of non-ground reasoning
effectively. In this paper, however, we restrict attention to queries in which each variable is known a
priori to range over a fixed, finite domain, which allows us to avoid additional complexities.

3.2 Deductive Reasoning

Hypergraphs. A hypergraph G (B-hypergraph; Gallo et al., 1993) is a tuple (V, FE), where V is
a set of vertices, and E C 2” x V isa set of hyperedges, where a hyperedge e = T’ — vp consists
of a tail T C V, with |T| > 0, and ahead vp, € V. We define the size of a hypergraph as |$| = |V|
where § = (V, £).° A subhypergraph of a hypergraph § = (V, £) is ahypergraph S’ = (V’, EB’)
where V’ C V and E’ C E. Given S C V and v € V, an (S,v)-hyperpath in a hypergraph
G = (V, £) isa finite sequence of distinct hyperedges T; — vp,,..., Ty > vp, such that v,, = v
and for every j € [J]: T; C SU {vn,,-, Un;_;}, Le., each hyperedge’s tail consists only of nodes
that are either in the source set S' or are heads of previous hyperedges in the sequence. A hyperpath
generalizes the notion of a directed path in a graph, but allows each hyperedge to have multiple tail
nodes that jointly produce a head node. Finding the shortest (5, v)-hyperpath in a hypergraph is
analogous to context-free parsing (Klein & Manning, 2001) and can be executed in polynomial time.

Proof Forests, Proofs and Proof Efficiency. Let P be a logic program. A proof forest (F, )
in P is a pair where ¥ = (F,V) is a hypergraph and ¢: V + H where H is P’s Herbrand
base (Heijltjes, 2010). Additionally, we require that, for every hyperedge e = {t1,...,tk} =
un © E, there exists a rule (b1,...,b% / h) € R and a substitution 9 € O(P) such that b)/0 =
€(t1),..., 0% /0 = l(tK) and h/@ = (up). We call a proof forest (F, 2) an (A, h,)-proof if there
exists a (€~1(A), 0-1(h,))-hyperpath in Hp.? In Fig. 1, we show an example of a proof in which
hg = cont(fa,b,c}, 25, apple, 2) in our custom logic program for math word problems (§4),
together with some axioms in the program that do not contribute to the proof of the goal theorem hg.
We call an (A, 2, )-proof a shortest proof if it has the least number of vertices of all (A, h, )-proofs in
P. A shortest proof can be found by forward-chaining, discussed in the subsequent paragraph. Now
we turn to measuring proof efficiency. Consider an (A, h,)-proof P in P. We define the efficiency of
P as EFFICIENCY (?) © |P*|/|P| where |P*| is the number of vertices in a shortest (A, hg)-proof. In
the remainder of the paper, we will refer to an axiom a as irrelevant if there does not exist a shortest
proof P that contains a vertex v such that ¢(v) = a.

5We note that this is non-standard; the size of a hypergraph is more often defined as its number of hyperedges
or the sum of the cardinalities of its hyperedges (Gallo et al., 1993). We use this definition to sync with the exper-
imental setup, which we explain in §5. Future work could easily adapt our efficiency metric to other definitions.

We note that the expression (A, h, )-hyperpath is a slight abuse of notation in the case that £ is not injective
adopted for convenience: A and h, are a subset and an element, respectively, of P’s Herbrand base—not of
Rp’s V. In this context, by A, we refer to a set X C €~'(A) where €(X) = A, and by hg we refer to a set
Y C €~"(hg) where &(Y) = hg.


===== PAGE BREAK =====

id Inference Rule

(la) cont(44, In, Eax, Ty), comp(By, 44, Yn, Eax, In), IN+ YN=2Zy + cont(BA, Zn, Eax, Ty)
(Ib) cont(B4, 2y, Eax, Ty), comp(B.4, 44, Yn, Eax, In). 2N> YN» 2N—YN=AN + cont(4,, An, Ex, Ty)
(Ie) cont(A 4, ty, Zax, Ty), cont(B4, My, Zax, Ty), NZIN, IN—IN=ZN F comp(By, 4.4; ZN; Ex, Ty)

(2a) cont(44, In, Eax, Ty), tramsfer(4,4, BA, Yn, Zax, TN), IN+YN=2N. TNt+1=Uy k cont(4y, Zy, Ear, UN)
(2b) cont(By, 2y, Eax, Ty), transfer(44, 24, Yn, Eax, Ty), 2N> In» 2N—YN=4N, INt+1=Uy + cont(By, In, Ear, UN)

8)   cont(4a,s ON, > Zax, In), comt(A a,» Ong» Zax, In), 4a, U +++ Ula, =8.4a, Ny +++ +4N, = In F cont(By, In, Zax, In)
for2<k<K

(4) cont(4y, In, Fax, Ty), rate(A a, Yn, Zax, Fax, Ty), INX IN=Zy F cont(4,, Zn, Fax, Ty)

(5a) cont(44, ty, Eax, Ty), comp(Dy, C4, Yn, Eax, Ty), compeq(4,4, 24, CA, D4, Eax, Ty), IN+¥N=2ZN | cont(By, 2y, Eax, Ty)
(5b) comp(8,4, 4.4, In, Zax, Ty), comp(D A, CA, Yn, Ea, TN), IN=¥N F compeq(4y, BA, CA, DA, Eax, TN)

(6)   p(4,, In, Eax, In), atransfer(44, B.A, ¥n, Eax, Ty), atransfer(B,4, 44, 2, Eax, Ty), INF-1 = UN p(4AA, IN, Ene, UN)
for p € {cont, comp, rate, compeq}

Table 1: Inference rules in Pw. The symbols cont, comp, transfer, rate, compeq are predicates and we use
variables 44, B4,C4,Ca € 24 for agents, Ea*, Fa» € Ey for entities, Xy, x, Zy € N? for quantities, and
Ty € N¢ for timestamps. We refer to Fig. 2 for ground instantiations of the atoms shown here with corresponding
example verbalizations. We note that Rule (6) is special since it has negation (§A.1); it is included to treat
complications resulting from the timestamp in Rules (2a) and (2b)—see footnote 10—and is not used when
generating shortest proofs for our experiments (§C).

Forward Chaining. Forward chaining (Hayes-Roth et al., 1983; Poole & Mackworth, 2017) is a
meta-strategy for theorem proving in logic programming that proceeds from the axioms toward the
goal theorem. The process terminates once the goal theorem is proved. Pseudocode for the forward-
chaining is given in Alg. | in §A.2. As a meta-strategy, each instance of forward chaining defines
an ordering over proof steps. Different orderings give rise to familiar search algorithms, such as
depth-first search (DFS; Tarjan, 1972), breadth-first search (BFS; Moore, 1959), Dijkstra’s algorithm
(Dijkstra, 1959), and heuristic-based search (Pearl, 1984) like A* (Hart et al., 1968). While DFS and
BFS ignore information about the goal theorem, such information can guide search more efficiently, as
exemplified by goal-aware strategies like Earley’s algorithm (Earley, 1970) for context-free parsing or
its more general equivalent in logic programming—magic templates (Bancilhon et al., 1986; Ramakr-
ishnan, 1991). In the spirit of using top-down information in proof search, in $5, we examine whether
LMs make use of lexical overlap with the goal theorem as part of their internal search heuristic.

4 Evaluating Language Models on Grade School Math Word Problems

We are interested in reasoning that takes places in natural language, particularly as performed by LMs.
To this end, we consider grade school math (GSM) word problems as empirical test domain. Such
problems are commonly used for training and evaluating LMs on reasoning tasks (Cobbe et al., 2021;
Patel et al., 2021). In §4.1, we introduce a family of logic programs, using the technical notions intro-
duced in §3, that correspond to a natural class of such math word problems. We also describe a simple
manner to convert text generated by an LM to a proof in such logic programs in $4.2. Finally, in §4.3
we explain how we generate problem descriptions in natural language that contain irrelevant axioms.

4.1 Modeling Math Word Problems with Verbalized Logic Programs

Logic Programming for Grade School Math Word Problems. We consider a particular family
of logic programs to represent GSM problems, adapted from Opedal et al. (2023, 2025). All
of the logic programs have the signature ©” = (U\’, 5,5’). The set of predicate symbols

aM = {cont, comp, transfer, rate, compeq} corresponds to arithmetic concepts that occur in GSM
word problems (Riley et al., 1983), e.g., cont for denoting how many entities an agent contains, comp
for comparing the number of entities across multiple agents, or transfer for expressing one agent
transfering entities to another. We partition DW = 24 £, UNZUN¢ and DW = 24U Ey UNZUNt
into the following pairs: sets of strings (24, 2+!) called sets of agents (who possesses), strings
(E,, Ex) called entities (what is possessed), natural numbers (N%, N?) called quantities (how much
is possessed), and natural numbers (N‘, N¢) called timestamps (time of possession). We note that 24
is a power set of the set of agent strings A,, which enables us to code a state where multiple agents
possess the same entity jointly. The family of logic programs all share the same inference rules, which
are given in Table 1. Fig. 1 shows an example proof using these inference rules, omitting built-ins.
We note that possession may change over time and is governed by the transfer predicate in Rule (2).!°

‘The time component requires the addition of Rule (6), which expresses that all theorems with time Ty that
are not affected by a proof step using Rule (2) maintain their truth value at Ty+1. This is an instance of the


===== PAGE BREAK =====

Axioms. The rules given in Table 1 are held constant across all logic programs in our family.
Indeed, what distinguishes one program from another, then, is the choice of axioms. For example,
consider the axiom cont( {ryan}, 5, cat, 2) which expresses that “Ryan has 5 cats at time step
2”; the predicate cont represents the semantics of possession, and {ryan} €  24,  5 € NY,
cat € E,, and 2 € N¢ are all ground atoms of different types. Additionally, we only consider
axiom sets Aw C H that have the following property: We call an interpretation J C H of a logic
program in our family (Table 1) numerically consistent if there do not exist two substitutions
6 = {(Ay, ta), (4z, t), (Eax, te), (Tn, te) } and O” = {(Ay, ta), (Xz, t’), (Ear, te), (Tn, te) } such that
t At and both cont(44, Xn, Zax, Ty) /O, cont(A,, An, Zax, Ty)/0’ € Th, (1). This ensures that
the minimal Herbrand model does not contain contradictory pairs such as cont( {ryan}, 5, cat, 2)
and cont({ryan}, 4, cat, 2). For example, the following set of axioms is numerically consistent:
Aw = {cont(fryan}, 5, cat, 2), comp(feleanor}, {ryan}, 3, cat, 2)}, expressing that “Ryan
has 5 cats” and that “Eleanor has 3 more cats than Ryan”. If we were to, e.g., include the two
axioms {cont( fandreas}, 7, cat, 2), comp(feleanor}, fandreas}, 3, cat, 2)}, we would obtain
a numerically inconsistent axiom set. Inference in our family of logic programs is decidable under
numerically consistent axiom sets. See §B for details.

4.2 Language Modeling and Proofs in Natural Language

Language Modeling. We give a brief formal introduction to language modeling. Let I’ be an
alphabet of tokens and I* be the set of all strings over I’, its Kleene closure. We write w € I*
for a string, w; for the token at the t" position in w = w; --+ wr, and |w| = T for the number
of tokens in w, i.e., its length. A language model (LM) p is a probability distribution on I*. Let
EOS ¢ [' be a distinguished symbol denoting the end of a token string. The probability of a string
w can be written autoregressively as p(w) = (EOS | w) Tr! P (w; | wer), where P(- | c) isa

probability distribution over T° “Tu {EOS} conditioned on the context c € I*.

Verbalized Logic Programs. To bridge reasoning in formal proof systems to rea-
soning in natural language, we introduce the idea of a verbalized logic program.
Given a logic program P with nega-

tion (§ A.1), let H be its extended  Grounded Atom              Verbalization

Herband base. We associate each cont({alice}, 3, apple, 1)       “Alice has 3 apples.”

iwi                                          cont({alice, bob}, 8, apple, 1)           “Alice and Bob have 8 apples combined.”
atom b € H with a set of natural lan-   comp({bob}, {alice}, 2, apple, 1) | “Bob has 2 more apples than Alice.”

guage strings. To that end, we define    transfer({alice}, {bob}, 2, apple, 1) “Bob gave 2 apples to Alice.”
1      . Oo     I“          t   lt  , 4, basket,   le, 1   “Each of Alice’s baskets contains 4  les.”
a verbalizer vp: H — 2", where   rate({alice}, 4, basket, apple, 1)      ‘ach of Alice’s baskets contains 4 apples.

:      coe                       342=5                              Not verbalized
each 1p(b) is a disjoint set. For every

b €  H, the set y p (b) represents the   of vpy (b) for some b € H. Built-ins are not verbalized other than
various ways In which the meaning of 4, part of the conclusion; §D.2 shows how this was done in our
b can be expressed in natural language.   prompt. We additionally note that time is not verbalized directly
In this paper, we take a straightfor- but implicitly through the use of a past form depending on context.
ward approach. For each b € H, we

construct a finite set G, C I*. Moreover, we enforce disjointness, ie., Gp, Gs, = 2 for b;, be € H,
and that, for all b € H, each string in G, ends in a distinguished separator symbol—in our case a
period “.”—that appears nowhere else in the string. These assumptions allow for trivial linear-time
parsing of natural language text into a sequence of atoms in the verbalized logic programs. In practice,
we generate the strings in each G,, with a series of hand-written templates. We give examples in Fig. 2.

Figure 2: Examples of verbalized grounded atoms, i.e., elements

4.3 Generating Problems with Irrelevant Axioms

Sampling Axiom Sets. We introduce a simple sampling algorithm, presented and analyzed in §C,
that samples a ground goal theorem h, = cont(4,, Xn, Ea, Ty) and a shortest proof of h, under
the rules Rw from Table 1. By construction, the axioms Aw in the shortest proof are numerically
consistent and all axioms in Aw will be used in the proof of h, in the program Pw = Rw U Aw;
we denote this dependency by Aw(h,).'' That is, Aw(h,) contains no irrelevant axioms. However,

frame problem (McCarthy & Hayes, 1969; Sandewall, 1972; Hanks & McDermott, 1987). To express this rule,
we introduce negation into the logic program; see §A.1 for background on negation in logic programming. The
only negated predicate in Table 1 is stransfer; because stransfer only appears in the body of an inference
tule, the program is trivially stratified (§A.1). That is stransfer atoms can not be proved true, but we assume
—transfer atoms if the corresponding transfer atom is not known to be true from the axioms.

"| Aw(hg) is the unique smallest set of axioms (Lemma 1) needed to prove hg, justifying the function notation.


===== PAGE BREAK =====

w/ Axiom                                  w/ Tree                            w/ Multiple Trees

Model         Base

Irrelevant             Control              Irrelevant             Control              Irrelevant             Control

Llama-3.1-     65.0        60.8        54.0        52.6        58.6        41.0        52.4
8B      —4.3,4.1) | (-2.2,2.1) (—4.4,4.3) | (—2.2,2.2) (—4.4,4.2) | (—2.2,2.2)  (—4.4, 4.3)

Qwen2.5-     52.8        43.4        48.4        35.6        40.2        23.5        30.6
Math-7B    —4.4,4.3) | (—2.2,2.2) (—4.4,4.4) | (—2.1,2.2) (—4.2,4.4) | (-1.8,1.9)  (—3.9, 4.2)

63.4        62.2        76.2        58.7        72.2        50.1        65.4

QwQ-32B

—4.3,4.1) | (-2.2,2.1) (—3.9,3.5) | (—2.2,2.1)  (—4.1,3.7) | (—2.2,2.2)  (—4.3, 4.0)

DeepSeek-           99.4                98.2                98.4                 98.0                98.6                97.6                98.6
R1       —1.1,0.4) | (-0.7,0.5) (—1.5,0.8) | (—1.1,0.9) (—0.8,0.6) | (-1.1,0.9)  (—1.5,0.7)

Table 2: Average answer accuracy (%) with 95% confidence interval (CI) for base problems augmented with
different degrees of irrelevance (one irrelevant axiom, one irrelevant tree, and multiple irrelevant trees; §4.3).
The control problems are of the same length as the corresponding problems that have irrelevant axioms, with
the difference being that all axioms are relevant. The CIs are Wilson (1927) score intervals. Note that adding
irrelevant axioms degrades performance across all models.

to produce logic programs that do contain irrelevant axioms, we do the following. We sample an
additional / distinct distractor theorems {Pim }M     —,- For each distractor theorem him, We again apply
our axiom sampling procedure to generate distractor axioms Am(h  m). Importantly, we are able to
show that Aw(h,) remain on a shortest proof of h, even in the case that we consider the augmented
logic program Pw = Rw U Aw(hg) U A, (hy) Ue u Am (hu); see §C.4.

Structural Overlap. In our experiments, we vary the size of the irrelevant axiom sets A = A, (hy yu

- LU Aqg (haz) as follows: (i) a single irrelevant axiom (w/ axiom), where M = 1, |A,(h1)| = 1,
and A,(h;) = {h1} (ie., the distractor theorem is trivial); (ii) a single irrelevant tree (w/ tree), where
M =1, |Ay (h1)| > 1, and hy has a non-trivial proof; (iii) multiple irrelevant trees (w/ multiple
trees), where M = 3, |Am(Am)| > 1 for all m, and hy, ho, hg all have non-trivial proofs.

Agent and Entity Overlap. We additionally control for overlap between the set of agents, i.e.,
elements of 24, and the entities, i.e., elements of Ez, of the goal theorem hy = cont(44, Xn, Zax, Ty),
and those present in A. Intuitively, for a query asking how many telescopes “Bernhard” has, we
should make use of the information in “telescope” and “Bernhard” when deciding whether to take
a certain deduction step. By constructing irrelevant axioms that also mention “telescope” and/or
“Bernhard”, it becomes harder to distinguish what is relevant and what is not. We distinguish four
cases: (i) neither the set of agents nor the entity occur in A (no overlap),  (ii) the agent does not occur
in A but the entity does (entity overlap), (iii) the entity does not occur in A but the set of agents does
(agent overlap), and (iv) entity overlap in which the agents occurring in A have lexical overlap with
the set of agents (agent and entity overlap), e.g., if bernhard is in hg then A contains agents like
bernhard’s_student or bernhard’s_son. Entities that do not overlap are always made topically
related, e.g., if Aw contains axioms with telescope, then A may contain binocular.

5 Experiments

We use proofs generated from the family of verbalized logic programs introduced in §4 to help un-
derstand how LMs reason about GSM problems. Our primary experimental manipulative is irrelevant
axioms with respect to a goal theorem introduced into a logic program, which allows us to analyze
how LMs fare in the face of irrelevant axioms. We generate 500 problems with varying structural,
agent and entity overlap, as discussed above. See §D.1 for more details on the make-up of the dataset.
We refer to the problems without any irrelevant axioms as base problems. We additionally generate
control problems that have the same number of axioms as the problems with irrelevant axioms, except
that all axioms are relevant. Their shortest proofs contain the base problem’s shortest proof as a
subproof. This controls for the possible confounder of problem length (see, e.g., Leeb et al., 2025).
We consider both non-ground queries, corresponding to questions like “How many drones does Yanick
have?”,'* and ground queries, corresponding to questions like “Show that Yanick has 5 drones.” .

'? Assuming numerical consistency ensures there exists at most one ground atom in the minimal Herbrand
model that unifies with the non-ground query. This ensures that forward chaining would halt in finite time.


===== PAGE BREAK =====

Meta-Llama-3.1-8B-Instruct                Qwen2.5-Math-7B-Instruct                             QwQ-32B                                       DeepSeek-R1

0.006                                                                                                                                                                    model tokens
0.005                                                                                                                                                                    annotated tokens
2 0.004
Z
3 0.003
Qo
0.002
0.001
0.000 +—       1   :   1  :   —   ;   :   1  ;          +         T
0   1000 2000 3000 4000 «0   1000 2000 3000 4000 «0   1000 2000 3000 ©4000 0   1000 ©2000» 3000-4000,
Number of tokens                        Number of tokens                        Number of tokens                        Number of tokens

Figure 3: Number of tokens in the natural language annotation of the shortest proof as compared to model
outputs for problems with three irrelevant trees (A; L) Az LI A3). The plot includes problems for which the
model gave the correct final answer; this is why the density for annotated tokens differs between the models. We
observe that LMs often use more tokens than necessary.

Language Models. We use one “vanilla” LM and three reasoning LMs in our experiments:
Llama-3.1-8B-Instruct (Llama Team, 2024), Qwen2.5-Math-7B-Instruct (Yang et al., 2024), Qwen’s
reasoning model QwQ-32B, and DeepSeek-R1 (DeepSeek-AI, 2025). We generate strings using
ancestral sampling, restricting the context length to 4000 tokens.

Prompting. Our experimental design is based on in-context learning (Brown et al., 2020).
Specifically, we use five fixed in-context examples of shortest proofs to expose the LM to proofs
in our verbalized logic programs. The verbalized proofs are ordered under a DFS traversal of the
theorems in the proof, such that the axioms are popped in the same order they occur in the verbalized
text. See §D.2 for the prompt.

5.1 Addition of Irrelevant Axioms and Answer Accuracy

We begin by analyzing how irrelevant axioms influence an LM’s ability to generate the correct goal
theorem for non-ground queries. We employ the two-step prompting strategy given by Kojima et al.
(2022). In the first step, the model is prompted to produce a natural-language proof outlining its reason-
ing process. This natural-language process is then mapped to a proof in the verbalized logic program.
In the second step, we prompted the LM a second time—conditioned on the proof it generated—to
produce the goal theorem. In Table 2, we report model accuracy in generating the correct goal
theorem. We observe that even a single irrelevant axiom reduces model performance, particularly for
Llama-3.1 and Qwen2.5. Performance degrades further as additional irrelevant axioms are introduced.
The performance of the most capable model, DeepSeek-R1, is nearly saturated at perfect accuracy,
though slight decreases are still observed when irrelevant axioms are included. Across models,
accuracy on problems containing irrelevant axioms is almost always lower than on the corresponding
control examples, suggesting that irrelevance has a substantial effect on accuracy beyond what can
be explained by longer problem statements. The only exception is Llama-3.1, whose performance on
problems with one irrelevant axiom exceeds that of the corresponding control. QwQ-32B stands out
as an outlier: for this model, performance on the control problems is significantly higher than on the
original base problems. In Fig. 7 (§D.4), we present results stratified by agent and entity overlap (§4.3).
A consistent pattern emerges: such overlap between the goal and irrelevant axioms makes solving the
problem more difficult. Compared to no overlap, performance drops with both kinds of overlap, sug-
gesting both serve as heuristics during search. While drops are typically larger for agent overlap than
for entity overlap, we note that this could be partially due to the entities being topically related (§4.3).
In the following subsection, we analyze the proofs in greater detail to further illuminate these effects.

5.2. Addition of Irrelevant Axioms and Efficiency

In Fig. 3 we plot the empirical distribution over the number of tokens in the model’s output and com-
pare it to the number of tokens in the natural language annotation of the shortest proof, taking only the
proofs that concluded at the correct goal theorem. This analysis, as well as those in the remainder of
this section, are done on the problems with multiple irrelevant trees (i.e., the kind of structural overlap
with the most axioms; §4.3). We observe that all models often use more tokens than are in the annota-
tions, suggesting that they use more compute than necessary to prove goal theorems. This is consistent
with findings on reasoning models (§2), but holds also for the Llama model. However, these results
do not confirm that the models generate irrelevant theorems—they might just be more verbose than
our annotations. This leads us into our efficiency analysis in line with the technical exposition in §3.2.


===== PAGE BREAK =====

Non-ground Queries               Ground Queries

None Entity Agent Both None’ Entity § Agent Both
Efficiency               60.2      43.5       47.5      34.0 | 45.3      34.9       29.9      23.6
Llama-            Exact matches               15           3            4            0          11           9             7           11
3.1-8B — Efficiency (non-axioms) | 71.8      50.3      63.0      44.2 | 57.6      41.3      42.9      37.1
Correct Theorems           84.5       82.9        86.0       85.4 | 76.0       77.8        72.1       69.8
Qwen2.5-         Efficiency            43.7     32.4     34.4     31.1 | 36.8     30.6      29.3     25.3
Math .           Exact matches              8          0           1          0         10          1           2          1
a        Efficiency (non-axioms) | 57.3      40.1       51.5      46.2 | 50.5      38.1      41.1      36.0
Correct Theorems           75.1       73.7        74.3       73.6 | 62.5       63.4        57.4       56.6

Table 3: We report efficiency, number of exact matches (out of 500), and efficiency restricted to non-axioms
between the theorems parsed from the output generated by LMs and the shortest, most-efficient proof. Results
are stratified by type of query and type of overlap between agents and entities present in the query and the
irrelevant axioms. The numbers are computed based on the problems for which the model got the correct
final answer. The low efficiency scores show that LMs often produce irrelevant theorems when successfully
proving a goal theorem. The differences in efficiency scores across datasets of different overlaps are significant
(p < 0.001) according to one-way ANOVA analyses. Lastly, “Correct Theorems” shows the proportion of
the theorems in the shortest proof that the LM predicted.

Efficiency Evaluation. This analysis is performed for Llama-3.1-8B-Instruct and Qwen2.5-Math-
7B-Instruct since only those models followed the required formatting (§4.2);'> however, we perform
a more crude analysis based on only the arithmetic expressions for the other two models in §D.4.
We report the efficiency metric presented in §3.2 for the problems where the LM generated the
correct goal theorem, comparing against the shortest proof generated with our method (§C).'* We
omit built-ins from the efficiency analysis since those are not verbalized. Additionally, we note that
it might be the case that all irrelevant steps the models take are axioms; the LMs may simply be
stating that some axioms are irrelevant to the query. We therefore also consider a metric in which
only non-axiom theorems are counted. In §D.4 we provide an additional analysis on search order.

Efficiency for Non-ground Queries. The main results are shown in §5.2 (non-ground queries), with
scores stratified by agent and entity overlap. The efficiency scores are far from 100%, meaning that the
models predict several theorems beyond the required ones present in the shortest proof. Additionally,
we observe that the efficiency scores vary significantly across the type of overlap (p < 0.001), so we
conclude that lexical information in the query has a substantial effect on proof planning. We finally
comment on the results that only consider non-axioms, presented at the last row in §5.2. We again
observe efficiency scores that are considerably below 100%, showing that the LMs prove theorems that
are irrelevant to the query. §D.3 gives an example where Llama-3.1-8B proves irrelevant theorems.

Comparison to Ground Queries. We compare the performance to the same problems when
presented with ground queries. Queries tend to be non-ground in the GSM domain (Riley et al.,
1983; Cobbe et al., 2021). Since LMs are heavily influenced by training data, we therefore expect
them to perform better on non-ground queries. Our results on the same verbalized logic programs
as before, but with ground queries, are presented on the right-hand side of §5.2. We observe lower
efficiency scores, suggesting that LMs are indeed worse at proving ground theorems in this domain.

6 Conclusion

This paper provided a framework based on logic programming for studying deductive reasoning in
language models, with a particular emphasis on efficiency. This framework enables us to disentangle
efficiency due to generating irrelevant theorems from efficiency due to verbose natural language verbal-
izations of those theorems. We applied this framework to empirically investigate how language models
perform reasoning on math word problems that have many irrelevant axioms. We found that introduc-
ing irrelevant axioms into reasoning problems leads to significantly lower answer accuracies for most
models—even when controlling for problem length—and proofs that exhibit frequent detours through
irrelevant theorems. Our work highlights the need to improve models in terms of reasoning efficiency,
as well as the advantages to viewing deductive reasoning through the lens of logic programming.

'3We manually verified parsing accuracy on the theorems generated by the models for a subset of 20 randomly
sampled examples. An additional class representing that there is no match with any annotated theorem in the proof
is included as well. The parser predicted the correct (or correctly predicted no) match in 394/397 = 99.2% of
the theorems for Llama-3.1-8B-Instruct, and 381/384 = 99.2% of the theorems for Qwen2.5-Math-7B-Instruct.

'4T Ms often generated the same theorems multiple times. We chose to ignore such duplicates in the evaluation.

10


===== PAGE BREAK =====

Acknowledgments and Disclosure of Funding

We thank Juan Luis Gastaldi for useful discussion and criticisms. Andreas Opedal acknowledges
funding from the Max Planck ETH Center for Learning Systems.

References

Serge Abiteboul, Richard Hull, and Victor Vianu. Foundations of Databases: The Logical Level.
Addison-Wesley Longman Publishing Co., Inc., USA, Ist edition, 1995. ISBN 0201537710. URL
https://dl.acm.org/doi/10.5555/551350.

Ujjwala Anantheswaran, Himanshu Gupta, Kevin Scaria, Shreyas Verma, Chitta Baral, and Swaroop
Mishra. Cutting through the noise: Boosting LLM performance on math word problems. In
Proceedings of the ICLR 2025 Workshop on Reasoning and Planning for Large Language Models,
2025. URL https: //openreview.net/forum?id=VnPYbWQjz7.

Daman Arora and Andrea Zanette. Training language models to reason efficiently. In Proceedings
of the ICML Workshop ES-FoMo III: 3rd Workshop on Efficient Systems for Foundation Models,
2025. URL https: //openreview.net/forum?id=tCUGSPSZ3A.

Francois Bancilhon, David Maier, Yehoshua Sagiv, and Jeffrey D. Ullman. Magic sets and other
strange ways to implement logic programs. In Proceedings of the 5th ACM SIGACT-SIGMOD
Symposium on Principles of Database Systems (PODS), pp. 1-15, 1986. URL https://doi.
org/10.1145/6012.15399.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel
Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler,
Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,
Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,
and Dario Amodei. Language models are few-shot learners. In Advances in Neural Information
Processing Systems, volume 33, pp. 1877-1901, 2020. URL https://proceedings.neurips.
cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper. pdf.

Stefano Ceri, Georg Gottlob, and Letizia Tanca. What you always wanted to know about Datalog
(and never dared to ask). IEEE Transactions on Knowledge and Data Engingeering, 1(1):146-166,
March 1989. URL https: //doi.org/10.1109/69 . 43410.

Xingyu Chen, Jiahao Xu, Tian Liang, Zhiwei He, Jianhui Pang, Dian Yu, Linfeng Song, Qiuzhi
Liu, Mengfei Zhou, Zhuosheng Zhang, Rui Wang, Zhaopeng Tu, Haitao Mi, and Dong Yu. Do
NOT think that much for 2+3=? On the overthinking of long reasoning models. In Forty-second
International Conference on Machine Learning, 2025. URL https: //openreview.net/forum?
id=MSbU3L7VO00.

Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,
Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John
Schulman. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168,
2021. URL https: //arxiv.org/abs/2110. 14168.

Alain Colmerauer and Philippe Roussel. The birth of Prolog. SIGPLAN Not., 28(3):37-52, March
1993. doi: 10.1145/155360.155362. URL https: //doi. org/10.1145/155360. 155362.

Evgeny Dantsin, Thomas Eiter, Georg Gottlob, and Andrei Voronkov. Complexity and expressive
power of logic programming. ACM Computing Surveys, 33(3):374—-425, 2001. URL https:
//doi.org/10.1145/502807 . 502810.

Leonardo de Moura and Sebastian Ullrich. The lean 4 theorem prover and programming lan-
guage. In Automated Deduction — CADE 28, volume 12699 of Lecture Notes in Computer Sci-
ence, pp. 625-635. Springer, 2021. URL https://link.springer.com/chapter/10.1007/
978-3-030-79876-5_37.

DeepSeek-AI. DeepSeek-R1: Incentivizing reasoning capability in LLMs via reinforcement learning.
arXiv preprint arXiv:2501.12948, 2025. URL https: //arxiv.org/abs/2501 . 12948.

11


===== PAGE BREAK =====

Edsger W. Dijkstra. A note on two problems in connexion with graphs. Numerische Mathematik, |
(1):269-271, 1959. URL https: //doi.org/10.1007/BF01386390.

Jay Earley. An efficient context-free parsing algorithm. Communications of the ACM, 13(2):94—102,
1970. doi: 10.1145/357980.358005. URL https: //doi. org/10.1145/362007 . 362035.

Emily First, Markus N. Rabe, Talia Ringer, and Yuriy Brun. Baldur: Whole-proof generation and
repair with large language models. In Proceedings of the 31st ACM Joint European Software
Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE
2023, pp. 1229-1241, New York, NY, USA, 2023. Association for Computing Machinery. ISBN
9798400703270. doi: 10.1145/3611643.3616243. URL https: //doi.org/10.1145/3611643.
3616243.

Simon Frieder, Luca Pinchetti, Chevalier Chevalier, Ryan-Rhys Griffiths, Tommaso Salvatori,
Thomas Lukasiewicz, Philipp Petersen, and Julius Berner. Mathematical capabilities of Chat-
GPT. In A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine (eds.), Ad-
vances in Neural Information Processing Systems, volume 36, pp. 27699-27744. Curran Asso-
ciates, Inc., 2023. URL https: //proceedings.neurips.cc/paper_files/paper/2023/
file/58168e8a92994655d6da3939e7cc0918-Paper-Datasets_and_Benchmarks. pdf.

Giorgio Gallo, Giustino Longo, Stefano Pallottino, and Sang Nguyen. Directed hypergraphs and
applications. Discrete Applied Mathematics, 42(2):177—201, 1993. ISSN 0166-218X. doi: https://
doi.org/10.1016/0166-218X(93)90045-P. URL https: //www.sciencedirect.com/science/
article/pii/0166218X9390045P.

Kanishk Gandhi, Dorsa Sadigh, and Noah Goodman. Strategic reasoning with language models.
In NeurIPS 2023 Foundation Models for Decision Making Workshop, 2023. URL https://
openreview.net/forum?id=MUtbsFRZwI.

Kanishk Gandhi, Denise H J Lee, Gabriel Grand, Muxin Liu, Winson Cheng, Archit Sharma, and
Noah Goodman. Stream of search (SoS): Learning to search in language. In First Conference on
Language Modeling, 2024. URL https: //openreview.net/forum?id=2cop2jmQVL.

Nicolas Gontier, Koustuv Sinha, Siva Reddy, and Chris Pal. Measuring systematic generalization
in neural proof generation with transformers. In H. Larochelle, M. Ranzato, R. Hadsell, M.F.
Balcan, and H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33,
pp. 22231-22242. Curran Associates, Inc., 2020. URL https: //proceedings.neurips.cc/
paper_files/paper/2020/file/fc84ad56f9f547eb89c72b9bac209312-Paper . pdf.

Christoph Haase. A survival guide to Presburger arithmetic. ACM SIGLOG News, 5(4):4-21, 2018.
URL https://dl.acm. org/doi/10.1145/3242953 .3242964. A concise tutorial overview
on decision procedures and complexity of Presburger arithmetic.

Tingxu Han, Zhenting Wang, Chunrong Fang, Shiyu Zhao, Shiging Ma, and Zhenyu Chen.
Token-budget-aware LLM reasoning. In Wanxiang Che, Joyce Nabende, Ekaterina Shutova,
and Mohammad Taher Pilehvar (eds.), Findings of the Association for Computational Lin-
guistics: ACL 2025, pp. 24842-24855, Vienna, Austria, July 2025. Association for Compu-
tational Linguistics. ISBN 979-8-89176-256-5. doi: 10.18653/v1/2025.findings-acl.1274. URL
https: //aclanthology.org/2025.findings-acl.1274/.

Steve Hanks and Drew McDermott. Nonmonotonic logic and temporal projection. Artifi-
cial Intelligence, 33(3):379-412, 1987. ISSN 0004-3702. doi: https://doi.org/10.1016/
0004-3702(87)90043-9. URL https: //www.sciencedirect.com/science/article/pii/
0004370287900439.

Peter E. Hart, Nils J. Nilsson, and Bertram Raphael. A formal basis for the heuristic determination of
minimum cost paths. [EEE Transactions on Systems Science and Cybernetics, 4(2):100—107, 1968.
doi: 10.1109/TSSC. 1968.300136. URL https: //doi.org/10.1109/TSSC. 1968. 300136.

Frederick Hayes-Roth, Donald A. Waterman, and Douglas B. Lenat. Building expert systems.

Addison-Wesley Longman Publishing Co., Inc., 1983. URL https: //doi.org/10.1109/PROC.
1985.13159.

12


===== PAGE BREAK =====

Willem Heijltjes. Classical proof forestry. Annals of Pure and Applied Logic, 161(11):1346-1366,
2010. ISSN 0168-0072. doi: https://doi.org/10.1016/j.apal.2010.04.006. URL https: //www.
sciencedirect.com/science/article/pii/S0168007210000473. Special Issue: Classical
Logic and Computation (2008).

Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob
Steinhardt. Measuring massive multitask language understanding. In International Conference on
Learning Representations, 2021. URL https: //openreview.net/forum?id=d7KB jm13GmQ.

Mark Kaminski, Bernardo Cuenca Grau, Egor V. Kostylev, Boris Motik, and Ian Horrocks. Founda-
tions of declarative data analysis using limit Datalog programs. In Proceedings of the 26th Interna-
tional Joint Conference on Artificial Intelligence, IJCAY 17, pp. 1123-1130. AAAI Press, 2017.
ISBN 9780999241103. URL https: //www.ijcai.org/proceedings/2017/0156. pdf.

Mehran Kazemi, Najoung Kim, Deepti Bhatia, Xin Xu, and Deepak Ramachandran. LAMBADA:
Backward chaining for automated reasoning in natural language. In Anna Rogers, Jordan Boyd-
Graber, and Naoaki Okazaki (eds.), Proceedings of the 61st Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers), pp. 6547-6568, Toronto, Canada, July
2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.361. URL
https: //aclanthology.org/2023.acl-long.361/.

Dan Klein and Christopher D. Manning. Parsing and hypergraphs. In Proceedings of the Seventh
International Workshop on Parsing Technologies, pp. 123-134, Beijing, China, October 2001.
URL https: //aclanthology.org/W01-1812/.

Takeshi Kojima, Shixiang (Shane) Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwa-
sawa.  Large language models are zero-shot reasoners.  In S. Koyejo, S. Mo-
hamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh (eds.), Advances in Neu-
ral Information Processing Systems, volume 35, pp. 22199-22213. Curran Associates,
Inc., 2022. URL https://proceedings.neurips.cc/paper_files/paper/2022/file/
8bb0d29 1lacd4acf06ef 112099c16£326-Paper-Conference. pdf.

Robert Kowalski. Predicate logic as programming language. In JFIP congress, volume 74, pp.
569-544, 1974. URL https://www.doc.ic.ac.uk/~rak/papers/IFIP{2074. pdf.

Keito Kudo, Yoichi Aoki, Tatsuki Kuribayashi, Shusaku Sone, Masaya Taniguchi, Ana Brassard,
Keisuke Sakaguchi, and Kentaro Inui. Think-to-talk or talk-to-think? When LLMs come up
with an answer in multi-step reasoning. arXiv preprint arXiv:2412.01113, 2024. URL https:
//arxiv.org/abs/2412.01113.

Philipp K6rner, Michael Leuschel, Joao Barbosa, Vitor Santos Costa, Veronica Dahl, Manuel V.
Hermenegildo, Jose F. Morales, Jan Wielemaker, Daniel Diaz, Salvador Abreu, and Giovanni.
Ciatto. Fifty years of Prolog and beyond. Theory and Practice of Logic Programming, 22(6):
776-858, 2022. URL https://doi. org/10.1017/S1471068422000102.

Felix Leeb, Zhijing Jin, and Bernhard Schélkopf. Causality can systematically address the monsters
under the bench(marks). arXiv preprint arXiv:2502.05085, 2025. URL https://arxiv.org/
abs/2502.05085.

Lucas Lehnert, Sainbayar Sukhbaatar, DiJia Su, Qinqing Zheng, Paul McVay, Michael Rabbat, and
Yuandong Tian. Beyond A*: Better planning with transformers via search dynamics bootstrapping.
In First Conference on Language Modeling, 2024. URL https://openreview.net/forum?
id=SGoVICOuOf.

Belinda Z. Li, Been Kim, and Zi Wang. QuestBench: Can LLMs ask the right question to acquire
information in reasoning tasks? arXiv preprint arXiv:2503.22674, 2025. URL https://arxiv.
org/abs/2503. 22674.

Qintong Li, Leyang Cui, Xueliang Zhao, Lingpeng Kong, and Wei Bi. GSM-plus: A comprehensive
benchmark for evaluating the robustness of LLMs as mathematical problem solvers. In Lun-Wei
Ku, Andre Martins, and Vivek Srikumar (eds.), Proceedings of the 62nd Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers), pp. 2961-2984, Bangkok,
Thailand, August 2024. Association for Computational Linguistics. doi: 10.18653/v 1/2024.
acl-long.163. URL https: //aclanthology.org/2024.acl-long.163/.

13


===== PAGE BREAK =====

Hunter Lightman, Vineet Kosaraju, Yuri Burda, Harrison Edwards, Bowen Baker, Teddy Lee, Jan
Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. Let’s verify step by step. In The Twelfth
International Conference on Learning Representations, 2024. URL https: //openreview.net/
forum? id=v8LOpN6E0i.

Llama Team. The Ilama 3 herd of models. arXiv preprint arXiv:2407.21783, 2024. URL https:
//arxiv.org/abs/2407 .21783.

Haotian Luo, Li Shen, Haiying He, Yibo Wang, Shiwei Liu, Wei Li, Naiqiang Tan, Xiaochun Cao,
and Dacheng Tao. Ol-pruner: Length-harmonizing fine-tuning for o1-like reasoning pruning. In
2nd AI for Math Workshop @ ICML 2025, 2025. URL https: //openreview.net/forum? id=
ioYybCRcyW.

Qing Lyu, Shreya Havaldar, Adam Stein, Li Zhang, Delip Rao, Eric Wong, Marianna Apidianaki, and
Chris Callison-Burch. Faithful chain-of-thought reasoning. In Jong C. Park, Yuki Arase, Baotian
Hu, Wei Lu, Derry Wijaya, Ayu Purwarianti, and Adila Alfa Krisnadhi (eds.), Proceedings of the
13th International Joint Conference on Natural Language Processing and the 3rd Conference of the
Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers),
pp. 305-329, Nusa Dua, Bali, November 2023. Association for Computational Linguistics. doi: 10.
18653/v1/2023.ijcnlp-main.20. URL https: //aclanthology.org/2023.ijcnlp-main.20/.

Xinyin Ma, Guangnian Wan, Runpeng Yu, Gongfan Fang, and Xinchao Wang. CoT-valve: Length-
compressible chain-of-thought tuning. In Wanxiang Che, Joyce Nabende, Ekaterina Shutova, and
Mohammad Taher Pilehvar (eds.), Proceedings of the 63rd Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers), pp. 6025-6035, Vienna, Austria, July 2025.
Association for Computational Linguistics. ISBN 979-8-89176-251-0. doi: 10.18653/v 1/2025.
acl-long.300. URL https: //aclanthology.org/2025.acl-long.300/.

David Maier, Jeffrey D. Ullman, and Moshe Y. Vardi. On the foundations of the universal relation
model. ACM Trans. Database Syst., 9(2):283-308, June 1984. ISSN 0362-5915. doi: 10.1145/329.
318580. URL https: //doi.org/10.1145/329.318580.

John McCarthy and Patrick Hayes. Some philosophical problems from the standpoint of artificial
intelligence. In B. Meltzer and Donald Michie (eds.), Machine Intelligence 4, pp. 463-502.
Edinburgh University Press, 1969. URL https: //philpapers.org/rec/MCCSPP.

Seyed Iman Mirzadeh, Keivan Alizadeh, Hooman Shahrokhi, Oncel Tuzel, Samy Bengio, and
Mehrdad Farajtabar. GSM-symbolic: Understanding the limitations of mathematical reasoning in
large language models. In The Thirteenth International Conference on Learning Representations,
2025. URL https: //openreview.net/forum?id=AjXkRZIvjB.

Edward F. Moore. The shortest path through a maze. Proceedings of an International Symposium
on the Theory of Switching, pp. 285-292, 1959. URL https: //books. google. ch/books?id=
IVZBHAAACAAJ.

Niklas Muennighoff, Zitong Yang, Weijia Shi, Xiang Lisa Li, Li Fei-Fei, Hannaneh Hajishirzi, Luke
Zettlemoyer, Percy Liang, Emmanuel Candes, and Tatsunori Hashimoto. s1: Simple test-time
scaling. In Workshop on Reasoning and Planning for Large Language Models, 2025. URL
https: //openreview.net/forum?id=LdHOvrgAHm.

Minh-Vuong Nguyen, Linhao Luo, Fatemeh Shiri, Dinh Phung, Yuan-Fang Li, Thuy-Trang Vu,
and Gholamreza Haffari. Direct evaluation of chain-of-thought in multi-hop reasoning with
knowledge graphs. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Findings of the
Association for Computational Linguistics: ACL 2024, pp. 2862-2883, Bangkok, Thailand, August
2024. Association for Computational Linguistics. URL https: //aclanthology.org/2024.
findings-acl.168/.

Andreas Opedal, Niklas Stoehr, Abulhair Saparov, and Mrinmaya Sachan. World models for math
story problems. In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (eds.), Findings of
the Association for Computational Linguistics: ACL 2023, pp. 9088-9115, Toronto, Canada, July
2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.findings-acl.579. URL
https: //aclanthology.org/2023.findings-acl.579/.

14


===== PAGE BREAK =====

Andreas Opedal, Haruki Shirakami, Bernhard Schélkopf, Abulhair Saparov, and Mrinmaya Sachan.
MathGAP: Out-of-distribution evaluation on problems with arbitrarily complex proofs. In
The Thirteenth International Conference on Learning Representations, 2025. URL https:
//openreview.net/forum?id=5ck9PIrTpH.

Arkil Patel, Satwik Bhattamishra, and Navin Goyal. Are NLP models really able to solve simple math
word problems? In Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek Hakkani-Tur,
Iz Beltagy, Steven Bethard, Ryan Cotterell, Tanmoy Chakraborty, and Yichao Zhou (eds.), Proceed-
ings of the 2021 Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies, pp. 2080-2094, Online, June 2021. Association for
Computational Linguistics. URL https: //aclanthology.org/2021.naacl-main. 168.

Judea Pearl. Heuristics: Intelligent Search Strategies for Computer Problem Solving. Addison-
Wesley, Reading, MA, 1984. ISBN 0-201-05594-5. URL https: //dl.acm. org/doi/book/10.
5555/525.

Ivo Petrov, Jasper Dekoninck, Lyuben Baltadzhiev, Maria Drencheva, Kristian Minchev, Mislav
Balunovic, Nikola Jovanovi¢, and Martin Vechev. Proof or bluff? Evaluating LLMs on 2025 USA
math olympiad. In 2nd Al for Math Workshop @ ICML 2025, 2025. URL https: //openreview.
net/forum? id=3v650rMO5U.

David L. Poole and Alan K. Mackworth. Artificial Intelligence: Foundations of Computational
Agents. Cambridge University Press, USA, 2nd edition, 2017. ISBN 110719539X. URL https:
//doi.org/10.1017/9781009258227.

Mojzesz Presburger. Uber die Vollstandigkeit eines gewissen Systems der Arithmetik ganzer Zahlen,
in welchem die Addition als einzige Operation hervortritt. In Comptes Rendus du I*" congrés
de Mathématiciens des pays Slaves, Varsovie 1929, pp. 92-101, 1929. URL https://books.
google.ch/books?id=7agKHQAACAAJ. In German.

Xiao Pu, Michael Saxon, Wenyue Hua, and William Yang Wang. ThoughtTerminator: Benchmarking,
calibrating, and mitigating overthinking in reasoning models. In Second Conference on Language
Modeling, 2025. URL https: //openreview.net/forum? id=oHR862dpMC.

Raghu Ramakrishnan. Magic templates: A spellbinding approach to logic programs. The
Journal of Logic Programming, 11(3&4):189-216, 1991. URL https://doi.org/10.1016/
0743-1066 (91)90026-L.

David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani,
Julian Michael, and Samuel R. Bowman. GPQA: A graduate-level google-proof q&a benchmark.
In First Conference on Language Modeling, 2024. URL https://openreview.net/forum?
id=Ti67584b98.

Mary Riley, James Greeno, and Joan Heller. Development of Children’s Problem-Solving Ability in
Arithmetic, pp. 153-196. Learning Research and Development Center, University of Pittsburgh, 01
1983. ISBN 978-0122847806. URL https: //eric.ed. gov/?id=ED252410.

John Alan Robinson. A machine-oriented logic based on the resolution principle. Journal of the
ACM, 12(1):23-41, 1965. doi: 10.1145/321250.321253. URL https://doi.org/10.1145/
321250 . 321253.

Erik Sandewall. An approach to the frame problem and its implementation. Machine intelligence, 7
(195-204):11-19, 1972. URL https://www.ida.liu.se/ext/caisor/archive/1972/001/
caisor-1972-001.pdf.

Clayton Sanford, Bahare Fatemi, Ethan Hall, Anton Tsitsulin, Mehran Kazemi, Jonathan Halcrow,
Bryan Perozzi, and Vahab Mirrokni. Understanding transformer reasoning capabilities via graph
algorithms. In The Thirty-eighth Annual Conference on Neural Information Processing Systems,
2024. URL https: //openreview.net/forum?id=AfzbDw6DSp.

Abulhair Saparov, Srushti Ajay Pawar, Shreyas Pimpalgaonkar, Nitish Joshi, Richard Yuanzhe Pang,
Vishakh Padmakumar, Mehran Kazemi, Najoung Kim, and He He. Transformers struggle to learn
to search. In The Thirteenth International Conference on Learning Representations, 2025. URL
https: //openreview.net/forum?id=9cQB1Hwrtw.

15


===== PAGE BREAK =====

Bilgehan Sel, Ahmad Tawaha, Vanshaj Khattar, Ruoxi Jia, and Ming Jin. Algorithm of thoughts:
Enhancing exploration of ideas in large language models. In Proceedings of the 41st Inter-
national Conference on Machine Learning, 2024. URL https://proceedings.mlr.press/
v235/sel24a.html.

Kulin Shah, Nishanth Dikkala, Xin Wang, and Rina Panigrahy. Causal language modeling can elicit
search and reasoning capabilities on logic puzzles. In The Thirty-eighth Annual Conference on
Neural Information Processing Systems, 2024. URL https: //openreview.net/forum?id=
i5PoejmWoC.

Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed Huai hsin Chi, Nathanael
Scharli, and Denny Zhou. Large language models can be easily distracted by irrelevant context.
In International Conference on Machine Learning, 2023. URL https://openreview.net/
forum? id=JSZmoNO30p.

Charlie Victor Snell, Jachoon Lee, Kelvin Xu, and Aviral Kumar. Scaling LLM test-time compute
optimally can be more effective than scaling parameters for reasoning. In The Thirteenth In-
ternational Conference on Learning Representations, 2025. URL https: //openreview.net/
forum? id=4FWAwZtd2n.

Leon Sterling and Ehud Shapiro. The Art of Prolog: advanced programming techniques. MIT Press,
Cambridge, MA, USA, 2nd edition, 1994. ISBN 0262193388. URL https: //cliplab.org/
~logalg/doc/The_Art_of_Prolog. pdf.

Yang Sui, Yu-Neng Chuang, Guanchu Wang, Jiamu Zhang, Tianyi Zhang, Jiayi Yuan, Hongyi Liu,
Andrew Wen, Shaochen Zhong, Na Zou, Hanjie Chen, and Xia Hu. Stop overthinking: A survey
on efficient reasoning for large language models. Transactions on Machine Learning Research,
2025. ISSN 2835-8856. URL https: //openreview.net/forum? id=HvoG8SxggZ.

Hisao Tamaki and Taisuke Sato. Unfold/Fold transformation of logic programs. In Proceedings of the
International Conference on Logic Programming, 1984. URL https://ci.nii.ac. jp/naid/
10000035006/.

Robert Tarjan. Depth-first search and linear graph algorithms. SJAM Journal on Computing, 1(2):
146-160, 1972. doi: 10.1137/0201010. URL https: //doi.org/10.1137/0201010.

Alfred Tarski. A lattice-theoretical fixpoint theorem and its applications. Pacific Journal of Mathemat-
ics, 5(2):285-309, 1955. URL https: //msp. org/pjm/1955/5-2/pjm-v5-n2-p1i-s.pdf.

Kimi Team, Angang Du, Bofei Gao, Bowei Xing, Changjiu Jiang, Cheng Chen, Cheng Li, Chenjun
Xiao, Chenzhuang Du, Chonghua Liao, Chuning Tang, Congcong Wang, Dehao Zhang, Enming
Yuan, Enzhe Lu, Fengxiang Tang, Flood Sung, Guangda Wei, Guokun Lai, Haiqing Guo, Han
Zhu, Hao Ding, Hao Hu, Hao Yang, Hao Zhang, Haotian Yao, Haotian Zhao, Haoyu Lu, Haoze Li,
Haozhen Yu, Hongcheng Gao, Huabin Zheng, Huan Yuan, Jia Chen, Jianhang Guo, Jianlin Su,
Jianzhou Wang, Jie Zhao, Jin Zhang, Jingyuan Liu, Junjie Yan, Junyan Wu, Lidong Shi, Ling Ye,
Longhui Yu, Mengnan Dong, Neo Zhang, Ningchen Ma, Qiwei Pan, Qucheng Gong, Shaowei Liu,
Shengling Ma, Shupeng Wei, Sihan Cao, Siying Huang, Tao Jiang, Weihao Gao, Weimin Xiong,
Weiran He, Weixiao Huang, Wenhao Wu, Wenyang He, Xianghui Wei, Xianqing Jia, Xingzhe Wu,
Xinran Xu, Xinxing Zu, Xinyu Zhou, Xuehai Pan, Y. Charles, Yang Li, Yangyang Hu, Yangyang
Liu, Yanru Chen, Yejie Wang, Yibo Liu, Yidao Qin, Yifeng Liu, Ying Yang, Yiping Bao, Yulun
Du, Yuxin Wu, Yuzhi Wang, Zaida Zhou, Zhaoji Wang, Zhaowei Li, Zhen Zhu, Zheng Zhang,
Zhexu Wang, Zhilin Yang, Zhiqi Huang, Zihao Huang, Ziyao Xu, and Zonghan Yang. Kimi k1.5:
Scaling reinforcement learning with LLMs. arXiv preprint arXiv:2501.12599, January 2025. URL
https://doi.org/10.48550/arXiv.2501.12599.

George Tsoukalas, Jasper Lee, John Jennings, Jimmy Xin, Michelle Ding, Michael Jennings, Ami-
tayush Thakur, and Swarat Chaudhuri. PutnamBench: Evaluating neural theorem-provers on
the Putnam Mathematical Competition. In The Thirty-eight Conference on Neural Information
Processing Systems Datasets and Benchmarks Track, 2024. URL https://openreview.net/
forum? id=ChKCF750cd.

16


===== PAGE BREAK =====

Miles Turpin, Julian Michael, Ethan Perez, and Samuel R. Bowman. Language models don’t always
say what they think: Unfaithful explanations in chain-of-thought prompting. In Thirty-seventh
Conference on Neural Information Processing Systems, 2023. URL https: //openreview.net/
forum? id=bzs4uPLxvi.

Moshe Y. Vardi. The complexity of relational query languages. In Proceedings of the Fourteenth
Annual ACM Symposium on Theory of Computing, STOC °82, pp. 137-146. Association for
Computing Machinery, 1982. ISBN 0897910702. doi: 10.1145/800070.802186. URL https:
//doi.org/10.1145/800070. 802186.

Peiyi Wang, Lei Li, Zhihong Shao, Runxin Xu, Damai Dai, Yifei Li, Deli Chen, Yu Wu, and Zhifang
Sui. Math-Shepherd: Verify and reinforce LLMs step-by-step without human annotations. In
Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Proceedings of the 62nd Annual Meeting
of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 9426-9439,
Bangkok, Thailand, August 2024. Association for Computational Linguistics. doi: 10.18653/v1/
2024.acl-long.510. URL https: //aclanthology.org/2024.acl-long.510/.

Edwin B. Wilson. Probable inference, the law of succession, and statistical inference. Journal of the
American Statistical Association, 22(158):209-212, 1927. doi: 10.1080/01621459.1927.10502953.
URL https: //www.tandfonline.com/doi/abs/10.1080/01621459. 1927. 10502953.

Wilson Wu, John Xavier Morris, and Lionel Levine. Do language models plan ahead for future
tokens? In First Conference on Language Modeling, 2024. URL https://openreview.net/
forum? id=Ba0AvPUyBO.

Shijie Xia, Xuefeng Li, Yixin Liu, Tongshuang Wu, and Pengfei Liu. Evaluating mathematical
reasoning beyond accuracy. Proceedings of the AAAI Conference on Artificial Intelligence, 39:
27723-27730, 04 2025. doi: 10.1609/aaai.v39i26.34987. URL https: //ojs.aaai.org/index.
php/AAAT/article/view/34987.

An Yang, Beichen Zhang, Binyuan Hui, Bofei Gao, Bowen Yu, Chengpeng Li, Dayiheng Liu,
Jianhong Tu, Jingren Zhou, Junyang Lin, Keming Lu, Mingfeng Xue, Runji Lin, Tianyu Liu,
Xingzhang Ren, and Zhenru Zhang. Qwen2.5-Math technical report: Toward mathematical
expert model via self-improvement. arXiv preprint arXiv:2409. 12122, 2024. URL https:
//arxiv.org/abs/2409.12122.

Longhui Yu, Weisen Jiang, Han Shi, Jincheng YU, Zhengying Liu, Yu Zhang, James Kwok, Zhenguo
Li, Adrian Weller, and Weiyang Liu. MetaMath: Bootstrap your own mathematical questions for
large language models. In The Twelfth International Conference on Learning Representations,
2024. URL https: //openreview.net/forum?id=N8NOhgNDRt.

Hugh Zhang, Jeff Da, Dean Lee, Vaughn Robinson, Catherine Wu, William Song, Tiffany Zhao,
Pranav Vishnu Raja, Charlotte Zhuang, Dylan Z Slack, Qin Lyu, Sean M. Hendryx, Russell Kaplan,
Michele Lunati, and Summer Yue. A careful examination of large language model performance
on grade school arithmetic. In The Thirty-eight Conference on Neural Information Processing
Systems Datasets and Benchmarks Track, 2024. URL https: //openreview.net/forum?id=
RJZRhMZZzH.

17


===== PAGE BREAK =====

A Further Background

A.1_ Negation in Logic Programming

It is also useful to introduce a notion of negation into logic programming. We denote negation by —.
To accommodate negation, we introduce the extended Herbrand base H © H U {Ah | he H}.
We call an interpretation J C H consistent iff b ¢ I => —b ¢ I. Furthermore, a logic program
P is called consistency-preserving if J is consistent implies Tp (JZ) is consistent. One simple way
to check whether a logic program is consistency-preserving is to inspect the program’s dependency
structure. Construct the predicate dependency graph G as follows. Create a vertex (p ) for every
distinct predicate symbol p appearing in P. For each rule r = (bj,...,b% + h) € P and each
predicate p appearing among r’s premises,  add a directed edge (p ) + (a) where q is h’s predicate
symbol. Then, label the edge — if p is negated and + otherwise.  We say ‘that G has a negative cycle
if there exists a directed cycle that contains at least one negatively labeled edge. Logic programs that
do not have negative cycles are called stratified (Abiteboul et al., 1995, §15.2). It is easy to see that
any stratified logic program has a consistency-preserving fixpoint operator.

A.2. Forward Chaining

We give background details and pseudocode for the forward chaining algorithm; see Alg. 1. The
algorithm takes a logic program P = R LU A with a set of ground goal theorems 1, and returns T
(true) if all goal theorems in H, can be proved. It uses a priority queue @ and a set C. The priority
queue Q is called the agenda. It keeps track of theorems that are to be used to prove new theorems.
The order in which the axioms are pushed to Q will determine the order in which they are popped
and @ may implement any arbitrary priority policy. For example, a last-in first-out (LIFO) policy
yields a depth-first search (DFS) order, while a first-in first-out (FIFO) policy yields a breadth-first
search (BFS) order. The set C is called a chart. The chart keeps track of theorems that have been
proved. Theorems are added to C after they have been popped from Q.

When a theorem is popped, it is used to prove new theorems if applicable. The algorithm iterates
over all rules in the program and proves all conclusions that can be proved from the popped premise
together with theorems that have previously been added to C. For a conclusion to be proved, there
must exist an instantiation of the rule for which the premises in the instantiated ground rule are in
C. The algorithm iteratively removes theorems from H, as they are proved, and terminates with the
result T when H, has been emptied. If all theorems that could be proved have been popped and H,
remains non-empty, the algorithm returns F (false). The algorithm may not terminate, however, if the
minimal Herbrand model is infinitely large.

B_Decidability of GSM Programs

Proposition 1 (Decidability). Let Pw = RwUAw be a logic program where Ry is specified in Table 1
and Ay is a numerically consistent subset of Ry’s extended Herbrand base H. Then, inference in
Pw is decidable, i.e., it is decidable to determine whether h € T (Aw) for an arbitrary h € H.

Proof sketch. First, observe that the extended Herbrand base H of Pw is countably infinite due to
the unbounded sets of quantity constants N¢ and timestamp constants N¢.. However, since the axioms
Aw were chosen to be numerically consistent and the sets =,  2A    and EF, are all finite, it follows
that T7,(Aw)—or equivalently 1M—contains only finitely many theorems for each element of N‘.
Consequently, reasoning in Pw reduces to Presburger arithmetic, as the only built-in predicate that
applies to timestamps is 7y+ 1, present in Rule (2) in Table 1. Since Presburger arithmetic is famously
decidable (Presburger, 1929; Haase, 2018), it follows that inference in Pw is decidable.            |_|

C. Data Generation

We adapt and apply Opedal et al.’s (2025) method for generating shortest proofs with axioms that are
numerically consistent. §C.2 introduces and discusses pseudocode (Alg. 2), §C.3 explains how we
use the algorithm to generate a proof along with irrelevant axioms, and §C.4 shows that the algorithm
indeed returns a shortest proof. To do so, we define a class of logic programs of which Pw is a
member, and we will present a generalization of Opedal et al.’s (2025) method that generates shortest
proofs under any program in this class. We start by defining this class of logic programs in §C. 1 below.

18


===== PAGE BREAK =====

Algorithm 1 Generic forward chaining

|. function FORWARDCHAINING(P = RL A, Hy)
Dprogram P = RL A, set of ground goal theorems Hg

yD oN

s Q+e                                                                          Dinitialize agenda
4 Ce @                                                            Dinitialize the chart / set of known atoms
5.    for b' € A:                                                                         >push axioms to agenda
6.        Q.PUSH(b’)

7, whileQ 4 @:                                                             >pop premises while available
8.      ve Q.POP()                                                  Dpop highest priority premise
9.        CeCuU {b'}                                                         >mark as proved by adding to chart
10.       for (b,,..,by FR) ER:                                        Diterate over all rules in program
M.         if 30 € O(P) : b1/8,....bv /OF h/O and b;/6, ...,bv /0 € C:

12.              >there is a new inference rule available for which all premises have been previously proved

13.             hie h/6                                                        >ground conclusion to the rule
14.              if h’ €C:                                                                   >we proved a new theorem
15.                  Q.PUSH(h’)                                                                          >push to agenda
16.                 if h’ € Hg:                                                       >we proved a new goal theorem
17.                   Hg <— Hy \ {h'}                             >mark as proved by removing from goal set
18.                     if Hg =D:                     >the goal set is empty so we have proved all goal theorems
19.                        return T

20. Ball goal theorems could not be proved

21. return F

C.1 Additional Definitions

We define the expanded Herbrand base containing all ground and non-ground atoms—including

negation (§A.1)—as H ©  {p(ti,..,tw) | p € Yp,ar(p) = N,ti,..,tw € LeU Uy} U
{ap(ti,..,tw) | p € Ep,ar(p) = N,ti,..,tw € NeU Uy}. We let C : H + 2**4™ be a
function that selects a set of terms from an input atom. We refer to C(b) as the C-terms of b.
One example of such a function in Rw is to return the set of agent terms from a given atom, e.g.,
C(cont(A, 5, boat, 1)) = {4} and C(comp(4, tharukt}, 2, boat, 1)) = {4, tharuki}}. In the
following, we will also define C' of an inference rule. Indeed, r = 0y,...,bK% F h, we define
C(r) = Us, C'(b,) as the union of the C’-terms in the premises of the inference rule r. We similarly
define C of a hyperedge: Given a hyperedge e = {b1,...,bK} > h, C(e) = Un, C(bx).
Definition 1. We say a set of inference rules R is C-conserving if, for every inference rule by, ...,bK F
h, we have C(by) & {} for all k, C(h) & {}, and one of the following conditions holds:

1. The rule is an introduction rule for a predicate p, and can be written as

Here, we require the premises to be non-p atoms. We require the C’-terms in the conclusion

appear in the premises: C(p(ti,...,tw)) = UL, C'(bx). We also require that the C-terms
of the premises are disjoint: C(b,) 1 C(b;) = @ for all k A j. We require that R have at
most one introduction rule for each predicate.

2. The rule is an elimination rule for a predicate p, and can be written as
Here, we require that the C-term of the conclusion is distinct from that of the premises:
by, -)bK-1, C(h) NC (bg) = @ for all k = 1,..., K — 1. We also require that the C-term
of the premise p(t1, ...,t~) contains the C-terms of all other premises and the conclusion:

C(h) U Urs) C(bkp) © C(p(ti,...,tn)). Finally, we require the C-terms of the other
premises are disjoint: C(b,) ON C(b;) = @ for all0 < k,j < K andk F j.

3. The rule is a union rule, where there is a built-in premise requiring the C'-terms of the

conclusion be equal to the union of the C’-terms of the premises: C(h) = Un, Cb). This
rule must be unique in R.

19


===== PAGE BREAK =====

4. The rule is an unused rule: it contains premises that do not unify with the conclusion of
any rule.

Finally, if R has multiple elimination rules for a predicate p, we require that those rules be dis-
tinct in the following way: For any two such rules, written by, ...,bK-1,p(ti,...,fn) / h and
BL, O17, D(H, Uh) F A’, for any 6 such that h/0 = h’, p(ti, ..,tw)/0 A p(t), ..., ty).

Given a C-conserving set of inference rules R, we will use the following short-hand notation to refer
to specific subsets of rules:

¢ R, is the set of introduction rules in ?.
¢ R, is the set of elimination rules in 7?.
¢ Ry is the set of union rules in FR.

Definition 2. Let E: H +> 2¥=V™* be a function. We say a set of inference rules R is E-monotonic
if, for every inference rule by,...,b% / h, we have E(b,) # {} for all k, E(h) 4 {}, and one of the
following conditions holds:

1. The rule is an introduction rule; see above.
2. The rule is an elimination rule; see above.
3. The rule preserves E-terms: E(b;) =+-- = E(bx) = E(h).

To prove the optimality of our generated proofs, we need additional constraints on the relationship
between introduction and elimination rules. Let C: H +4 2¥2¥** be a function. Consider each elim-
ination rule 0, ..., bk —1, p(ti, ..,t~) F A, and let Cy   ae C(b,) and Ch, 2 C(h). Construct
a hypergraph using the following procedure: Start by mapping the atom p(ty, ..., ty) to a vertex vo,
i.e., we set £(vo) = (p(t, ..., tw). Repeat the following: For any vertex v that contains C-terms in
both C; and Cy, (i.e., C(E-!(v)) ACy A @ and C(L-1(v)) AN Cy, ¥ B), and for any introduction rule
B15 OK FR’ ER, add a vertex for each unified premise b;/0 where £(h’/0) = v and a hyperedge
from {£~1(b;/0)} to €-1(v). We say the elimination rule is C-locally reducible if either: (1) the
hypergraph contains no edges, or (2) there exists a vertex in this hypergraph that identifies with the
conclusion of the elimination rule h. If all elimination rules in F are locally reducible, we say R
is in harmony. One consequence of harmony is that, in any proof P containing a proof step with
an elimination rule, if the subproof of the premise p(t1, ...,£,’) does not contain any axioms with
C-terms from both C, and C},, which is true of any proof generated by the procedure in §C, then
the conclusion of the elimination rule must be an axiom of the subproof. Therefore, P is not optimal.

We note that Ry is agent-conserving, i.c., Rw is C-conserving where C is the function that returns
the agents of any atom. In particular, if we inspect the rules in Table 1, we observe that (1a) and
(1b) are elimination rules for comp, and (1c) is the corresponding introduction rule. Rules (2a)
and (2b) are elimination rules for transfer. Rule (4) is an elimination rule for rate. There are no
corresponding introduction rules for transfer and rate. (5a) is an elimination rule for compeq and
(5b) is the corresponding introduction rule. Rule (3) is a union rule. Rule (6) is an unused rule. Rw
is also entity-monotonic with (4) being the elimination rule for rate. Rw is also in harmony, with
respect to both agents and entities: (1a) and (1b) are each locally reducible with (1c). (Sa) is locally
reducible with a combination of (5b) and (Ic).

A ground substitution {(m, tm)}M_, is a typed substitution where t,,, € D*, for all m € [M]. We
define O,(P) to be the set of all ground substitutions under the logic program P.

C.2 Applying Opedal et al.’s (2025) Method

Opedal et al. (2025) provide a method to generates the shortest proof for a goal hg, i.e., a
(€—!(Aw), €~1(hg))-hyperpath in Hp,,; see $3.2. We present the pseudocode in Alg. 2. The method
takes any logic program P with C’-conserving rules, e.g., Pw as described in Table 1, a goal theorem
hg, a set of forbidden ground theorems A,,, and a maximum depth D. The set A, becomes relevant
when generating irrelevant axioms, which will be discussed in §C.3. For now, we assume that
Ay = &. The algorithm will terminate and return a proof of depth D. In our experiments with
Pw, we use the following arguments: We sample the goal h, to be a ground atom of the form
cont(A, @, £, T)/@ for some 0 € O(Pw). For the agent set we make an arbitrary choice, sampling an

20


===== PAGE BREAK =====

Algorithm 2

. function SAMPLES HORTESTPROOF(P, hg, Ax, D)
blogic program P (e.g., Table 1), goal theorem hg, forbidden ground theorems Ax, max depth D
let R be the inference rules in P

y oN

4 Pee                                                                     Dinitialize an empty hyperpath
5. QUEUE <— []                                 Dinitialize queue for conclusions to expand and their depth
6. QUEUE.PUSH((0, hg))                                                         >hg is distance 0 from hg
7 SET¢ {hg}U Ay

s. While QUEUE 4 @:

9,       d, h) < QUEUE.POP()

10.       ifd > D:                                                         Dexit if stopping criterion has been met
HL.         break

12.        first, sample the inference rule for the next proof step

Bn RE Lr | r= (Vig De FR) E RU Re U Ry, 0 € Oo(P) : h’/0 = h}

14,      r = (b1,..,0% Fh’) ~ SAMPLE(R’)

15.         next, we sample the substitution

16.      0’ + {0 | 0 € Og(P), h'/0 =h, bi. /0 ¢ SET}

17.         sample novel and distinct C-terms whenever possible

18.       let Copp & Useser C(x)

pO HON {B| [Ups CO) \ CCH)| = [Ups CO/9) \ Creel}

20.       ifr € Ry:                                                        >sample widest possible union rules
’       ’              ,             G                       .

21.     0! & ON {4 | C(b,/0) A C(Y;,/0) = @ for k # j}

22.      0 ~ SAMPLE(Q’)

23.     fork =1upto K:

24,         SET < SET U {b1,/0}

25.          ifr eR, andk 4 Kk:                        >the last premise of elimination rules are axioms

26.             QUEUE.PUSH((d + 1, bi, /0))

27.        >construct the hyperedge for this new proof step, and prepend it to the hyperpath

28.     Pe ({b,..,bK} — h)oP
2. return P

agent set with cardinality {1, 2, 3, 4} with probabilities {114 1/2,2H 1/6, 3} 1/6, 4 1/6}. We
restrict the cardinality to 4 in order avoid generating GSM problems that are too large; see §D.1 for
dataset statistics. The timestamp is set to an arbitrary value larger than the value of D, which ensures
that the timestamps remain in N¢ throughout the generation procedure. We sample D uniformly
at random from {1, 2,3} for every generated proof.

Sampling proceeds recursively in a top-down manner. We then sample an inference rule bj, ..., bk Fh,
i.e., where h is the conclusion. This yields a tree. We then repeat the procedure recursively for
each leaf node until the stopping criterion, i.e., required depth, has been reached. Importantly, all
premises are sampled without replacement; this ensures that any individual theorem will not be
used more than once in the generated proof, i.e., the proof is acyclic. For example, suppose we
have cont(fharuki}, 5, boat, 1) and sample an instantiation of Rule (1a) in Table 1. We generate
two new premises, cont({abu}, 3, boat, 1) and comp(fharuki}, fabu}, 2, boat, 1), where the
agent {abu} is a new agent that does not appear elsewhere in the proof. In Alg. 2, this is handled
by maintaining a set SET of generated non-ground atoms, and by restricting the substitutions such
that new C-terms are mapped to new objects. We only sample atoms that are not in SET.

We comment on two more details of Alg. 2. First, whenever we sample an elimination rule
by, .-, bk 1, p(t1, ..., tv) F h, we require the last premise, p(t1, ...,t), to be an axiom, i.e., we do
not recursively apply the algorithm on this premise. This is due to the fact that the rules in P are
in harmony, and so the addition of introduction rules preceding elimination rules could result in
locally-reducible regions in the output proof, and so the proof would not be shortest. Second, if we
sample a union rule, we always require the C-terms of the premises to be singleton sets. Otherwise, a
shorter proof could have been obtained by several instantiations of the union rule.'>

'SThis is analogous to folding and unfolding (Tamaki & Sato, 1984).

21


===== PAGE BREAK =====

Throughout the algorithm, we sample substitutions from O,(P). By substituting under the constraints
laid out by the arithmetic built-ins we ensure numerical consistency. However, numerical substitutions
may fail due to unsatisfiable constraints, i.e., QO’ in Alg. 2 may become empty before we sample from
it. We therefore perform rejection sampling until a successful substitution has been found. In a few
cases, this may run prohibitively long. We therefore retry a maximum of 1000 times before rejecting
the candidate proof and sampling a new one.

C.3 Generating Math Word Programs With Irrelevant Axioms

We apply Alg. 2 described in the previous subsection to generate irrelevant axioms. As mentioned in
§4.3, we augment a logic program Pw = Rw L! Aw—as sampled by the method described above—
with M additional sets of irrelevant axioms A, L---L! Ag. In simple terms, we do so by applying the
sampling procedure again, once for every A,,, with additional restrictions to not generate duplicate
axioms. As we will show later, this procedure for generating irrelevant axioms requires the additional
constraint that the inference rules 7? in the logic program P be E-monotonic. With each application
of the sampling procedure, we provide a perturbed goal argument h,. At least one C-term or /-term
of the original goal will be replaced with a new value (e.g., in Pw, either the agent, the entity, or both
will be perturbed). Precisely which term is perturbed depends on the experimental setting (see §4.3).
The set of forbidden theorems A,, is initialized to be the theorems in the shortest proof (including
the axioms) from Pw = Rw LI Aw, thus, avoiding generating those theorems. The same is done
incrementally for the irrelevant axioms as they are generated, guaranteeing disjoint sets.

Moreover, for practical reasons, the distribution from which we sample is slightly modified. In
particular, we restrict cont predicates to have singleton agent sets; otherwise, the number of irrel-
evant axioms could get very large. Furthermore, we exclude the rate predicate, as we found that
overlapping agents and entities could sometimes be hard to instantiate with a rate atom, since it
requires a particular semantic relationship between the two entity terms in the atom, e.g., “apples”
per “basket”. Enforcing these restrictions led to substantially more efficient rejection sampling
during the substitution part of Alg. 2.

When ordering the axioms in natural language, it is undesirable to have a predictable ordering of
relevant and irrelevant axioms, e.g., appending all irrelevant axioms to follow the relevant ones. We
therefore randomly reorder them in a manner that respects the ordering of the values of the timestamp.

C.4_ Uniqueness and Optimality of Generated Proofs

Here, we will show that the above procedure for generating proofs produces a shortest proof—a proof
from axioms A to a goal h, for which there does not exist a shorter proof of h, from A. Furthermore,
we will show that each generated proof is unique: There are no other shortest proofs with the same
axioms and goal theorem.

C-conservation, monotonicity, and harmony of the inference rules alone is insufficient to guarantee
that the proofs generated by the procedure described in §C are shortest. We need additional properties
of the generated proofs, as well as few additional definitions.

A linear chain is a sequence of hyperedges €1, ..., €,g where the head of every edge is in the tail of the
next edge (except for the last edge). More precisely, for all m, we have em = {bm1,--;0m,K} > hm,
and for allO <m < M, hm € {0m4ij1; Om+1,2, --}-

Given an (A, h,)-proof P = ((V,£),@), and an atom x € H in the extended Herbrand base H
($A.1) where ~!(x) € V, a subproof of x is an (A, x)-proof P,, = ((Vz, Ex), £) where V, C V
and F.,, C EF. Using this, we can define the subproof relation: If P,, is a subproof of some atom in P,
we write P, < P. We say a subproof P., of x contains an atom y, or similarly, y is in P,., if there is
an (A, x)-hyperpath where £~!(y) is in the head or tail of any edge in the hyperpath. Similarly, we
say a subproof P,, of x contains a C-term t, or t is in P,, if there is some y such that t € C(y) and
P., contains y.

Theorem 1 (Generated proofs are shortest and unique). Let R be a set of inference rules that are
C-conserving, E-monotonic, and in harmony,'® let P be an (A, hg)-proof in R UA generated by the

procedure in §C.3, and let A be the set of irrelevant axioms generated by §C.3. There does not exist
an (A’, hg)-proof P’ in R LAU A such that |P'| < |P\.

'Swith respect to both C’ and E.

22


===== PAGE BREAK =====

To prove Thm. | we introduce two lemmas. First, in Lemma 1, we show that the shortest proofs
(without irrelevant axioms) are unique. That is, for a given goal theorem and set of axioms, there is
no shortest proof that is different than the one we generate. Then, we show that the irrelevant axioms
generated in §C.3 generated through Alg. 2 can not be used to yield another shortest proof of the goal
theorem; this is done in Lemma 2. Taken together, these lemmas imply Thm. 1.

Lemma 1. Let R be a set of inference rules that is C'-conserving, A be a set of axioms. Then, for
all theorems hg in RU A such that (A, hg)-proof P could be generated by Alg. 2, we have that P
is hg’s unique shortest proof in UA.

Proof. We perform structural induction on the subproof relation =.

We first observe that P can not have cycles: By definition, a cycle contains several vertices labeled
with the same theorem. This is not possible since Alg. 2 maintains a set of already sampled theorems
SET that can never be sampled again: Specifically, line 16 excludes theorems in SET from being
sampled and line 24 adds generated theorems to SET.

Base Case. The base case is the smallest possible proof containing a single axiom that is also the
goal theorem, i.e., an (A, h,)-proof P of h, with |P| = 1. This is clearly the unique shortest proof
in this case.

Inductive Case. Consider the last hyperedge {£~1(b,), ..., 0-1(bx)} — €-1(h), ie., the hyperedge
for which the head is labeled with the goal theorem h of the subproof. The inductive hypothesis
states that for any atom x« 4 h in P, the subproof of x in P is the unique shortest (A, x)-proof in
RU A. We consider the various cases of inference rules in the logic program for the last hyperedge
and show that the unique shortest proof of the conclusion is obtained by combining the unique
shortest proofs of the premises under the inference rule corresponding to that hyperedge.

We now consider four cases.

Case 1: (Introduction). The inference rule corresponding to the last hyperedge is an instantiation
of an introduction rule:

Because there are no other introduction rules for p, C(p(t1,...,t~)) = Un, C'(b;), and the atoms
in the subproofs of the premises are disjoint, the above introduction rule is the only way to prove
p(ti, ...,t). Thus, we conclude that P is the unique shortest proof of p(t, ...,t~).

Case 2: (Elimination). The inference rule corresponding to the last hyperedge is an instantiation
of an elimination rule: 6,,...,b«—1, p(ti,..,t~) / h. Due to the restriction in the generative
process—see §C.2—the premise p(t1, ..., ty) is not expanded when generating P because it is an
axiom. Furthermore, since C(h) 9 C(b,,) = © for all premises by, it is impossible to prove h using
only the atoms in the subproofs of the premises by, ..., bx _1. In fact, since C(h) C C(p(ti, ..., t~v)),
the axiom p(t1, ...,£) must appear in any proof of h. The logic program may have other elimination
rules for the same predicate p, but since such rules are distinct due to C-conservation, those other
rules cannot be used to derive h from 61, ...,b«—-1, p(t, .., tw). Therefore, we conclude that P is
the unique shortest proof of h.

Case 3: (Union). The inference rule corresponding to the last hyperedge is an instantiation of a union
tule: bj, ...,b% F h. Since the generation procedure in §C.2 only generates hyperedges corresponding
to union rules where the premises have disjoint C’-terms, i.e., C'(b,) 1 C(b;) = @ for all k A j, and
there is no way to prove /, other than the union rule, this case is identical to Case J above.

Case 4: (Unused). The inference rule corresponding to the last hyperedge is an instantiation of an
unused rule. But the procedure in §C.2 never includes such inference rules, so this is impossible.

Lemma 2. Let R be a set of inference rules that is C-conserving, E-monotonic, and in harmony, let
(A, h,)-proof P be the proof in R U A generated by §C.3, and let A be the set of irrelevant axioms

generated by §C.3. Then, there does not exist an (A',hg)-proof P! in RU AU A such that A' # A
and |P"| < |P|.

Proof. We offer a proof by contradiction. By way of contradiction, assume there exists an (A’, hg )-
proof ?’ in RLIALIA such that A’ # A and |P’| < |P|. Take ” to be the shortest such proof. Because,

23


===== PAGE BREAK =====

by construction of the algorithm, the proof P consists of a single hyperpath starting from A. Thus,
A’ # Aimplies there exists an a € A’ where a ¢ A. Recall that P = ((V, E), @) is itself a proof
forest. Let C(P) © Ue Cle) be the set of C-terms in P, i.e., the relevant C-terms. Similarly, let
E(?) = Ue E(e) be set of H-terms in P, i.e., the relevant E-terms. We now consider two cases.

Case 1: C(a) C C(P) (The irrelevant axiom only has relevant C-terms). The generation procedure
described in §C.3 can only generate an irrelevant atom with relevant C-terms when generating proof
trees that have -terms that are distinct from those in the relevant proof. Therefore, the /-terms in the
proof containing a, i.e., the irrelevant E-terms, are disjoint from those in P, i.e., the relevant E-terms.
Take the linear chain e1, ...,ea¢ € P’ such that {a} is the tail of e; and hg is the head of en. Let hy, be
the head of edge e,,,. Select the first e,,, such that E(h,,) contains an /-term that is not relevant and
E(Am-+1) has only relevant E-terms. There must be at least one such edge since h, has only relevant
£-terms but a does not. Because R is E-monotonic, only elimination rules allow an £-term from a
premise to be absent from the conclusion, and so e,,+1 must be an instantiation of an elimination rule

and E(h) U E(b,) = E(p(ti,...,t~)), for any k. The E-terms of h,, and h,,+1 are included in
E(p(ti, ...,t~)). Thus, the premise p(¢1, ..., £7) must contain both relevant and irrelevant E-terms.
Note that in the generation procedure described in §C.3, no axiom is generated that contains both
relevant and irrelevant E-terms. Therefore, p(t1, ...,¢,) must be derived from axioms other than
a. However, because 7 is in harmony, the subproof of this premise must contain h, and so the proof
’ is not shortest, which is a contradiction.

Case 2 C(a) £ C(P) (The irrelevant axiom has an irrelevant C-term). Take the linear chain
€1,...,em € P such that {a} is the tail of e; and h, is the head of eyy. Let h,, be the head of edge
€m. Select the first e,, such that C(hm) Z C(P) and C(hm+41) C C(P). There must be at least
one such edge since h, has only relevant C-terms but a does not. Since the 7? is C-conserving, only
elimination rules allow a C-term from a premise to be absent from the conclusion, and so e;,41 must
be an instantiation of an elimination rule

and C'(h) U Us C(b;) C C(p(ti, ..., tw)). That is, the C-terms of h,, and hy,41 are included in
C(p(t1, ..., tw )). Thus, the premise p(t1, ..., tv) must contain both relevant and irrelevant C-terms.
Note that in the generation procedure described in §C.3, no axiom is generated that contains
both relevant and irrelevant C-terms. Therefore, p(t1, ...,¢) must be derived from other axioms.
However, since R is in harmony, the subproof of this premise must contain h, and so the proof P’
is not shortest, which is a contradiction.                                                                    |_|

We can now prove Thm. | using the above lemmas.

Theorem 1 (Generated proofs are shortest and unique). Let R be a set of inference rules that are
C-conserving, E-monotonic, and in harmony,'’ let P be an (A, hg)-proof in RU A generated by the

procedure in §C.3, and let A be the set of irrelevant axioms generated by §C.3. There does not exist
an (A', hg)-proof P’ in RU AU A such that |P'| < |P\.

Proof. By Lemma 1, there exists one unique shortest proof P of a goal theorem from a set of relevant
axioms and this is the proof we generate as the ground-truth proof. By Lemma 2, there will be no
additional proofs P’ where |P’| < |P| when generating irrelevant axioms through our procedure.
Therefore, all our generated proof systems have a unique shortest proof, which is identical to the
ground-truth proof that is generated through our procedure.                                                   |

D More Details on Experiments

D.1 Dataset Statistics

Here, we present more statistics on the datasets used in our experiments (§5). Fig. 4 shows the
distribution of the number of edges in the proofs in the base problems, which is equivalent to the

'7With respect to both C’ and E.

24


===== PAGE BREAK =====

Base Problem Length

1204

100 4

80 4

60 4

404

20 4
||] |) |
2 3 4 5 6 7 8 9 10 11

# Steps

# Problems

PR 2B

Figure 4: Histogram of the number of hyperedges (i.e., inference rule applications) present in the shortest proof
for the GSM programs in our dataset.

Number of Axioms

Complexity
ME Base
Ma w/ Axiom
Ml w/ Tree

ME W/ Multiple Trees
ili,

5 6 7 8 9 10 11 ADE Ae
# Axioms

# Problems
NV           Ww           £           wn           n           =           oo
oS           oS           oS           oS           o           oS           oS

S

So

Figure 5: Histogram of the total number of axioms, including irrelevant ones, per type of complexity of the GSM
programs in our dataset.

number of non-axiom theorems. The numbers range from 2 to 13.'* The distribution is skewed
towards shorter problems. This was done by design in order to prevent saturation when evaluating
models with different levels of capabilities.

Fig. 5 shows the number of axioms the GSM problems contain, including irrelevant ones. As expected,
adding one irrelevant axiom (w/ axiom) yields a distribution that is shifted by exactly one additional
axiom as compared to the base distribution. When adding a single irrelevant tree (w/ tree), the
distribution shifts further and spreads out. This trend is further amplified when adding multiple
irrelevant trees (w/ multiple trees).

D.2. Prompt
See Fig. 6 for the prompt used in our experiments.

D.3. Example Proof

In this section we give an example proof in natural language. Consider the following problem, with
the irrelevant axioms marked in bold:

Anatola has 67 keys. Ichabod has 23 packets. Clayborne has 55 crayons. Pieter
has 20 parrots. Ichabod has 30 packets less than Winnah. Pieter then gives

'8For reference, GSM8K (Cobbe et al., 2021) includes problems with 2 to 8 steps.

25


===== PAGE BREAK =====

[PROMPT 1]

You are a helpful assistant tasked with solving math word problems. You follow the formatting of the
problems and the solutions as given in the examples below.

Q: Lib possesses 20 puzzles. Shanna has 4 puzzles more than Lib. Shanna then donates 5 puzzles to Costa.
Shanna has 6 puzzles more than Valeria. Valeria has 11 puzzles more than Clementius. How many puzzles
does Clementius have totaled?

A: Let’s think step by step.

. Lib possesses 20 puzzles.

. Shanna has 4 puzzles more than Lib.

. So Shanna has 20 + 4 = 24 puzzles.

. Shanna then donates 5 puzzles to Costa.

. So Shanna has 24 - 5 = 19 puzzles.

. Shanna has 6 puzzles more than Valeria.

. So Valeria has 19 - 6 = 13 puzzles.

. Valeria has 11 puzzles more than Clementius.
. So Clementius has 13 - 11 =2 puzzles.
Therefore, the answer (arabic numerals) is 2.

OAONANSWNH

[...repeat...]

Q: Stacee owns 18 necklaces. Stacee then gets 14 more necklaces from Felic. Valencia has 11 necklaces
less than Stacee. How many necklaces does Valencia have?

A: Let’s think step by step.

[GENERATION 1]

1. Stacee owns 18 necklaces.

2. Stacee then gets 14 more necklaces from Felic.
3. So Stacee has 18 + 14 = 32 necklaces.

4. Valencia has I1 necklaces less than Stacee.

5. So Valencia has 32 - 11 = 21 necklaces.
[PROMPT 2]

Therefore, the answer (arabic numerals) is
[GENERATION 2]

21

Figure 6: Two-stage prompting method used in our experiments. We first prompt the model with in-context
examples (5-shot) and the test problem. After generation, we re-prompt the model to generate the final numerical
answer.

Yorgos 6 parrots. Clayborne has 96 crayons less than Imogene. Anatola has 55
keys less than Rahel. Dennie has 19 parrots. Dianna owns 4 parrots. The number
of parrots that Edgar has more than Pieter is the same as the difference between the
number of parrots that Dennie has compared to Dianna. Edgar has 3 parrots more
than Eddie. How many parrots does Eddie have in all?

Note that the only axioms that are relevant are the ones containing information about parrots. The
shortest proof for this problem requires the application of four inference rules and can be written in
natural language as follows:

Pieter has 20 parrots.

Pieter then gives Yorgos 6 parrots.

So Pieter has 20 - 6 = 14 parrots.

Dennie has 19 parrots.

Dianna owns 4 parrots.

So the difference between the number of parrots Dennie and Dianna have is

19-4=15.

7. The number of parrots that Edgar has more than Pieter is the same as the
difference between the number of parrots that Dennie has compared to Dianna.

8. So Edgar has 14 + 15 = 29 parrots.

9. Edgar has 3 parrots more than Eddie.

AWRWN DS

26


===== PAGE BREAK =====

10. So Eddie has 29 - 3 = 26 parrots.

In this case, employing a best-first search heuristic based on lexical overlap with the query (i.e.,
prioritizing theorems that contain information about parrots) will yield the above shortest proof.
Llama-3.1-8B-Instruct did not opt for that strategy. Instead, it generated the following, inefficient
solution to this problem:

. Anatola has 67 keys.

. Anatola has 55 keys less than Rahel.

. So Rahel has 67 + 55 = 122 keys.

. Ichabod has 30 packets less than Winnah.

. So Winnah has 23 + 30 = 53 packets.

. Clayborne has 96 crayons less than Imogene.
. So Imogene has 55 + 96 = 151 crayons.

. Pieter has 20 parrots.

. Pieter then gives Yorgos 6 parrots.

. So Pieter has 20 - 6 = 14 parrots.

. The number of parrots that Edgar has more than Pieter is the same as the
difference between the number of parrots that Dennie has compared to Dianna.

12. Dennie has 19 parrots and Dianna has 4 parrots.
13. The difference between Dennie and Dianna is 19 - 4 = 15.
14. So Edgar has 15 more parrots than Pieter.
15. Edgar has 15 + 14 = 29 parrots.
16. Edgar has 3 parrots more than Eddie.
17. So Eddie has 29 - 3 = 26 parrots.
Therefore, the answer (arabic numerals) is 26.

ee
FB OO WAN NUN FWN

D.4 Further Empirical Results

Accuracy Stratified by Agent and Entity Overlap. Fig. 7 shows further stratified results that
were mentioned in §5.1. We briefly note that these results suggest that the models might make use of
a heuristic based on such overlap. (Recall that the problem sets are otherwise identical.) One could
reasonably expect that a model could learn such a heuristic, based on previous work suggesting that
models may derive the conclusion to a proof step greedily within a forward pass before initiating the
step in the output tokens (Kudo et al., 2024; Wu et al., 2024).

Parsing Reasoning Model Outputs. Since QwQ-32B and DeepSeek-R1 did not generate output
corresponding to strings in our verbalized program, we performed a separate, more crude analysis
for those two models. Rather than matching the full generated token sequence, we match only the
arithmetic expressions. They are matched with the ground-truth expressions from the built-ins of
the corresponding inference rules. This can only be done for theorems that are not axioms, since only
those require an arithmetic built-in (i.e, arithmetic expression) to prove. Arithmetic expressions are ex-
tracted flexibly, accounting for formatting irregularities and natural language that may be interleaved.
The parser may also predict no match for a particular model output if no matches are found.

We manually verified parsing accuracy (macro-average) on model outputs over 20 randomly selected
example problems. The parser predicted the correct match (or correctly predicted no match) in 94.4%
of cases for QWQ-32B and 94.8% of cases for DeepSeek-R1.

Table 4 displays the results. We observe results that are overall consistent with the main conclusions
of the paper; even state-of-the-art models like DeepSeek-R 1—despite performing well in terms of
accuracy (Table 2)—appear to generate theorems that are irrelevant to the goal theorem. As with
the two models discussed in the main text, the efficiency scores decrease when there is agent and/or
entity overlap between the irrelevant axioms and the goal theorem.

Search Order. While our results in §5.2 suggest that LMs make use of information in the query
to prove goals, they also reveal that LMs generate irrelevant theorems. Thus, LMs appear to use
some heuristic, albeit an imperfect one, in their reasoning. Here, we present a limited analysis on
whether this heuristic could be in combination with either DFS or BFS. We do so by examining the

27


===== PAGE BREAK =====

Meta-Llama-3.1-8B-Instruct                                          Qwen2.5-Math-7B-Instruct                                                             QwQ-32B                                                                           DeepSeek-R1

w/ Axiom        w/ Tre                                                  w/ Tre                                  / Axiom        w/ Tre                                                  w/ Tre

ree W/ Multiple Trees      w/ Axiom             ree W/ Multiple Trees      wi                     ree W/ Multiple Trees      w/ Axiom             ree W/ Multiple Trees
Complexity                                                           Complexity                                                           Complexity                                                           Complexity

Accuracy
cos o
b RR & ©

°

ME ono overlap      ME entity overlap      ME agent overlap      ME agent and entity overlap

Figure 7: Results on problems with irrelevant axioms from Table 2 as average answer accuracy (%) when
stratified by different kinds of lexical overlap between the irrelevant axioms and the query. The error bars show
the 95% confidence interval using Wilson (1927) score intervals.

Non-ground Queries
None Entity Agent Both

QwQ-32B       Efficiency (non-axioms) | 77.1      63.8      72.2      63.1
DeepSeek-R1 — Efficiency (non-axioms) | 89.4      67.7      77.3      67.8

Table 4: Additional efficiency analysis for QWQ-32B and DeepSeek-R1, using a more crude parser that only
extracts arithmetic expressions corresponding to the arithmetic built-ins in Table 1. The efficiency score can
therefore only be presented for theorems that are not axioms. Results are stratified and computed in the same
way as §5.2. The differences in efficiency scores across datasets of different lexical overlaps are significant
(p < 0.001) according to one-way ANOVA analyses.

order in which intermediate theorems, both relevant and irrelevant, are generated by the LM, and
comparing this order to the respective reference orders. Furthermore, we compare the LM’s ordering
to the theorems in the shortest proof as visited in DFS order as a control.

Before presenting the results, we make note of a few limitations of this analysis. First, the only
irrelevant theorems we consider in the DFS and BFS orderings are those that are generated by Alg. 2
when sampling the axioms for the irrelevant goal theorems hy.h mo (§4.3). In addition, we note that
the in-context examples were ordered according to DFS; see §5. However, the examples were chosen
so that the ordering of theorems that are not axioms would be the same under both DFS and BFS. We
therefore ignore the axioms as we compare the orderings.

Concretely, the DFS and BFS orderings correspond to the order in which atoms are popped from the
chart C in Alg. 1, where: (i) C is implemented as a stack for DFS and a queue for BFS, (ii) the axioms
are popped from the agenda Q in the order in which they are presented (i.e., pushed) to the model in
natural language (as described in §5), and (iii) we do not include pops of axioms.

As our metric, we compute the Levenshtein distance between the sequence of indices produced by
the LM and the ground truth reference ordering under the different search orders, normalized by the
longest of the two sequences. The results are shown in Fig. 8. We observe that the models’ search
orders are closer to DFS than to BFS across all types of query overlap. Furthermore, for Llama-3.1,
they are closer to the DFS-based ordering required for the shortest proof than DFS when there is no
agent or entity overlap between the goal and the irrelevant axioms. Qwen2.5-Math appears to be less
efficient however, consistent with the results in §5.2. These findings suggest that LMs tend to follow
a depth-first exploration of the proof space in combination with the superficial heuristic. However,
future work should perform a more rigorous analysis to confirm these preliminary findings.

28


===== PAGE BREAK =====

Meta-Llama-3.1-8B-Instruct                                                                          Qwen2.5-Math-7B-Instruct

none               entity               agent         agent and entity           none               entity               agent         agent and entity
Overlap                                                                                Overlap

i  S  id  >
5  Es  be  oS

Levenshtein distance

S
i

S
i

Ml DFS   ll = BFS   ME Efficient DFS

Figure 8: Average Levenshtein distance between Llama-3.1-8B-Instruct’s search order and depth-first search
(DFS), breadth-first search (BFS), and an efficient DFS which only visits relevant theorems. The plot is based on
problems for which the model gave the correct answer. The Levenshtein distances are normalized by the length
of the longest string to take values in [0, 1]; lower values mean shorter distances.

29
