2510.24530v1 [cs.CL] 28 Oct 2025

arXiv

Levée d’ambiguités par grammaires locales

Eric Laporte *

1 Introduction

De nombreux mots sont ambigus quant a leurs catégories grammaticales :
ainsi, montre peut étre nom ou verbe. Toutefois, lorsqu’un mot apparait dans un
texte, cette ambiguité se réduit généralement beaucoup : dans Une des études
les plus importantes montre que l’expérience est critique, le mot montre ne peut
étre qu’un verbe. Un systeme d’étiquetage lexical est un systéme qui attribue
des catégories lexicales aux mots. Lever des ambiguités de catégories lexicales
consiste a utiliser le contexte pour réduire le nombre de catégories lexicales
associées aux mots. La levée des ambiguités de catégories lexicales est un des
principaux défis de l’étiquetage lexical.

Le probleme d’étiqueter les mots par des catégories lexicales se pose fréquem-
ment dans le traitement des langues naturelles, par exemple pour la correction
orthographique, la vérification grammaticale ou stylistique, la reconnaissance
d’expressions, la phonétisation, l’analyse de corpus de textes... En analyse syn-
taxique, l’étiquetage correct des mots fait partie des résultats de l’analyse, mais
si on a préalablement affecté les mots de leurs catégories lexicales, le reste de
Vanalyse en est souvent facilité (Milne, 1986 ; Hindle, 1989 ; Rimon, Herz, 1991;
Cutting et al., 1992). Les grands corpus désambiguisés sont une vaste source
d’informations utiles dans de nombreuses applications, et sont notamment mis
a contribution pour l’apprentissage des systémes probabilistes, mais leur éti-
quetage manuel est lent, cofiteux et source d’erreurs. Les systémes d’étiquetage
lexical sont ainsi utiles comme composant initial de nombreux systémes de trai-
tement de langues naturelles.

2 Méthodologie

2.1 Les étiquettes lexicales

Un systeme d’étiquetage lexical attribue a chaque forme d’un texte une ou
plusieurs étiquettes, c’est-a-dire des codes qui renferment des informations lexi-
cales. Si ces informations se réduisent a la catégorie grammaticale, on compte
de 10 a 20 catégories lexicales. Si elles incluent d’autres données grammati-
cales, les catégories lexicales sont plus fines et plus nombreuses. Ces données
grammaticales peuvent comporter :

— la forme canonique, par exemple montrer pour montrée, ou les informa-

tions requises pour la reconstituer 4 partir de la forme trouvée dans le

*Institut Gaspard-Monge, Université de Marne-la-Vallée, 2, rue de la Butte-Verte, F-93166
Noisy-le-Grand CEDEX, France.


===== PAGE BREAK =====

texte ;

— les traits flexionnels : temps, personne, genre, nombre... ;

— la délimitation des mots composés, c’est-a-dire des séquences figées com-
portant plusieurs mots simples séparés par des séparateurs graphiques,
comme bien stir ou traitement de texte. Dans ce cas, les composés sont
étiquetés en tant que tels, par exemple Adverbe pour bien stir.

— Si les étiquettes donnent explicitement les formes canoniques, et aussi les
codes de flexion (les numéros de conjugaison par exemple), toute forme
peut étre déduite de son étiquette.

Dans la levée d’ambiguités lexicales, on prend rarement en compte les infor-
mations de plus haut niveau, telles que la relation syntaxique avec le prédicat
(Koskenniemi, 1990).

Le corpus étiqueté Brown utilise un ensemble de 87 étiquettes simples (Gar-
side, Leech, Sampson, 1987, pp. 165-183) réutilisé dans d’autres projets. Pour
le francais, un ensemble d’étiquettes qui donne seulement la catégorie gramma-
ticale et les traits flexionnels a 4 peu prés la méme taille. Dans cet article, nous
décrivons des expériences en francais avec des catégories lexicales qui incluent la
forme canonique dans les informations lexicales, 4 la fois pour les mots simples
et pour les mots composés. La taille de l’ensemble d’étiquettes est ainsi celle
d’un dictionnaire de la langue.

2.2 La forme du texte désambiguisé

La plupart des systémes de levée d’ambiguités produisent pour un texte
donné une séquence de paires mot/étiquette : chaque mot recoit une étiquette
unique. Ce choix peut a priori s’appuyer sur deux présupposés :

1. qu’il est possible de mettre au point un systeme d’étiquetage lexical qui

affecte une étiquette unique 4 chaque mot sans aucune erreur ;

2. ou que le fait d’attribuer 4 un mot dans un texte une seule étiquette
fausse n’est pas un défaut sérieux d’un systéme d’étiquetage lexical.

L’affirmation 1 n’a pas un statut clair, sauf a considérer un analyseur syntaxique
comme un module d’un systéme d’étiquetage lexical au lieu de l’inverse : méme si
Vensemble d’étiquettes est rudimentaire, l’étiquetage lexical correct de certaines
phrases naturelles met en jeu la reconnaissance de leur structure syntaxique
globale ou méme la compréhension de leur sens. L’affirmation 2 est également
contestable, surtout dans le contexte de l’analyse syntaxique : il est parfois
impossible de corriger 4 la main les sorties d’un systéme d’étiquetage lexical ; or
il est naturel qu’un analyseur syntaxique élimine des hypothéses, il lest moins
qu’il en crée de nouvelles avec des catégories grammaticales différentes de celles
de départ. De plus, si on étiquette chaque mot d’une fagon unique, méme les
phrases effectivement ambigués sont représentées comme non ambigués.

Un certain nombre de systémes récents d’étiquetage lexical (Silberztein,
1989; Koskenniemi, 1990; Rimon, Herz, 1991; Roche, 1992) produisent, au
contraire, plusieurs solutions lorsque le texte est lexicalement ambigu ou que
Vunique solution correcte ne peut pas étre trouvée. Ces contributions visent 4
garantir un taux de silence nul : la ou les étiquettes correctes pour un mot ne
doivent jamais étre éliminées. Cet objectif est rarement évoqué en-dehors de ces
auteurs, et peu réaliste pour les systémes qui étiquettent chaque mot de fagon
unique, 4 moins de postuler le présupposé 1.


===== PAGE BREAK =====

traverse
Nom

il

Pronom
traverse
Verbe

FIGURE 1 — un automate acyclique pour II traverse le chemin de fer.

Les étiquettes des mots d’une méme phrase ne sont pas indépendantes, c’est
pourquoi le résultat d’un systéme a plusieurs solutions pour une séquence don-
née de mots est un ensemble d’une ou plusieurs séquences d’étiquettes. L’en-
semble des séquences d’étiquettes sélectionnées pour une séquence d’entrée don-
née est représenté sous une forme appropriée. Comme il s’agit d’un ensemble
fini de séquences qui ont généralement beaucoup en commun, cette forme est
toujours celle d’un automate fini acyclique, également appelé graphe orienté
acyclique (DAG ou DAWG en anglais), machine a états finis ou réseau a états
finis (Koskenniemi, 1990), graphe de phrase (Rimon, Herz, 1991) ou treillis de
mots (Vosse, 1992). Un des avantages des automates acycliques dans ce contexte
est qu’ils permettent de systématiser la représentation des ambiguités lexicales.
Ils sont en effet utilisables avant comme aprés la levée des ambiguités, et que
celles-ci soient liées aux catégories grammaticales, aux traits flexionnels, ou a la
délimitation des composés (pour représenter la distinction entre un composé et
une séquence de mots simples). La figure 1 illustre ’ambiguité entre catégories
grammaticales pour traverse et l’ambiguité entre composé et mots simples pour
chemin de fer.

2.3 Etiquetage initial et levée d’ambiguités

La plupart des systémes d’étiquetage lexical divisent la taéche en deux étapes :
en premier lieu, lors d’un étiquetage initial, les formes sont considérées indépen-
damment de leur contexte pour dresser la liste de toutes les étiquettes pour
chaque mot; ensuite, lors de la levée d’ambiguités, on prend en compte le
contexte pour sélectionner une partie de l’ensemble des séquences étiquetées
initiales.

Dans d’autres systémes d’étiquetage lexical (Klein, Simmons, 1963 ; Derma-
tas, Kokkinakis, 1989; Pelillo, Refice, 1991; Brill, 1992; Federici, Pirrelli, 1992),
les deux sous-taches sont effectuées en méme temps et un résultat désambiguisé
est construit directement, généralement pour éviter la construction d’un grand
dictionnaire.

Plusieurs arguments viennent en faveur de la solution modulaire. Les deux
sous-taches sont clairement définies. Une fois choisi un ensemble d’étiquettes
lexicales, les deux sous-taches sont indépendantes. Il peut en étre de méme des
méthodes permettant de les effectuer avec les meilleurs résultats : perfection-
ner |’étiquetage initial est un probleme de description morphologique des mots,
améliorer la levée des ambiguités met en jeu la description grammaticale de
séquences de mots.

Cette solution est cohérente avec l’utilisation d’automates acycliques pour
représenter les ambiguités lexicales. Aprés l’étiquetage initial, l’ensemble des
séquences reconnues par l’automate est l’ensemble des séquences d’étiquettes


===== PAGE BREAK =====

possibles a priori pour la séquence d’entrée. Lors de la levée d’ambiguités, l’au-
tomate est modifié. Le nombre de séquences reconnues par l’automate diminue,
mais le nombre d’états et de transitions dans l’automate peut croitre ou dé-
croitre.

La solution modulaire a bien stir un intérét particulier si l’on dispose d’un
dictionnaire morphologique fiable qui donne pour chaque forme, simple ou com-
posée, la liste des étiquettes possibles. Dans ce cas, l’étiquetage initial est simple-
ment mené a bien par une consultation du dictionnaire. Un tel environnement
pour le francais a été développé au LADL! et au CERIL? avec les diction-
naires DELAF (Courtois, 1990) et DELACF (Silberztein, 1990), et avec les
algorithmes de compression et de consultation mis en ceuvre par Revuz (1991)
et Roche (1992) pour obtenir de meilleures performances qu’avec les arbres
lexicographiques (tries) de Knuth (1973). Il est maintenant intégré au systéme
d’analyse lexicale INTEX (Silberztein, 1993). La taille du dictionnaire comprimé
est inférieure 4 900 Ko pour 700.000 formes.

2.4 Données élaborées a la main ou données statistiques

Les informations utilisées par les systemes d’étiquetage lexical pour lever
des ambiguités consistent soit en connaissances grammaticales formalisées a la
main, soit en données statistiques acquises par apprentissage automatique dans
un grand corpus de textes. Le systéme de Hindle (1989) utilise un mélange
des deux. Comme exemples de systémes d’étiquetage lexical qui utilisent des
données grammaticales élaborées 4 la main, on peut citer ceux de Klein, Sim-
mons (1963), Hindle (1983), Silberztein (1989), Paulussen, Martin (1992), Roche
(1992). Dans le cas de Rimon, Herz (1991), les données sont produites automa-
tiquement a partir de grammaires algébriques faites 4 la main. Dans toutes ces
contributions, les données grammaticales sont formalisées dans des automates
finis, ou pourraient facilement l’étre. Nous désignons ces données par le nom de
grammaires locales, car elles ne constituent jamais une grammaire complete de
la langue. L’étiquetage lexical a partir de statistiques est représenté par Greene,
Rubin (1971), Hindle (1989), Brill (1992), Federici, Pirrelli (1992), qui utilisent
des régles produites par des processus statistiques; et par Marshall (1983), Je-
linek (1985), DeRose (1988), Cutting et al. (1992), etc., qui utilisent des tables
de statistiques, par exemple des paramétres de modeéles de Markov. Toutes ces
contributions donnent 4 chaque mot une étiquette unique.

Les arguments pour ou contre ces deux types de méthodes tiennent sou-
vent a leur capacité a faire face a la variété qui caractérise le texte réel dans
toute sa généralité. Certains doutent que des connaissances linguistiques élabo-
rées a la main puissent tenir compte de tout ce qui peut se présenter dans du
texte. D’autres pensent que des informations apprises automatiquement dans
un corpus, méme vaste et soigneusement composé d’échantillons variés de types
de textes, ne sont pas assez précises pour de nouveaux textes. L’utilisation de
connaissances linguistiques élaborées a la main nous semble en tous cas mieux
adaptée pour atteindre l’objectif d’un taux de silence nul, c’est-a-dire pour ga-
rantir qu’une analyse n’est éliminée que si elle est sans aucun doute incorrecte.
L’auteur des données linguistiques peut s’aider d’un corpus de textes, mais doit
pouvoir créer des contre-exemples qui n’y figurent pas, de sorte que les données

1. Laboratoire d’automatique documentaire et linguistique, Université Paris 7, 2, place
Jussieu, F-75252 Paris CEDEX 05, France.
2. Centre d’études et de recherches en informatique linguistique, Institut Gaspard-Monge.


===== PAGE BREAK =====

linguistiques qu’il élabore soient indépendantes de ce corpus.

La suite de cet article concerne une méthode de levée d’ambiguités lexi-
cales adaptée 4 l’objectif d’un taux de silence nul (Silberztein, 1989, 1993) et
mise en ceuvre dans le systeme INTEX de Silberztein (1993). Nous présentons ici
une description formelle de cette méthode. Elle combine la possibilité de plu-
sieurs solutions — le résultat produit pour une séquence de mots donnée est
un automate acyclique —, le parti pris modulaire — l’étiquetage lexical et la
levée des ambiguités sont considérés comme indépendants une fois choisi un en-
semble d’étiquettes —, et l'utilisation de connaissances linguistiques élaborées
a la main, pour |’étiquetage initial — de grands dictionnaires morphologiques
— comme pour la levée des ambiguités — des données grammaticales appelées
grammaires locales. La seule autre contribution qui rentre dans ce cadre est, a
notre connaissance, celle de Roche (1992). Toutes les deux comprennent des al-
gorithmes et leur mise en ceuvre et elles utilisent les mémes dictionnaires. Pour
une comparaison entre ces deux systémes, cf. Laporte (1994).

3 Les étiquettes lexicales dans INTEX

3.1 Etiquettes grammaticales complétes

La confrontation d’un texte avec les dictionnaires produit plusieurs séquences
détiquettes grammaticales en raison des ambiguités lexicales. Ainsi, pour la
phrase Je ne me le suis pas fait confirmer sur le moment, on obtient l’étique-
tage initial suivant :

("je.” + "je.PRO :1s”)

("ne.” + "ne.XIP + *ne.XI[+ Préd]”)

*me.PRO :1s”

("le.DET :ms” + "le.PRO :3ms”)

("étre.V :P1s” + "suivre.V :P1s :P2s :Y2s”)

("pas.ADV” + ”pas.N :ms :mp” + ”pas.XI’)

(faire. V :Kms :P3s” + ”fait.A :ms” + ”fait.N :ms” + ”fait.XI[+
Préd]”)

*confirmer. V :W”

(

*sur/le/moment.ADV ;PDETC”

+

("sur.A :ms” + ”sur.PREP”)

("le.DET :ms” + "le.PRO :3ms”)

*moment.N :ms”

)

Les unités de base d’INTEX donnent la forme canonique (mot simple ou mot
composé), la catégorie grammaticale, et les traits flexionnels s’ils sont perti-
nents. Nous les appellerons étiquettes grammaticales completes et nous les no-
terons comme dans les exemples suivants : <suivre V :P2s>, <sur/le/moment
ADV ;PDETC>, <coup/fumant N;NA :ms>...

3.2 Etiquettes grammaticales incomplétes

Le systéme de levée d’ambiguités grammaticales d’INTEX utilise un autre
ensemble d’étiquettes lexicales que nous appellerons étiquettes grammaticales


===== PAGE BREAK =====

incomplétes et qui peuvent spécifier
— une forme canonique : <prendre>, <le>, <coup/fumant>...
— une catégorie grammaticale : <V>, <ADV>, <A>...
— une forme canonique et des traits flexionnels pertinents pour cette forme :
<prendre :P3s>, <prendre :P>, <prendre :s>, <coup/fumant :ms>...
— une catégorie grammaticale et des traits flexionnels pertinents pour cette
catégorie: <V :P3s>, <V :P>, <V :s>, <N :ms>...
— une forme simple : vient, aussitét, fait...
— L’étiquette <MOT> représente toutes les formes simples, a l’exclusion
des formes composées.
Une étiquette grammaticale incomplete sert 4 représenter l’ensemble des éti-
quettes grammaticales completes qui satisfont aux informations qu’elle spécifie.
Exemples :

<prendre> représente toutes les formes du verbe prendre
<A> représente tous les adjectifs 4 toutes les formes

suis représente toutes les étiquettes lexicales possibles de suis, c’est-
a-dire une forme du verbe étre et trois formes du verbe suture.

En d’autres termes, une étiquette grammaticale complete est ou n’est pas conforme
a une étiquette grammaticale incomplete. Exemples :

<suivre V :P2s> est conforme a <suivre> et a <V>

<étre V :P1s> est conforme a4 <étre> et A <V :P>

<suivre V :P2s> n’est pas conforme a < étre> car la forme canonique

ne correspond pas

<coup/fumant N;NA :ms> nest pas conforme 4 <MOT> car c’est

une forme composée

<suivre V :P1s> et <suivre V :P2s> sont conformes a suis

<étre V :P1s> est conforme a suis

4 Grammaires locales de levée d’ambiguités

Dans le systeme INTEX, la levée d’ambiguités lexicales met en jeu des infor-
mations linguistiques élaborées 4 la main. Ces informations sont spécifiées sous
la forme d’un ou plusieurs transducteurs appelés grammaires locales de levée
d’ambiguités. On peut voir une telle grammaire locale comme un moyen formel
de spécifier un ensemble de séquences grammaticales acceptées. Un algorithme
de levée d’ambiguités applique la grammaire 4 un texte, ce qui consiste a sélec-
tionner parmi les étiquetages grammaticaux du texte ceux qui sont conformes a
la grammaire. L’intérét de ce systeme est qu’il permet de spécifier des ensembles
de séquences grammaticales tout 4 fait complexes a l’aide de grammaires rela-
tivement petites, lisibles et intuitives. Il est important que les grammaires ne
rejettent jamais une séquence grammaticale correcte. En revanche, on est loin
de disposer d’une grammaire qui n’accepte que les séquences correctes.

Nous utilisons l’éditeur d’automates Editor de Max Silberztein pour re-
présenter graphiquement les transducteurs de levée d’ambiguités (exemple : le
transducteur T,, figure 2). Chaque transition comporte deux étiquettes gram-
maticales incomplétes, une dite “d’entrée” (dans la boite) et une “de sortie”
(sous la boite). Dans un transducteur, une séquence d’entrée est une séquence


===== PAGE BREAK =====

)- [se ce Dane Pie P—$ Ine Pr] me Pe P—-O)

<PREP> <PRO> <CNJS> <PRO> <XI><PRO> <PRO>

FIGURE 2 — le transducteur T}.

détiquettes grammaticales d’entrée. Le transducteur sert 4 mettre en relation
des séquences d’entrée et des séquences de sortie. Par exemple, le transducteur
T, (figure 2) met en relation la séquence d’entrée

de ce que je ne me le

et la séquence de sortie
<PREP> <PRO> <CNJS> <PRO> <XI> <PRO> <PRO>

Grosso modo, les séquences d’entrée servent 4 sélectionner les portions du texte
auxquelles la grammaire locale va s’appliquer, et les séquences de sortie imposent
des contraintes a ces portions de texte. Pour s’assurer qu’une grammaire ne
rejettera pas de séquences grammaticales correctes, on a besoin d’une régle plus
précise pour répondre a la question : étant donné une séquence grammaticale
compléte et une grammaire locale de levée d’ambiguités, la grammaire accepte-
t-elle la séquence ?

4.1 Cas ot les séquences d’entrée du transducteur ne sont
constituées que de formes simples

Dans ce premier cas particulier, on a une regle plus simple que dans le cas
général. Nous illustrerons cette régle en prenant l’exemple du transducteur T,
(figure 2) et de la séquence grammaticale complete

<cela PRO :ms> <venir V :P3s> <de PREP> <ce PRO :3s> <que
CNJIS> <je PRO :1s> <ne XI> <me PRO :1s> <le PRO :3ms>
<étre V :Pis> <pas ADV> <faire V :Kms> <confirmer V :W>
<aussit6t ADV>

Cette séquence est l’étiquetage grammatical correct de
Cela vient de ce que je ne me le suis pas fait confirmer aussitot
La grammaire accepte la séquence si et seulement si on peut diviser la sé-

quence en portions qui sont chacune de l’un ow de l’autre des deux types sui-
vants :

1. la portion est conforme a la fois 4 une séquence d’entrée et & une séquence
de sortie associées par le transducteur.

2. la portion est réduite a une seule étiquette grammaticale complete, peu
importe laquelle, mais le texte qui commence a ce mot n’apparait dans
aucune séquence d’entrée du transducteur.

Dans cet exemple (table 1), les deux premiéres portions sont du type 2 :

<cela PRO :ms> et <venir V :P3s>. La suivante est du type 1:

<de PREP> <ce PRO :3s> <que CNJS> <je PRO :1s> <ne XI>

<me PRO :1s> <le PRO :8ms>
Toutes les autres sont du type 2. Finalement cette séquence est acceptée par la
grammaire.


===== PAGE BREAK =====

Séquences d’entrée | Séquence gramm.     Séquences de sortie
du transducteur     complete                  du transducteur
—            <cela PRO :ms>              —

—            <venir V :P3s>               —

de           <de PREP>               <PREP>
ce           <ce PRO :3s>             <PRO>
que         <que CNJS>            <CNJS>
je           <je PRO :1s>             <PRO>
ne            <ne XI>                     <XI>
me           <me PRO :1s>            <PRO>
le           <le PRO :3ms>           <PRO>
—           <étre V :P1s>               —

—             <pas ADV>                    —

-           <faire V :Kms>              -
-            <confirmer V :W>            —
-             <aussitot ADV>                -

TABLE 1 — une séquence grammaticale acceptée par le transducteur 7.

<PRO>                 <PRO>

FIGURE 3 — le transducteur T>.

On notera que la condition 2 ci-dessus met en jeu non pas seulement |’éti-
quette grammaticale complete qui figure dans la portion considérée, mais aussi
les autres étiquettes complétes associables au méme mot, et éventuellement les
étiquettes des mots qui le suivent. L’écriture de grammaires locales de levée
d’ambiguités s’apparente a la programmation mais nécessite aussi de l’intuition
grammaticale, pour imaginer les séquences grammaticales qu’une grammaire va
rejeter.

4.2 Deuxiéme cas particulier

En fait, une régle tres voisine reste valable pour de nombreux autres trans-
ducteurs. Il s’agit des transducteurs dont chaque transition vérifie ’une des deux
conditions suivantes :

— Vétiquette en entrée est une forme simple,

— ou bien toute étiquette grammaticale compléte conforme a l’étiquette de

sortie est conforme a l’étiquette d’entrée.
Par exemple, c’est le cas pour le transducteur T> (figure 3) et pour toutes les
grammaires locales de levée d’ambiguités du chapitre 8 de Silberztein (1993).
La regle est alors la suivante.

La grammaire accepte la séquence si et seulement si on peut diviser la sé-
quence en portions qui sont chacune de l’un ow de l’autre des deux types sui-


===== PAGE BREAK =====

Séquences d’entrée | Séquence gramm. | Séquences de sortie

du transducteur     complete               du transducteur
-            <ne XI/+ Préd/>             -
<V>-         <faire V :P8s>-         <V :3s>

il            <il PRO :8ms>           <PRO>
—             <le DET :mp>               —
-           <compte N :mp>           —
-          <que CNJS>              —

TABLE 2 — une séquence grammaticale acceptée par le transducteur T>.

)—${fne) [=)——@

<XiI>                      <V>

FIGURE 4 — le transducteur T3.

vants :

1. la portion est conforme a la fois 4 une séquence d’entrée et 4 une séquence
de sortie associées par le transducteur.

2. la portion est réduite a une seule étiquette grammaticale complete, peu
importe laquelle, mais le texte qui commence a ce mot n’admet aucun éti-
quetage grammatical qui corresponde 4 une séquence d’entrée du trans-
ducteur.

Nous illustrons cette régle avec Ty et la séquence grammaticale

<ne XI[+ Préd/> <faire V :P3s>-<il PRO :3ms> <le DET :mp>
<compte N :mp> <que CNJS>

qui est une partie de l’étiquetage correct de
Ne fait-il les comptes que pour rendre service ?

Dans cet exemple (table 2), <il PRO :3ms> <le DET :mp> n’est pas comparé
aux séquences d’entrée de la grammaire, car deux portions ne peuvent pas se
chevaucher.

Il n’est pas absurde d’avoir des transitions dans lesquelles l’étiquette d’entrée
est la méme que l’étiquette de sortie. Par exemple, le transducteur T3 (figure 4)
accepte la séquence ci-dessus mais la rejette si on remplace <faire V :P3s> par
<fait N :ms> (table 3).

En effet, la portion <ne XI/+ Préd/> <fait N :ms> n’est conforme ni a la
séquence d’entrée ni a la séquence de sortie, alors que le texte ne fait admet
un autre étiquetage grammatical conforme a la séquence d’entrée : <ne XI>
<faire V :P3s>. Il n’existe donc aucun découpage en portions qui satisfasse aux
conditions de la regle ci-dessus.

5 Combinaisons de grammaires locales

INTEX permet d’appliquer plusieurs grammaires locales de levée d’ambigut-
tés a un méme texte. Dans ce cas, tout se passe comme si on avait combiné


===== PAGE BREAK =====

Séquences d’entrée | Séquence gramm. | Séquences de sortie

du transducteur     compleéte               du transducteur
ne        <ne XI/+ Préd/>       <XI>
<V>         <fait N :ms>-             <V>

-            <il PRO :8ms>              -
-          <le DET :mp>            —
—           <compte N :mp>           -
-          <que CNJS>              -

TABLE 3 — une séquence grammaticale rejetée par le transducteur T3.

<PRO>      <PRO>

FIGURE 5 — le transducteur T>|T3.

les différents transducteurs en leur donnant le méme état initial et le méme
état final. Par exemple, la combinaison de T> (figure 3) et de T3 (figure 4),
notée T>|T3, est représentée figure 5. Les régles ci-dessus s’appliquent alors a
Vensemble.

Si une grammaire locale rejette une séquence grammaticale, et si on combine
la grammaire avec une autre, la combinaison obtenue peut accepter la séquence.
Par exemple, le transducteur T3 rejette a tort la séquence

<ne XI> <lui PRO :8s> <dire V :Y2s> <pas ADV>

qui est l’étiquetage correct de Ne lui dis pas, a cause du fait que lui est aussi une
forme du verbe luire : <luire V :Kms>. Pour tenter de corriger ce défaut, on
peut combiner T3 avec T, (figure 6). La séquence correcte ci-dessus est acceptée
par T, et aussi par la combinaison T3|T4 (table 4).

Inversement, la séquence incorrecte

<ne XI> <luire V :Kms> <dire V :Y2s> <pas ADV>

est rejetée par T, mais acceptée par la combinaison T3|T4.

Si deux grammaires locales acceptent une méme séquence grammaticale, la
combinaison des deux grammaires peut rejeter la séquence. Par exemple, les

)        [ne )              Ee)            ©)

<XI>        <PRO>

FIGURE 6 — le transducteur T4.

10


===== PAGE BREAK =====

Séquences d’entrée

Séquence gramm.

Séquences de sortie

du transducteur     complete               du transducteur
ne            <ne XI>                   <XI>
lui           <lui PRO :3s>

<dire V :Y2s>

<PRO>

<pas ADV>

TABLE 4 — une séquence grammaticale acceptée par le transducteur T3|T4.

Séquences d’entrée
du transducteur

Séquence gramm.
compleéte

Séquences de sortie
du transducteur

ne            <ne XI/+ Préd/>          <XI>
<V>         <faire V :P8s>-           <V>

il           <il PRO :8ms>          <PRO>

les           <le DET :mp>           <PRO>

<compte N :mp>

<que CNJS>

TABLE 5 — une séquence grammaticale rejetée par le transducteur T>|T3.

transducteurs T> et T3 acceptent tous les deux la séquence correcte

<ne XI/+ Préd/> <faire V :P3s>-<il PRO :3ms> <le DET :mp>
<compte N :mp>
mais la combinaison T>|T3 (figure 5) la rejette (table 5).

Si deux grammaires locales rejettent une méme séquence grammaticale, la
combinaison des deux grammaires peut accepter la séquence. Par exemple, cha-
cun des deux transducteurs Ts (figure 7) et Ts (figure 8), utilisé séparément,
rejette la séquence incorrecte

<pourquot ADV> <me PRO :3s> <presser V :P3p>-<il PRO :3ms>

<de PREP> <le PRO :3ms> <luire V :Kms> <dire V :W>,
qui est un étiquetage du texte incorrect

Pourquoi me pressent-il de le lui dire ?
Mais la combinaison T;|Tg accepte cette méme séquence (table 6).

On voit que pour vérifier une grammaire locale de levée d’ambiguités, il ne

suffit pas de considérer les chemins du transducteur séparément : on a besoin de
vérifier leurs interactions. De méme, si on utilise une combinaison de plusieurs

<PRO>

<PRO>

FIGURE 7 — le transducteur T;.

11


===== PAGE BREAK =====

| de)

<PREP>

ap

<V:3s>          <PRO>

FIGURE 8 — le transducteur T¢.

Séquences d’entrée | Séquence gramm.     Séquences de sortie
du transducteur     complete                 du transducteur
-              <pourquot ADV>               —
me           <me PRO :8s>            <PRO>

<V>          <presser V :P3p>-          <V>
-            <il PRO :3ms>                -
de           <de PREP>              <PREP>
le            <le PRO :3ms>           <PRO>
—           <luire V :Kms>              —
—           <dire V :W>                —

TABLE 6 — une séquence grammaticale acceptée par le transducteur T5|To.

transducteurs, on ne peut pas prévoir le résultat en les considérant isolément
les uns des autres.

6 Cas général

Etant donné une séquence grammaticale compléte et une grammaire locale
de levée d’ambiguités, la grammaire accepte-t-elle la séquence ? Contrairement
aux régles données plus haut, la régle ci-dessous répond a cette question dans
le cas général.

Pour énoncer cette régle on a besoin de la notion suivante : deux séquences
grammaticales completes sont équivalentes si et seulement si elles décrivent le
méme texte avec la méme délimitation des mots simples et des mots composés.
Par exemple,

<superbe N :fs> <gaulliste A :fs>

et
<superbe A :fs> <gaulliste N :fs>
sont équivalents, mais
<pomme/de/terre N;NDN :fs> <cuire V :Kfs>
et
<pomme N :fs> <de PREP> <terre/cuite N;NA :fs>

ne le sont pas.
La grammaire accepte la séquence si et seulement si on peut diviser la sé-
quence en portions qui sont chacune de l’un des deux types suivants :

12


===== PAGE BREAK =====

)—[ana)

<PRO>

a)

<XiI>

s)

FIGURE 9 — le transducteur T7.

Séquences gramm.
compl. reconnues

Séquences d’entrée
du transd. (w)

Séquence gramm.
complete

Séquences de sortie
du transd. (v)

<mais CNJC>

<aucun DET :ms>
<ne XI>

<DET>
ne

<aucun PRO :ms>
<ne XI>

<PRO>
<XI>

<pouvoir V :P3s>-

<dépasser V :W>

<ce DET :fs>

<limite N :fs>

TABLE 7 — une séquence grammaticale acceptée par le transducteur T7.

1. la portion est conforme 4 une séquence de sortie uv du transducteur ; la
portion est équivalente 4 une séquence grammaticale complete conforme
a une séquence d’entrée u associée a v par le transducteur.

2. la portion est réduite a une seule étiquette grammaticale complete, peu
importe laquelle, mais le texte qui commence a ce mot n’admet aucun éti-
quetage grammatical qui corresponde 4 une séquence d’entrée du trans-
ducteur.

Exemple : le transducteur T7 (figure 9) accepte la séquence

<mais CNJC> <aucun PRO :ms> <ne XI> <pouvoir V :P3s>
<dépasser V :W> <ce DET :fs> <limite N :fs>

qui est l’étiquetage correct de
Mais aucun ne peut dépasser cette limite

(table 7). En revanche, sion remplace <aucun PRO :ms> par <aucun DET :ms>
dans la séquence grammaticale, on obtient une séquence qui est rejetée par T7.

7 Conclusion

Lorsqu’on examine l|’étiquetage initial d’un texte tel qu’il est produit par
INTEX, comme dans la section 3.1, des idées de réegles de levée d’ambiguités
viennent spontanément. Ces idées se présentent parfois sous une forme telle que

Si le déterminant du est suivi par un verbe, ce verbe ne peut étre

qu’au participe présent,
c’est-a-dire avec une condition qui reconnait une configuration grammaticale, et
une contrainte grammaticale 4 imposer lorsque la condition est remplie. II est
facile de concevoir et de réaliser une premiére version d’une grammaire locale a
partir d’une telle idée. Les régles que nous avons citées (sections 4 et 6) pour
décider si une grammaire donnée accepte une séquence donnée ne sont guére
utiles 4 ce stade, car le fonctionnement du systéme est plus intuitif que ces
régles ne le laissent penser.

13


===== PAGE BREAK =====

Toutefois, les intuitions grammaticales peuvent se révéler inexactes, a cause
bien souvent d’une construction ou d’une ambiguité a laquelle on n’aura pas
pensé. Puisque nous nous sommes fixé l’objectif d’un taux de silence nul, les
grammaires locales doivent étre testées avec soin. C’est la qu’il est nécessaire de
savoir en détail ce que fera une grammaire une fois appliquée a des textes.

Références

Brill, Eric. 1992. "A Simple Rule-Based Part of Speech Tagger”, 3rd Applied
ACL, Trente (Italie), pp. 152-155.

Courtois, Blandine. 1990. ”Un systéme de dictionnaires électroniques pour les
mots simples du francais”, in Langue frangaise 87, Dictionnaires électroniques
du francais, Paris : Larousse, pp. 11-22.

Cutting, Doug, Julian Kupiec, Jan Pedersen, Penelope Sibun. 1992. ”A practical
part-of-speech tagger”, 3rd Applied ACL, Trente (Italie), pp. 133-140.

Dermatas, E., G. Kokkinakis. 1989. “A System for Automatic Text Labelling”,
Eurospeech 89, pp. 382-385.

DeRose, Stephen J. 1988. “Grammatical Category Disambiguation by Statistical
Optimization”, Computational Linguistics, vol. 14, no. 1, pp. 31-39.

Federici, Stefano, Vito Pirrelli. 1992. ”A Bootstrapping Strategy for Lemmati-
zation : Learning Through Examples”, Papers in Computational Lexicography.
COMPLEX 92, F. Kiefer, G. Kiss, J. Pajzs, éds., Institut de linguistique de
l’ Académie hongroise des sciences, Budapest, pp. 123-135.

Garside, Roger, Geoffrey Leech, Geoffrey Sampson. 1987. The Computational
Analysis of English, Londres : Longman.

Greene, Barbara, Gerald Rubin. 1971. Automated Grammatical Tagging of En-
glish, Rapport technique, Département de linguistique, Brown University, Pro-
vidence, Rhode Island.

Hindle, Donald. 1983. ”Deterministic parsing of syntactic non-fluencies”, 21st
Annual Meeting of the Association for Computational Linguistics. Proceedings
of the Conference.

Hindle, Donald. 1989. ”Acquiring disambiguation rules from text”, 27th Annual
Meeting of the Association for Computational Linguistics. Proceedings of the
Conference, pp. 118-125.

Jelinek, F. 1985. “Markov source modeling of text generation”, in Impact of
Processing Techniques on Communication, J.K. Skwirzinski, éd., Dordrecht.

Klein, S., R.F. Simmons. 1963. “A Computational Approach to Grammatical
Coding of English Words”, JACM 10, pp. 334-347.

Knuth, Donald. 1973. The Art of Computer Programming, Addison-Wesley.

Koskenniemi, Kimmo. 1990. ”Finite-state parsing and disambiguation”, Procee-
dings of COLING 90, H. Karlgren, éd., Université d’Helsinki, pp. 229-232.

Laporte, Eric. 1994. "Experiments in lexical disambiguation using local gram-

14


===== PAGE BREAK =====

mars”, Papers in Computational Lexicography. COMPLEX 94, Institut de lin-
guistique de l’Académie hongroise des sciences, Budapest, 10 p.

Marshall, Ian. 1983. “Choice of Grammatical Word-Class Without Global Syn-
tactic Analysis : Tagging Words in the LOB Corpus”, Computers in the Huma-
nities 17, pp. 139-150.

Milne, Robert. 1986. ”Resolving Lexical Ambiguity in a Deterministic Parser”,
Computational Linguistics, vol. 12, no. 1, pp. 1-12.

Paulussen, Hans, Willy Martin. 1992. "DILEMMA-2 : a Lemmatizer-Tagger for
Medical Abstracts”, 3rd Applied ACL, Trente (Italie), pp. 141-146.

Pelillo, Marcello, Mario Refice. 1991. "Syntactic disambiguation through relaxa-
tion processes”, E'urospeech 91, vol. 2, pp. 757-760.

Revuz, Dominique. 1991. Dictionnaires et lexiques, méthodes et algorithmes,
Thése de doctorat, Publication 91-44 du LITP, Université Paris 7, 105 p.

Rimon, Mori, Jacky Herz. 1991. ”The recognition capacity of local syntactic
constraints”, 5th Conference of the European Chapter of the ACL. Proceedings
of the Conference, Berlin, pp. 155-160.

Roche, Emmanuel. 1992. ”Text disambiguation by finite-state automata, an al-
gorithm and experiments on corpora”, in COLING-92, Proceedings of the Confe-
rence, Nantes.

Silberztein, Max. 1989. Dictionnaires électroniques et reconnaissance lexicale
automatique, Thése de doctorat, LADL, Université Paris 7, 176 p.

Silberztein, Max. 1990. ”Le dictionnaire électronique des mots composés”, in
Langue francaise 87, Dictionnatres électroniques du francais, Paris : Larousse,

pp. 71-83.

Silberztein, Max. 1993. Dictionnaires électroniques et analyse automatique de
textes. Le systeme INTEX, Paris : Masson, 233 p.

Vosse, Theo. 1992. Detecting and Correcting Morpho-syntactic Errors in Real
Texts”, 3rd Applied ACL, Trente (Italie), pp. 111-118.

15
