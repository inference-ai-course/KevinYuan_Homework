Depth and Autonomy:
A Framework for Evaluating LLM
Applications in Social Science Research*

Ali Sanaei & Ali Rajabzadeh

sanaei@uchicago.edu, rajabzadeh@methods. academy

October 29, 2025

“This is an early draft prepared for the Annual Meeting of the American Political Science Association,
September 2025, Vancouver, BC. For a more recent draft please contact the authors.


===== PAGE BREAK =====

Large language models (LLMs) are increasingly utilized by researchers across a wide
range of domains, and qualitative social science is no exception; however, this adoption faces
persistent challenges, including interpretive bias, low reliability, and weak auditability. We
introduce a framework that situates LLM usage along two dimensions, interpretive depth
and autonomy, thereby offering a straightforward way to classify LLM applications in qual-
itative research and to derive practical design recommendations. We present the state of
the literature with respect to these two dimensions, based on all published social science
papers available on Web of Science that use LLMs as a tool and not strictly as the subject of
study. Rather than granting models expansive freedom, our approach encourages researchers
to decompose tasks into manageable segments, much as they would when delegating work
to capable undergraduate research assistants. By maintaining low levels of autonomy and
selectively increasing interpretive depth only where warranted and under supervision, one
can plausibly reap the benefits of LLMs while preserving transparency and reliability.


===== PAGE BREAK =====

1 Introduction

Large language models (LLMs) have been transformative for natural language processing
and are increasingly used across qualitative social science research applications for indexing,
summarization, first-pass coding, and more. Despite the excitement, however, adoption is
constrained by concerns regarding interpretive bias, reliability, and auditability. Our goal is
to propose a framework which helps us more easily classify, recommend, and evaluate the
utilization of these models in research.

Our objectives are higher research quality (by which we mean validity, reliability, and
interpretive coherence), greater transparency and reproducibility, and preserved human con-
trol.! We propose a two-dimensional plane along ‘interpretive-depth’ and ‘autonomy,’ and
contend that the above objectives are jointly advanced by systematic constraints on model
autonomy—by ensuring that LLMs operate as assistants without authority over consequen-
tial interpretive decisions—and allowing interpretive depth to vary according to the substan-
tive goals of the analysis, under human supervision.

Our argument proceeds from a simple premise: contemporary models are powerful pro-
cessors of natural language but remain brittle in settings that require hermeneutic inference,
contextual sensitivity, expert knowledge, or reflexive judgment. We have acquired assistants
that exceed human capabilities in some tasks (some examples are reviewed in Section 2)
but have vexing deficiencies in other tasks. A growing body of evidence indicates persistent
failures in complex comprehension, global reasoning, and narrative verification (Subbiah et

al. 2024; Gevers et al. 2025; Manikantan et al. 2025; Hardt 2023b; Cui et al. 2023; Den-

1. A research project, from start to finish, can be partitioned into elements which should be reproducible
and elements for which reproducibility is not important or maybe not possible. For example, how exactly
one identifies a puzzle in a literature, or thinks of a theory, or devises a hypothesis need not be reproducible.
The elements for which reproducibility is needed are the concern of the present paper. Of course, one can

chat with a language model to come up with new hypotheses—that’s outside our scope.


===== PAGE BREAK =====

tella et al. 2024, 2024); They retain measurable social biases even when explicit tests appear
neutral, with prompt-based diagnostics revealing implicit associations and discriminatory de-
cision tendencies (Bai et al. 2025; Guo et al. 2024; Aguda et al. 2025). These models’ shaky
meta-cognition and lack of humility can only make the situation more precarious (Betley
et al. 2025; Anthropic 2025). From a teleological perspective, many of these behaviors corre-
spond to the statistical objectives and data distributions that shape next-token prediction,
leaving detectable “embers of autoregression” in model behavior even as capabilities improve
and even in models optimized for reasoning (R. Thomas McCoy et al. 2023; R Thomas Mc-
Coy et al. 2024), and the question of ‘how high the LLM asymptote is’ does not have an
empirical or theoretical answer yet.

While model scaling, instruction tuning, reinforcement learning from human feedback,
and rationale scaffolding have improved task following and multi-step reasoning, these ad-
vances are uneven and frequently sensitive to task form and evaluation design. Instruction-
tuned systems demonstrate notable zero- and few-shot gains (Chung et al. 2022; Brown
et al. 2020; Chowdhery et al. 2023; Ouyang et al. 2022), and chain-of-thought prompt-
ing can elicit performance improvements on arithmetic and commonsense benchmarks (Wei,
Wang, et al. 2022; Wei, Tay, et al. 2022). The hallucination (and limited context) issues have
been considerably remedied by using retrieval-augmented generation, which has now become
standard practice for grounding outputs (Lewis et al. 2020; Izacard et al. 2023; Borgeaud
et al. 2022; Huang and Huang 2024; Karimzadeh and Sanaei 2025).

Notwithstanding this success, replication studies indicate that many our present solutions
are fragile across models and benchmarks, underscoring the need for standardized protocols,
multiple seeds, and transparent documentation (Vaugrante, Niepert, and Hagendorff 2024).
The totality of these observations imply that we have enticingly cheap and powerful tools
at our disposals, but we must be cautious about what tasks are given to them, and having

ways of preserving human control and supervision.


===== PAGE BREAK =====

In response to this challenge, we adopt the bounded-autonomy principle: models may
propose candidates, summarize evidence, and surface contrasts, but they should be pre-
vented from making critical decisions or executing complex tasks without a clear roadmap.
We contend that autonomy becomes more important as our tasks require higher levels of
interpretive depth. Operationally, we constrain the LLM to research assistant roles with a
clear rubric, worked examples, and tightly scoped subtasks; it must cite the textual basis of
its suggestions, indicate uncertainty, and escalate difficult judgments to the human analyst.
The human retains prerogatives over coding decisions, category formation, conflict resolu-
tion, and theoretical integration, much as a PI retains responsibility for research claims
developed with the help of research assistants. This position is consistent with emerging
practice in qualitative workflows that utilize LLMs as bounded aids for first-pass coding,
code suggestion, and memo drafting while maintaining auditable artifacts (Dai, Xiong, and
Ku 2023; Chew et al. 2023; Dunivin 2024; Sinha et al. 2024), and it aligns with frameworks
that emphasize LLMs as tools to propose or refute models under direct human checking
(Eschrich and Sterman 2024) and to structure multi-agent proposer-—critic—-adjudicator roles
with logged exchanges (Rasheed et al. 2025; Su et al. 2024).

In the pages that follow, first, we formalize a depth by autonomy framework in Section
2 that yields design rules and evaluation criteria and show how vertical and horizontal
decomposition can attain high interpretive depth under low autonomy through staged and
auditable pipelines. Then, in Section 3 we presents the coding instruments and apply them
to the existing literature to assess how the present literature can be projected on these two
dimensions; We finally further empirical demonstrations. Finally, Section 5 concludes the

paper, and replication materials appear in the Appendix.


===== PAGE BREAK =====

2 Oracles or Bounded Assistants

The LLMs lack a conceptual notion of incapacity as they have been trained on internet-
sized data, and have been trained to be all-knowing helpful assistants, which as a result
encourage users to treat them as oracles. While that may be far-fetched, a cursory search
for how LLMs are used in research, especially research that is not published yet, yield ample
evidence of the naive optimism with which some researchers are relying on these models. In
qualitative inquiry and as a matter of design and accountability, we posit that generative
LLMs should be cast as assistants without agency over consequential interpretive moves; see
(Roberts, Baker, and Andrew 2024; Schroeder et al. 2025). A practical heuristic is to treat
the model as a competent student assistant in their sophomore year: provide a rubric and
examples, require citations, and reserve authorative decisions to the researcher. The model
operates as a bounded tool for indexing, summarizing, labeling, proposing alternatives, or
even deep-diving into a corpus to extract novel hermeneutic insights while humans retain
decision prerogatives over the exact procedures and oversee the execution step-by-step.

A distinction in qualitative methodology separates surface-level descriptive tasks from
deeper, more complex interpretive work. This distinction separates what Corbin and Strauss
(2015) term ‘superficial analysis’ which ‘skims the top of data,’ from ‘in-depth analysis’ that
‘digs beneath the surface [...] to explore all possible meanings’ (p. 86). Also, there is a distinc-
tion in content analysis method between quantitative and qualitative content analysis; While
early content analysis focused on the ‘objective, systematic and quantitative description of
the manifest content of communication’ (Berelson 1952, p. 18), qualitative approaches em-
phasize discovering meaning within texts through interpretive and hermeneutic engagement
(Kracauer 1952). Some qualitative scholars have distinguished between “thick” and “thin”
description. A key aspect of deeper analysis is the transition from thin description—merely

stating facts—to thick description, which includes the context, intentions, and meanings that


===== PAGE BREAK =====

underlie an action (Dey 1993; Denzin and Lincoln 2017). As Kuckartz indicates, meaning
is often unreachable without prior knowledge, as understanding a text requires context that
cannot be inferred from the text independently and cannot be automated or isolated into dis-
crete parts; he has also recognized a correlation between knowledge and the ability to identify
layers of meaning, suggesting that the more someone knows, the more levels of meaning they
can understand (Kuckartz, 2014). Methodological frameworks, such as grounded theory, are
explicitly designed to facilitate this advancement from description toward theoretical con-
struction. This is achieved through a phased analytical process that begins by “fracturing
the data” in initial open coding before moving to abstract conceptualization (Tie, Birks,
and Francis 2019; Corbin and Strauss 2014; Creswell and Creswell 2022; Denzin and Lincoln
2017). Subsequent stages, such as “axial coding”, systematically reconnect these concepts
by examining their relationships through a paradigm of conditions, context, actions, and
consequences, culminating in “selective coding”, where a core category is identified and in-
tegrated with other categories to form a coherent theoretical account. This analytical climb
involves moving from basic-level concepts, which are close to the raw data, to higher-level,
more abstract categories that capture a central theme or phenomenon. Achieving this level
of abstraction is not a mechanical task but relies on interpretive techniques that require
human judgment, such as constant comparison, analyzing metaphors and emotional expres-
sions, and maintaining the analytical distance needed to “walk a fine line between getting
into the hearts and minds of respondents while at the same time keeping enough distance to
be able to think clearly and analytically” (Corbin and Strauss 2014). Ultimately, in-depth
qualitative work depends on the researcher’s accumulated knowledge—Recognizing, as Dey
(1993) puts it, that there is “a difference between an open mind and an empty head”—to
transform descriptive data into a conceptual or theoretical contribution(Dey 1993).

Figure 1 presents Tesch’s taxonomy of qualitative research, where she has organized

methods according to whether they target the characteristics of language, the discovery of


===== PAGE BREAK =====

regularities, or the comprehension of meaning (1990). As one moves down the taxonomy,
the analysis becomes increasingly concerned with latent meaning, theoretical embedding,
and hermeneutic interpretation. This gradient is central for our purposes, since it implies
that the extent to which a task depends on latent constructs and hidden context is likely to
correlate inversely with model reliability when autonomy is high.

Recent evaluations of LLM-assisted qualitative tasks, for example, report strong perfor-
mance on content extraction and shallow categorization but mixed results on tasks requiring
context integration or interpretive synthesis (Bojic et al. 2025; Heseltine and Clemm von
Hohenberg 2024; Friedman, Owen, and VanPuymbrouck 2024); complementary mappings
and interview studies document similar tensions in adoption and evaluation (Schroeder et
al. 2025; Barros et al. 2025).

On the capability side, progress is rapid, and LLMs have surpassed human capabilities in
solving boutique linguistic tasks like multiple center embedding and garden path sentences,
and have gained emergent human capabilities like theory of mind (Hardt 2025; Kosinski

2024). It is difficult to imagine a human who could read the following sentence easily:

The cheese that the mouse that the cat that the dog that the boy that
the teacher that the principal that the inspector noted reported warned scolded

chased caught ate was moldy.

This was generated (and understood) by gpt-5, and even an open-weight model like qwen3-
32b had no problem resolving it even without ‘reasoning’.? But there is a different side to the
story: LLMs routinely struggle with deeper levels of meaning in summarizing never-seen-
before texts (Subbiah et al. 2024), in resolving ellipsis (Hardt 2023a), in book-length claim

verification (Karpinska et al. 2024) and they misrepresent sources and context in real-world

2.The prompt was Turn this sentence into simple short sentences: ~The cheese that the
mouse that the cat that the dog that the boy that the teacher that the principal that the

inspector noted reported warned scolded chased caught ate was moldy.'


===== PAGE BREAK =====

QUALITATIVE RESEARCH TYPES

[—— THE CHARACTERISTICS OF LANGUAGE
L+ As Communication
|    [/ Content — Content Analysis
|    L— Process — Discourse Analysis
|              L— Ethnography of Communication
L— As Culture
K+ Cognitive -. Ethnoscience
L— Interactive — Structural Ethnography
L— Symbolic Interactionism, Ethnomethodology

DISCOVERY OF REGULARITIES

Identification (and categorization) of elements, and exploration of their connections
[-— Transcendental Realism — Ethnographic Content Analysis

K+ Event Structure Analysis = Ecological Psychology

L— Grounded Theory — Phenomenography

Discerning of Patterns

ke In Conceptualization — Qualitative Evaluation, Action Research,
Collaborative Research, Critical/Emancipatory Research
ke As Deficiencies, Ideologies — [Connected to above methods]

[-— As Culture — Educational Ethnography, Naturalistic Inquiry

L— As Socialization -. Holistic Ethnography

[Te

COMPREHENSION OF THE MEANING OF TEXT/ACTION
Discerning of Themes (commonalities and uniquenesses) — Phenomenology
Interpretation
[/ Case Study
[| Life History
L— Hermeneutics — Reflection
L/ Educational Connoisseurship
K+ Reflective Phenomenology
L— Heuristic Research

;
[Tk

Figure 1: Tesch’s taxonomy of qualitative research types.

news answering (Archer and Elliott 2025). Moreover, this all happens with high levels of
confidence, and lack of meta-cognition (Chen et al. 2025). They also have an instruction-
following problem: they may assume more liberties than they are given, or they may be lazy
in performing multi-step tasks (Lou, Zhang, and Yin 2024; Zhao et al. 2024; Hernandez-
Orallo et al. 2024; Tang et al. 2023).

There are two main strategies at play to try to resolve this tension between super-human
power and second-hand Dunning-Kruger-esque combination of confidence and incompetence:
first, the technical aspects, which is progressing with full-speed and is reducing error and bias
either by providing better models, or by introducing remedies like ‘reasoning’ and ‘grounding
facts with web search,’ but are out of the hands of most social scientists; and, second, by
coming up with better research designs, that help rely on these models, for their strengths,

avoid their weaknesses, and produce reliable results. This is where our focus lies; By propos-


===== PAGE BREAK =====

ing a framework for comparing various applications of LLMs in different fields, we hope to

help establish better research designs and develop a language to evaluate research designs.

2.1 Dimensions of LLM Usage

Let us begin by delineating several potential dimensions along which LLM usage in qualita-

tive text analysis can be characterized.

¢ Depth of analysis (surface + hermeneutic) denotes the extent to which outputs rely

on manifest linguistic features versus latent thematic or interpretive inference.

e Autonomy level (from tool-like “assistant” to “delegate” to “trustee”) denotes the

extent to which consequential choices are made by the model rather than by a human.

¢ Scope of analysis (going from word to sentence to segment to document to corpus)

refers to the unit of analysis on the input side and by the nature of the task.

e Reasoning load (simple recall < multi-step reasoning) indexes whether performance
is plausibly pattern retrieval or requires explicit multi-step inference. Like other di-
mensions, this is about the task, not the model. For example, on the easier side of the
spectrum, imagine going from ‘What state contains Albuquerque?’ to ‘Name all states
that start with the same letter that the name of the state that contains Albuquerque

starts with but does not contain Albuquerque.’

e Task novelty (in-training + novel) distinguishes prompts that resemble training pat-
terns from genuinely new problems. In the former case, models typically perform well
irrespective of the task’s complexity. In the latter case, model performance relies on
how well can the existing training come to the rescue (one might say, like how humans
perform new tasks), even if the model has not ’performed’ the task in training, it may

have seen it, like answering medical diagnostic questions.

10


===== PAGE BREAK =====

Interpretive Depth

ange’ of                                                                                     ange of

Possibility                                                                               Possibility

Unit of Analysis                            Unit of Analysis

Figure 2: Research methodology constraint plots showing feasible regions

¢ Inference (descriptive + interpretive) specifies whether the task summarizes observable

content or imputes latent constructs.

¢ Logic (deductive + inductive) encodes whether categories are fixed a priori or emerge

iteratively.

¢ Context (contextual < non-contextual) indicates the extent to which broader situa-

tional information must be integrated.

¢ Iteration (iterative + single-shot) captures whether the pipeline is multi-pass or single-

pass, including multi-agent variants (Rasheed et al. 2025).

¢ Epistemology (positivist <> interpretivist) situates the epistemic stance of the analysis

(Eschrich and Sterman 2024).

These dimensions exhibit systematic correlations. For example, figure 2 demonstrates
the constraint relationships between scope and both autonomy and interpretive depth; the
feasible regions expand with analytical scale, revealing how broader context enables—but
does not necessitate—greater model agency or hermeneutic complexity. While these dimen-
sions overlap, we argue that interpretive depth and autonomy are conceptually distinct and
directly actionable in design. Depth is set by the substantive aim of the study; autonomy

is set by the pipeline. Together, they define, for a given task, what the model is able to

11


===== PAGE BREAK =====

High

yY

Autonom

Low

Low                                      High
Interpretive Depth   °

Figure 3: Depth and autonomy: configurations and risk region. Low-autonomy configu-
rations (green points) can support increasing interpretive depth; the shaded sector marks
high-risk high-autonomy /high-depth configurations.
do and what must be reserved for humans. Moreover, these two axes subsume, in terms
of predictive leverage, a wide range of the other dimensions—scope, novelty, and reasoning
load, inference, logic, context, iteration, and epistemology—are all easy to relate to these
two dimensions, in an abstract way, althought the exact relationships depend on the specific
task and the context.

It deserves emphasis that the interpretive depth associated with a substantive research
question is distinct from the depth of the operation assigned to the model. The latter is
a function of the protocol: What exactly is the model asked to do? What examples are

supplied? Which outputs are permitted?

12


===== PAGE BREAK =====

2.2 Context, Depth, and Autonomy

As Figure 2 illustrated, the feasible set for what the model could do expands with context.
The methodological problem is that realized autonomy can expand in lockstep with this
feasible set when researchers delegate end-to-end tasks to a model. Our advice is to try to
break this coupling by design when possible: a concern reinforced by observed directional
biases in relation predictions and implicit associations (Aguda et al. 2025; Bai et al. 2025;
Guo et al. 2024). We allow interpretive depth to rise when warranted by the research
question, but we leash realized autonomy through bounded subtasks, structured outputs,
and mandatory human checkpoints.

A practical corollary concerns task decomposition. Two strategies are useful in this
setting. Vertical decomposition sequences subtasks so that the input to stage k+1 is the
output of stage k (e.g., extract evidence — cluster codes — synthesize themes). Horizon-
tal decomposition, in contrast, runs tasks in parallel—either across disjoint input segments
when context budgets are binding (chunking) or across distinct dimensions applied to the
same input (e.g., rule of law, accountability, institutional constraints). Earlier models often
required horizontal decomposition because they drifted when requested to perform multiple
tasks concurrently and faced context limitations on long texts. While contemporary sys-
tems are more capable, task decomposition typically produces richer outputs, more faithful
instruction following, and multiple checkpoints that improve transparency and autonomy

control by creating opportunities to diagnose and correct intermediate artifacts.

2.3. Orchestrated Decomposition on the Autonomy-Depth Plane

Much can be accomplished by research design. Most importantly, high interpretive depth
does not necessitate high autonomy, as it may be possible to decompose the workflow

(‘bound’ it), make it auditable, and have steps that require human approval. Single-pass

13


===== PAGE BREAK =====

execution concentrates latent decisions in one opaque step. In contrast, multi-pass pipelines
separate extraction, candidate generation, adversarial critique, and adjudication, thereby
distributing depth across stages while maintaining low autonomy at each stage. In this con-
figuration, depth increases through synthesis across documented steps, rather than through
early delegation to a model.

Design rule: When interpretive depth is high or the stakes of inference are substantial,
utilize vertical decomposition to separate decision-bearing steps and horizontal decomposi-
tion to diversify inputs or dimensions. Each stage should have a narrow brief, typed outputs,
calibrated abstention, and a documented handoff. The objective is to preserve low realized
autonomy throughout, while enabling richer interpretive synthesis at the end of the pipeline.

The following three items are presented as examples, not prescriptions. Each demon-
strates how high- or moderate-depth interpretive work can be implemented under low au-
tonomy, using staged, auditable designs. Of course, all LLM steps can be iterated (to arrive
at a satisfactory prompt) and can be run multiple times (to have a better sense of the
uncertainty from the model’s side).

Example 1. Extracting elements of constitutional thought from a 7th century document.
The document is a letter from Ali ibn AbiTalib (the second caliph for Sunni muslims and
the first imam of Shia muslims) to Malik al-Ashtar, his governor for Egypt in year AD 659.
This is, while not the deepest task (especially given the roughly 3000 word length of the
document), still requires significant interpretive depth.

Our decomposition plan is as follows: (i) Extract dimensions of constitutional thought
from the sources, with clear definitions and evidence expectations; (ii) Run the model on the
document, for each dimension, to provide a short explanation of whether that dimension is
absent or present in the document, and if it is present, provide direct verbatim quotations
that support the claim. (iii) Adjudicate between different claims. (iv) Synthesize the results

into a final report.

14


===== PAGE BREAK =====

Example 2. Open coding of archival radio transcripts. Our decomposition plan is as
follows: (i) elicit candidate descriptive codes on short segments using worked examples and
descriptions of what is intended, and inclusion of an abstention option; (ii) human consolida-
tion into a provisional codebook; (iii) parallel application with abstention and conflict flags;
(iv) adversarial pass proposing merges, splits, and negative cases with citations; (v) human
revision; (vi) full-corpus application with reconciliation. Depth is moderate in the synthesis
phases; autonomy remains bounded by the rubric, abstention, and human adjudication.

Example 3. Focus-group synthesis for marketing insight. We can imagine a pipline like
this:(i) extract claims, needs, and quotations with source linkage (low depth); (ii) cluster
(maybe by persona, maybe by general stance, etc.) (moderate depth); (iii) produce evidence-
linked opportunity statements with confidence ratings and counter-evidence; (iv) human
prioritization; (v) recommendation drafting with traceable links back to evidence and explicit
caveats. The model proposes options and clarifies trade-offs; humans decide priorities and
finalize language.

We can generalize the idea beyond these cases by mapping qualitative method families
to the autonomy-depth plane in order to derive role assignments for models and humans.
The idea can be summarized in this pithy slogan: Break the task, bind the output, and climb

the ladder of abstraction under human gaze.

3 Survey of LLM Use in Social Science Research

In the preceding section we claimed that the depth-autonomy framework can both guide
our design decisions and can also help us evaluate existing research. Here we develop a
coding scheme that we apply to existing published social science research that has utilized

generative LLMs.

15


===== PAGE BREAK =====

Table 1: Summary of items in the coding questionnaire; full instrument in Appendix A

Construct                   Items (abridged descriptions; scoring anchors)
Description                Q01-Q09 (discipline, data type/language, ...)
Interpretive depth           Q10 Task nature (1-5: extraction...deep interpretation);

Q11 Ambiguity (0-2);
Q12 External context (0-3);
Q13 Reasoning (0-4);
Q14 Framework predefined vs emergent (1-3);
Q15 Unit of analysis (1-5)
Realized autonomy           Q16 Human scaffolding (0-3);
Q17 Human supervision (0-3);
Q18 Instruction mode (interactive/fixed/agentic);
Q20-Q21 Reasoning prompts and examples (yes/no);
Transparency, Validation Q23-Q33 (model identification, prompts shared, evaluation
against humans, limitations)

3.1 Measurement model and coding instrument: overview

Our instrument operationalizes two central constructs: interpretive depth (what kind of
inference the model is tasked to perform) and realized autonomy (the extent to which conse-
quential steps are delegated to the model versus scaffolded and supervised), but also includes
items to collect descriptive metadata (discipline, data types, language), other aspects of the
design (unit of analysis), evaluation practices (validation against humans, reporting of limi-
tations), and transparency of research (whether and to what extent replication materials are
shared). The full instrument, coder instructions, tie-breakers for primary-use selection, and
the rationale-and-evidence protocol appear in Appendix A.

Table 1 summarizes the mapping between constructs and items. Items Q10-Q15 index
interpretive depth. Items Q16-Q22 index realized autonomy. Items Q01-Q09 and Q23-Q33
are descriptive and evaluation covariates. The item content and anchors align with the
conceptual framework developed in ...

Exemplar items. (Full text in Appendix A)
Q10-Nature of the task performed by the LLM. (1) Information extraction; (2)

16


===== PAGE BREAK =====

Summarization/synthesis of explicit content; (3) Initial qualitative coding (sur-

face); (4) Thematic analysis (latent); (5) Deep interpretation (theory-building).

Q16-Human scaffolding of the task (end-to-end pipeline). (0) Not decomposed;
(1) Small extent; (2) Moderate extent; (3) Large extent (detailed checklist /code-
book).

Q17-Human supervision of the LLM’s work. (0) None; (1) Occasional; (2) Reg-

ular; (3) Intensive (approval at each step).

3.2 Empirical Results

We queried the Web of Science Core Collection to identify social-science journal articles
that deploy large language models (LLMs) in substantive research.* The query returned 955
records. Five lacked abstracts, leaving 950 for screening. We then conducted a three-pass
screening protocol. First, using DeepSeek-Reasoner v3.1 (temperature = 0), we classified
abstracts as relevant if an LLM was used instrumentally—e.g., as an analytic tool, coding
assistant, data generator under constraints, or research aide in an actual study—rather than

if the paper’s sole object was to analyze or benchmark LLMs themselves. This stage yielded

3. We queried the Web of Science Core Collection on 26 August 2025 at 16:30 UTC to identify social-
science journal articles that deploy large language models (LLMs) in substantive research. The search ex-
pression was: TS=(large language model OR LLM OR GPT) AND PY=(2023-2025) AND DT=(ARTICLE
OR EARLY ACCESS) AND WC=(Social Sciences, Interdisciplinary; Communication; Behavioral Sciences;
Law; Social Sciences, Mathematical Methods; Political Science; Psychology, Social; Psychology, Multidisci-
plinary; Social Issues; Sociology; History; Anthropology; Religion; Social Work; International Relations). We
included GPT” because many authors name that system explicitly in titles and abstracts after the release of
ChatGPT, whereas “LLM” is used inconsistently across fields. The 2023-2025 window captures the period
when generative models entered applied workflows while accommodating indexing lag. Restricting results
to Article and Early Access concentrates the output on peer-reviewed journal material and The disciplinary

filter spans political science and adjacent social-science fields to ensure coverage across cognate domains.

17


===== PAGE BREAK =====

234 items. Second, we re-screened these abstracts twice with GPT-5 (reasoning effort set
high) and retained items judged relevant across all three LLM calls. Third, we manually
adjudicated the resulting set, removing papers that did not actually use generative models,
used them only as the object of study, or offered comparisons of models without instrumental
use. The final corpus contains 56 articles; we also retrieved their PDFs. Our aim was not
exhaustiveness. We sought a diverse corpus of social-science studies that actually employ
LLMs in empirical or analytical work.

We applied the coding scheme to the retrieved works in three ways: first, we applied the
coding scheme using a competent open-weight model (gpt-oss-120b with high reasoning)
giving the codebook and the text of the papers, five times per paper, and asking all questions
that needed some reasoning to also produce a clear rationale. A random review of the results
proved disappointing with various types of mistakes: the majority of mistakes were those
could be easily done by human assistants who do not pay close attention to details (multiple
uses of generative models was one of the causes of some mixups); other mistakes were mistakes
in degree, in how Likert-type questions in the codes were answered; but there was a third
category of mistakes that were a bit baffling and interestingly all runs of the model would
agree on their wrong answer, but could be corrected with few-shot examples. An example
is when clear examples of ’classification’ would be categorized as ‘information extraction,

<cot>

The task is to classify tweets into predefined issue categories (e.g.,

health, economy), which involves identifying explicit topics mentioned

in the text. This is information extraction, not summarization, coding,
or deeper interpretation.

</cot>

1: Information extraction (identify explicit facts)
We then used ‘gpt-5’ with high reasoning on the same data. The results were generally

18


===== PAGE BREAK =====

better, but residual confusions persisted: degree errors on Likert anchors and stable misclas-
sifications that required few-shot guidance (as in the classification vs information-extraction

example).

3.3. Construct-level variation

How does the literature look throught the lens of our framework? We present a short
analysis that evaluates feasibility and variation for the autonomy—depth framework using
the coded corpus. The analysis demonstrates that the questionnaire items in Table 1 can
be operationalized with published materials, that the items are answerable with sufficient
fidelity to construct definitions, and that the resulting indices exhibit non-trivial dispersion
across studies. The objective is validation of implementability in the corpus, not hypothesis
testing about structural relations among the constructs.

The measurement follows the coding instrument. Interpretive depth aggregates Q10 to
Q15, which capture task nature, ambiguity, external context, reasoning, framework status,
and unit of analysis, and Realized autonomy aggregates Q16 to Q17 and Q22, which cap-
ture human scaffolding, human supervision, and iteration. The instruction mode from Q18
is recorded at the item level and contributes to the autonomy item set as implemented.
Reproducibility-and-rigor aggregates transparency and evaluation indicators: model iden-
tification, settings reporting, prompt availability, materials sharing across prompts, code,
and data, evaluation against a human standard or benchmark, limitations discussion, and
reliability reporting (Q23, Q25, Q27, the multi-item materials count, Q30—Q33). All items
are rescaled to the unit interval prior to row-wise averaging with available cases. This
available-case approach is intended to preserve information while avoiding listwise deletion.
The indices are descriptive summaries rather than latent-variable estimates.

The analysis yields three indices with visible dispersion on the unit interval. Figure 4

summarizes marginal distributions and bivariate relationships. Pairwise correlations are re-

19


===== PAGE BREAK =====

interpretive_depth                     autonomy                    reproducibility_rigor
154                                                                                                                   >
(0)
3
104                                                              Corr:                               Corr:                     Q
-0.141                         ~0.231.                 ®
Qa
54                                                                                                                  3
a>
0 4
1.004             ee
e
e
0.755 +e     wmaewe ee e@                                                                                          »
ea                                                                                                 i
e      ecce 0                                                                      Corr:                   Ss
0.504         eb-s-¢                                             -0.026            s
°                                                                                   <
e   ee     e     hi
e
0.254         eoce     e
e
0.84           “esse                             :   or   $° °
e                                       ee                                                  3
e     eoe e                   @ ee     e°e   e                                ne}
0.64               e      e                                  ee       e                                                       3
eS «©                    ee      ec      8                                     e
e    e           e      ee                     ee        e                                                  2.
0.44    e       e © ee                   eo evo                                   =
eo &             fe       e                                    <
e     e                                      e            e                                            =
0.24                3                                                e                                                           iS
e                                            e

0.0 0.204 06 08 10 00 02 04 06 08 10 00 02 04 06 08 1.0

Figure 4: Correlations and distributions of the constructs in the literature corpus. The figure
shows a scatterplot matrix for interpretive depth, realized autonomy, and reproducibility,
each scaled to the unit interval. Off-diagonal panels show pairwise relationships. Diagonal
panels show marginal distributions.

ported strictly as descriptive markers of separability. Interpretive depth with autonomy
equals —0.14, interpretive depth with reproducibility and rigor equals —0.23, and autonomy
with reproducibility and rigor equals —0.03, computed with pairwise deletion. The mag-
nitudes are modest, which is consistent with the intended use of these indices as distinct
descriptive dimensions. The central result here is variation. The literature contains studies
at different points in the autonomy—depth plane and with heterogeneous transparency and
evaluation practices. This is what is needed for subsequent descriptive comparisons that

utilize these indices as classification variables.

20


===== PAGE BREAK =====

4 Results

In this section we report two empirical demonstrations designed to evaluate the bounded-
autonomy principle. Implementation details, prompts, and full audit trails appear in Ap-
pendix A and Appendix B. Both of the experiments are tasks about “Letter 53” which is an
edict by Imam °Al to Malik al-Ashtar (AD 659), which is a canonical governance directive
when Malik was appointed governor of Egypt (al-Sharif al-Radhi 1987). All of the LLMs
used here have had this letter and multiple translations of it in their training, but the tasks
we are asking them to perform are novel and so the models training data do not comprise
anything directly answering our specific tasks. Experiment 1 is an anachronistic and impos-
sible task to demonstrate what could go wrong in the absence of guardrails and off-ramps;
experiment 2 is about a legitimate theoretical question that seeks to evaluate this old text

through the lens of modern ideas about governance.

4.1 Experiment 1: Prompt-Bounded Abstention on a Conceptu-

ally Mismatched Task

The goal is to assess how overly-compliant behavior by LLMs can lead to behavior that
defies the user’s intentions. The test case is deliberately asking to find for evidence that is
so obviously absent, but all models we tested easily complied and provided some pieces of
evidence with twisted arguments for why the irrelevant pieces could be seen as relevant.
The conclusion we want to draw is a strong word of caution: by reducing autonomy we
do not mean limiting the choices of an LLM; rather we mean the freedom given the model to
make consequential decisions. In the language of codebook development, a clearer codebook

reduces coding errors by research assistants.

21


===== PAGE BREAK =====

Design

The task is to “produce evidence of advocating for bicameralism” in a 7th-century piece
of political advice (letter 53 of Nahjulbalaghah). We implement a 2 x 2 design with these
factors: Enumerative range 0-10, 1-10 and Abstention option present, absent, with 50 runs
per cell. In the control condition, the model (gpt-5; reasoning effort = medium; verbosity
= medium) is instructed to extract “evidence elements” and return each item within an
<evidence> tag. In the treatment condition, the identical prompt additionally states: “Or,

!”’ For each of the four cells we run 50 parallel

you can say: ‘There is no evidence for that
calls on the same input letter. The primary outcome is the count of <evidence> tags per
response, which, by construction, lies in [0,10]. Content validity is not adjudicated here
because the task has no true positives; the correct output is abstention. All of the items we
saw were utterly irrelevant, as expected, and with various twists in logic they were pushed
as evidence supporting bicameralism. What was more informative was that the thinking

provided by some models showed that the models clearly had a sense that the task was

impossible or anachronistic, but still obsequiously complied, even when 0 was an option!

Outcomes

The quantity of enumerated “evidence elements” is used as a behavioral indicator of com-
pliance versus abstention in this case. We report the sample mean and standard deviation
of counts across the 50 runs per cell; we also record whether any run produced zero items.
Table 2 reports the distributional summaries. Without an abstention option, the model
reliably fabricates between five and eight “evidence” items, depending on whether the enu-
merative range is 0-10 or 1-10. With an explicit abstention option, outputs collapse to zero
almost always, including in the 1-10 setting where zero is not within the numeric range. For
(0-10, no abstention], the mean count is 5.26 (SD= 1.85) and for [1-10, no abstention], it

is 7.36 (SD= 0.964). Adding the explicit abstention string yields [0-10, abstention] mean

22


===== PAGE BREAK =====

= 0.00 (SD= 0.00; 50/50 zero-count runs) and [1-10, abstention] mean = 0.16 (SD= 1.13),
with 49/50 zero-count runs and one outlier run returning eight items.
Figure 5 shows the results of the experiment done with 4 top models. While there is

some difference between the models, they all suffer from this behavior.

Interpretation

Two implications follow. First, in the case of an impossible task, hard enumerative bounds
(e.g., “give 1-10 items”) act as constraints that the model prioritizes satisfying, yielding
nonsensical outputs rather than calibrated abstention. Second, “reduced autonomy” must
include an explicit valid off-ramp, an abstention clause that is semantically consistent with
the decision space, if we wish to prevent spurious compliance. Put differently, instructing a
model to “stay within tight bounds” without an auditable abstention path risks reliability
loss through over-compliance; adding a clear abstention option re-routes behavior toward
refusal, even overriding numeric bounds in nearly all runs. The extent to which abstention
is realized is therefore a function of prompt semantics as well as the allowed output set, and
careful human supervision remains necessary to iterate prompts or to halt tasks that are
ill-posed.

Recent research demonstrates the butterfly effect of changing minor characteristics such
as spacing, punctuation, and adverbs (Salinas and Morstatter 2024; Sclar et al. 2024), chang-
ing the prompt structure (He et al. 2024; Salinas and Morstatter 2024), the order of instruc-
tions (e.g., reasoning first then scoring, or scoring followed by reasoning)(Chu, Chen, and
Nakayama 2024), and semantically similar prompts (rephrasing prompt, changing language)
(Barrie, Palaiologou, and Tornberg 2025; Errica et al. 2025; Stewart et al. 2024) could lead
to significantly different outputs. While recent models have shown better consistency, nei-
ther model size nor prompt optimization methods, nor the use of reasoning models, has fully

addressed this challenge (He et al. 2024; Sclar et al. 2024). There is a substantial need to

23


===== PAGE BREAK =====

"give 0 to 10 points"                             "give 1 to 10 points"
507
40,
305                                                                                      9
=
204                                                                                      3
104                                                                                            model
< o                                                                                            = claude-sonnet-4
5                                                                         a
2 59                                                                                           gemini—2.5—pro
o                                                                                           m| [Eo gpt-s
40-                                                                                      os    | qwen/qwen3-32b
3.
304                                                                                      5
o
=
20+                                                                                      =
Ss
[e)
10;                                                                                      2
[e)
=
0;

0 2 4 6 8 10 oO 2 4 6 8 10
Number of points extracted

Figure 5: Distribution of evidence counts across experimental conditions. The plot shows the
behavioral response to enumerative constraints and abstention options in the bicameralism
experiment with multiple models.

Enumerative constraint Explicit abstention option Mean count SD

1-10 elements                          No                   7.36       0.964
1-10 elements                         Yes                   0.16        1.18
0-10 elements                          No                   5.26        1.85

0-10 elements                                       Yes                             0.00           0.00

Table 2: Mean number of enumerated <evidence> items across 50 runs per condition. Model:
gpt-5 (reasoning effort = ‘medium’; verbosity = ’medium’). In treatment cells, the prompt
added: Or, you can say: “There is no evidence for that!”

refine the prompt based on the model and specific tasks, which means we require an iterative
approach with human supervision checkpoints to minimize output inconsistency and improve
output quality, while also enhancing replicability and reliability.

The behavior observed here—strong compliance with numeric constraints absent an ex-

24


===== PAGE BREAK =====

plicit “out,” versus near-universal abstention when refusal is permitted—motivates subse-
quent designs that combine low model autonomy with calibrated abstention and human

checkpoints.

4.2 Experiment 2: Vertical and Horizontal Task Decomposition

The goal is to evaluate the utility of vertical and horizontal task decomposition in a higher-

depth analysis.

Design

The task is obtain core pillars of constitutionalism, as it is understood in the contemporary
literature, and apply them to Letter 53 of Nahj-al-Balaghah. Aside from substantive interest,
this is a methodologically challenging task for various reasons including: the text of the letter
has certainly been ‘seen’ by models, but the task is new; and constitutionalism is a concept
that would seem familiar to the models but there is no established definition or way to
measure it. We implement three orchestration regimes and compare their performance: (i)
Baseline (no decomposition): single call to a state-of-the-art model; (ii) Two-Stage (two-level
decomposition): two-stage prompting in which the model proposes a coding scheme that is
approved by humans and then applied at once; (iii) Multi-Stage (horizontal and vertical
decomposition): vertically and horizontally decomposed prompting in which the scheme is
approved and then applied in parallel to distinct dimensions (e.g., rule of law, institutional

constraints, accountability), followed by a synthesis step.

Outcomes

We compare agreement with human adjudication, stability across multiple runs, and trans-

parency (measured by audit-trail completeness).

25


===== PAGE BREAK =====

All three orchestration regimes reach the same high-level conclusion; if the outcome of
interest were a single sentence rather than a detailed analysis, in this case, even the base
model would suffice. As increase the amount of task-decomposition, we clearly observe two
benefits: there is clearly more detailed, better grounded response. Also, when we increase
the vertical decomposition, we decrease the autonomy of the model and also make it clearer
(less resembling a blackbox).

We conducted three analyses corresponding to the three orchestration regimes described
earlier: Baseline (No Decomposition) is an itemized extraction of elements with short ev-
idence and rationales (53_1); Two-Stage (Two-level Decomposition) is a dimension-by-
dimension diagnosis with verbatim quotations and 0-10 strength scores (53_ 2); Multi-Stage
(Horizontal and Vertical Decomposition) is a decomposed synthesis that integrates per-
element analyses into a consolidated report with the same 0-10 scoring rubric (53_ 3). We
first summarize convergent content across the three executions, then compare the quantita-
tive (0-10) scores from Two-Stage and Multi-Stage, and finally provide illustrative textual
evidence. The objective is not to adjudicate historical priority per se but to evaluate whether,
and the extent to which, the letter contains recognizable institutional and rights-anchored

constraints that can be operationalized as constitutional elements for text analysis.

Coverage and convergence across executions

All three executions converge on a broad rule-of-law conception with multiple, interlock-
ing constraints on executive power. Across the set, we observe repeated identification of:
supremacy of higher law (Book and Sunnah) over ordinary command; limited government
and the rejection of “because I command” authority; equality and human dignity across
confessional lines; impartial adjudication by a qualified and resourced judiciary; procedural
safeguards (verification, public hearings, avoidance of precipitous punishment); protection

of life and accountability for state violence; open petitioning and ruler accessibility; con-

26


===== PAGE BREAK =====

sultation with competent advisors; functional differentiation of state roles (military, judi-
ciary, administration, revenue, commerce, vulnerable); merit-based appointments and anti-
nepotism; oversight/auditing and corruption control; majoritarian welfare considerations;
social welfare duties toward the poor and vulnerable; fiscal constitutionalism (fair taxation
linked to productive development); market regulation (anti-hoarding and fair pricing); in-
tegrity of public resources (no privileged grants/monopolies); treaty fidelity and good faith;
and legal continuity with beneficial precedent. Two elements appear as weak or absent:
a formal amendment meta-rule (absent) and assembly-based consent requirements for law-
making and taxation (indirect /weak). The mapping from Baseline’s granular list (20 items)
to the 17-element schema in Two-Stage and Multi-Stage is straightforward: for example,
“Supremacy of higher law” (Baseline.1) aligns with “Supremacy of constitutional norms”
(Two-Stage/Multi-Stage.6), “Limited government” (Baseline.2) with “Legal limits on rulers’
powers” (Two-Stage/Multi-Stage.1), “Independent, competent judiciary” (Baseline.5) with
“Interpretation and enforcement mechanisms” (Two-Stage/Multi-Stage.11), “Market regula-
tion; anti-monopoly” (Baseline.17) with “Rights as limits on power” as well as “Procedural
limits” (Two-Stage/Multi-Stage.7-8), and “Treaty fidelity” (Baseline.19) with “Entrench-
ment” and “Conventions” (Two-Stage/Multi-Stage.3, 12). The “Consent in lawmaking”
dimension (Two-Stage/Multi-Stage.14) is scored as partial/low, while “Amendment rules”

(Two-Stage/Multi-Stage.10) are explicitly absent.

Quantitative concordance (scores)

Two-Stage and Multi-Stage report element-wise strength scores on a 0-10 scale. The two
sets are highly concordant: scores are identical or within two points for all seventeen ele-
ments. High-salience constraints—legal limits on rulers’ powers, supremacy of higher law,
writtenness and custom, allocation and checks of power, due process/procedural limits, in-

terpretation and enforcement mechanisms, and abstract principles—all receive strong scores

27


===== PAGE BREAK =====

in both executions. Jurisdictional limits and stability/continuity exhibit moderate-to-strong
scores, while consent in lawmaking is partial/low and amendment rules are absent in both.
This cross-execution agreement is consistent with the bounded-autonomy design: Two-Stage
and Multi-Stage yield stable element identification and closely aligned strength assessments,

with Multi-Stage providing the most detailed and tractable narrative.

Illustrative textual evidence

The letter’s constraints are repeatedly anchored in higher law and in procedures that render
the governor accessible and accountable. Representative passages include: the rejection
of autocratic fiat—‘*Do not say: ‘I am empowered—I command and I am obeyed’.”!; the
command to return hard matters to the Book and the Messenger—“Refer back to God and
His Messenger whatever weighs upon you ... the referral to God is taking the decisive of His

2. universal dignity—*For

Book, and the referral to the Messenger is taking his Sunna. ...
they are of two kinds: either your brother in religion, or your peer in creation.”%; judicial
selection and protection—“Then choose for judging between people the best of your subjects
.. then frequently oversee his judgments ... and make ample provision for him ...”*; public
hearing and petition—“Set aside a time for those with needs ... and sit for them in a public
assembly ... until their speaker speaks to you without stammering.”®; the sanctity of life
and accountability—‘“ Beware blood and its shedding without its due right ... and there is no
excuse for you ... in deliberate killing, for in it is retaliation against the body.”®; anti-hoarding
and fair markets—“So prevent hoarding ... and let sales be easy sales: with just scales and
prices that do not injure either party.”’; fidelity to covenants—‘“So protect your covenant

with fidelity, and guard your pledge with trustworthiness ... and do not betray your pledge.”®.

28


===== PAGE BREAK =====

Implications for orchestration.

In line with the design principle in Section 3, the three executions exhibit the expected
ordering in utility and detail—Multi-Stage (Horizontal and Vertical Decomposition) > Two-
Stage (Two-level Decomposition) > Baseline (No Decomposition). While all executions
point to the same high-level conclusion, only the decomposed runs deliver the granularity
and auditability required for cumulative qualitative inference. The separation of schema
construction from application, combined with per-element verification and synthesis, appears

to be a robust approach to high-dimensional text analysis under low model autonomy.

Element (17-dimension schema)             Two-Stage Multi-Stage

No)
No)

Legal limits on rulers’ powers
Sovereignty vs. government offices
Entrenchment of constraints
Writtenness and custom
Allocation and checks of power
Supremacy of constitutional norms
Rights as limits on power
Procedural limits

Jurisdictional limits

Amendment rules

Interpretation and enforcement
Binding political conventions

Due process and fair adjudication
Consent in lawmaking

Stability and continuity

Abstract commitments enabling adaptation
Remedies for constitutional breach

OUONWBOAONANDUFAWA YM YO N ©
NOMANAMAMOUDDA UNA VN AWF ON CO

Table 3: Scores are on a 0-10 scale; higher values indicate stronger presence.

29


===== PAGE BREAK =====

row Baseline element

Corresponding schema element(s)

1      Supremacy of higher law

2     Limited government
(no autocratic command)
3     Equality and human dignity
4     Impartial justice; no favoritism

5     Independent, competent judiciary

6      Procedural fairness

7     Protection of life and accountability
8     Right to petition and public hearing
9     Transparency; avoidance of seclusion
10 Consultation with qualified advisors

11    Institutional differentiation of functions

12. = Merit-based appointments; anti-nepotism

13 Oversight and anti-corruption

14 _—~ Public interest over elite preference
15 ~~ Social welfare duties

16 ~—_—- Fiscal constitutionalism

17. = Market regulation; anti-monopoly

18 = Integrity of public resources

19 ~~ ‘Treaty fidelity and good faith

20 Respect for precedent and continuity

Supremacy of constitutional norms;
Sovereignty vs. offices
Legal limits on rulers’ powers

Rights as limits on power; Due process
Due process; Interpretation and enforce-
ment

Interpretation and enforcement
Procedural limits; Due process

Rights as limits; Remedies; Due process
Procedural limits; Due process

Procedural limits

Procedural limits

Allocation and checks of power

Allocation and checks of power
Interpretation and enforcement;
Allocation/checks

Consent (partial); Stability and continuity
Rights as limits on power
Allocation/checks; Jurisdictional limits
Rights as limits; Procedural limits
Jurisdictional limits; Allocation /checks
Entrenchment; Conventions

Stability and continuity; Conventions

Table 4: Baseline elements map naturally onto one or more elements in the 17-dimension

schema.

30


===== PAGE BREAK =====

5 Conclusion

We formalized a depth-by-autonomy framework for utilizing large language models in qual-
itative social science research. The framework separates interpretive depth, set by the sub-
stantive aim, from realized autonomy, set by the pipeline. The design rule is to permit depth
where needed while constraining autonomy through decomposition, calibrated abstention,
and a series of human checkpoints and instruction refinement. The survey applies the frame-
work to published studies. We coded depth, autonomy, and transparency explicitly and
found that studies vary systematically across these dimensions. We then performed experi-
ments on a seventh-century document. Experiment 1 showed that enumerative constraints
without an explicit abstention path produce spurious compliance, whereas a semantically
valid abstention option triggers near-universal refusal—even when numeric ranges exclude
zero. Experiment 2 demonstrated that decomposed pipelines generate outputs that are si-
multaneously more detailed and more auditable than a single-pass baseline. Two-stage and
Multi-Stage executions yielded closely aligned element scores, with the Multi-Stage Approach
offering the most reliable analysis.

Large language models excel at linguistic surface-level tasks, such as overall sentiment
analysis, summarization, and in-distribution tasks. Add interpretive complexity or contex-
tual nuance, and performance erodes. While there is evidence of the high performance of
LLMs on narrow tasks, we cannot generalize this to all cases. The discovery that a large
language model can match or even surpass human performance on a specific, well-defined
metric—such as inter-coder agreement on surface-level codes—should not be mistaken for
the model having an expert-level understanding of the subject. This misunderstanding can
result in an uncritical reliance on the model’s outputs, treating them as authoritative answers
instead of recognizing them as sophisticated but limited statistical tools.

LLMs are designed to predict the next most likely token, and they do not exhibit emotions

ol


===== PAGE BREAK =====

such as wonder or doubt. They will not seek clarification unless prompted to do so, and they
cannot exit without being explicitly instructed to do so. Adjustments such as changing the
temperature setting or applying Chain of Thought (CoT) techniques do not truly enhance
curiosity or creativity; instead, they modify the probability distribution. It is critical to
recognize these limitations and account for them in how LLMs are used. In the present
work we almost exclusively relied on flagship proprietary models, but when we see that even
advanced commercial models can face the challenges mentioned here, we think employing low-

autonomy strategies with open-weight models may enhance transparency and reproducibility

without sacrificing much.

A Coding Scheme

The following is the coding scheme used for evaluation of the retrieved published papers in
social sciences that have used generative large language models.

Instructions for coders

Before coding, answer QOO. If QOO = YES, proceed. If QOO = NO, stop after Part 1
(basic metadata optional) and mark the paper out of scope. If QOO = NR (unclear),
skim Methods/Appendix for model details; if still unclear, stop and mark as out

of scope.

RAG edge case: If embeddings are used for retrieval but a generative model produces
the analytical outputs, Q00 = YES (in scope). Code the primary use based on the
generative model.

Primary-use selection when multiple LLM uses: choose the single use to code by this
tie-breaker order: (1) do not consider embedding models; only consider generative
models that produce natural-language outputs (2) highest autonomy, then (3) highest
interpretive depth, then (4) most data processed, then (5) first appears in Methods.
NR vs NA: NR = Not reported/unclear; NA = not applicable.

Immediate text: only verbatim content included in the prompt for that call.
Unit-of-analysis mapping: tweets/short posts/headlines/reviews -> Paragraph/Chunk;
full article/transcript or a conversation processed as one input -> Single document;
chunked long docs -> Paragraph/Chunk; cross-document synthesis -> Multiple
documents/Corpus.

Select-all items: NONE is exclusive (do not combine with other options).

Rationale and evidence protocol (applies whenever a question has requires_reason =
true in the JSON schema):

32


===== PAGE BREAK =====

1) Precede the final answer to the coding question with a rationale block in
exactly this format:
[brief rationale (<=5 sentences) & evidence span which is an array of (1 to 10)
verbatim quotes. The quotes MUST be verbatim but can include ellipsis.]

2) After the rationale block, provide the final answer (the selected code or text
response) for that question.

3) For multiselect items, provide a single rationale block that justifies all
selections; include at least one quote per selected option when possible.

4) If you select NR or NONE, still provide a brief rationale and include evidence
quotes that show the lack of reporting (e.g., statements indicating absence of
details).

Questionnaire (updated with screening; all other items unchanged)
Part 0: Scope & Screening (paper-level)

QOO (select one): Screening - Does the paper use or evaluate a generative large
language model (LLM) that produces natural-language outputs (e.g., GPT-4, Claude,
Gemini, Llama, or a RAG setup)?
- YES (in scope; continue)
- NO (embedding-only like BERT or fine-tuning based on embeddings from a BERT-
like

model, or other non-generative models; out of scope)
- NR (Not reported/unclear)

Part 1: Study Identification & Metadata (Descriptive; paper-level)

QO1 (open text): First Author's Name
- Example: "Jane Doe"

QO2 (select one): Primary academic discipline

- Computer Science / AI Research

- Social Sciences (Sociology, Psychology, Political Science, Business, Economics)
- Humanities (History, Literature, Philosophy, etc.)

- Medicine / Health Sciences

- Law

- Education

- Other

- NR

QO3 (open text): Study's primary aim or objective (summarize or quote)

33


===== PAGE BREAK =====

Q04 (open text): Main research question(s)

QO5 (select one): Overall research approach
- Quantitative

- Qualitative

- Mixed-Methods

- Methodological / Technical Development

- Review / Synthesis

- Unclear / Not Applicable

- NR

Part 2: Research Context & LLM Role (Descriptive; primary use)

Important: If multiple generative LLM uses, code all parts based on the single use
chosen by the tie-breakers (generative use case -> highest autonomy -> highest
interpretive depth -> most data -> first appears in Methods).

Q06 (select one): Primary role of the LLM in this research

- Non-analytical support only (example: writing assistance, grammar fixes, reference
formatting)

- Analytical tool to process or analyze data (example: annotating interviews,
extracting entities, coding posts)

- Subject of study being evaluated or tested (example: can GPT-4 replicate human
coding? can Claude resolve pronouns?)

- Both a tool and the subject (example: LLM codes data and its outputs are also
evaluated/compared)

- NR

QO7 (select one): Study's primary objective regarding the LLM (based on what data

are given to the LLM)

- Application: Apply a known LLM to accomplish a research task (example: code
interviews using a fixed schema)

- Comparison: Compare LLMs/configurations or compare to a human/non-LLM benchmark
(example: GPT-4 vs Claude; LLM vs human labels)

- Exploration: Explore feasibility on a novel task (example: attempt latent theme
discovery in a new domain)

- NR

Q08 (select all that apply; NONE is exclusive): Data type(s) the LLM processed
- 1: Text (examples: transcripts, tweets, articles)

Images (examples: figures, scanned pages)

: Audio/Speech (examples: interview audio, podcasts)

: Tabular/Structured Data (examples: CSV tables, JSON records)

BW DN

34


===== PAGE BREAK =====

- NONE: Not reported/Unclear

QO9 (select one): Primary language of the data given to the LLM
- English only

- A single non-English language (example: Spanish)

- Multilingual (example: English + French)

- NR

Part 3: Interpretive Depth of the Task (Scored; primary use)

Q10 (select one): Nature of the task performed by the LLM (primary)
- 1: Information extraction (identify explicit facts)
Examples: extract dates, names, information explicitly stated.

- 2: Summarization or Synthesis (of explicit content)

Examples: summarize a passage; produce bullet highlights.

- 3: Initial qualitative coding (surface-level codes)

Examples: assign descriptive codes; label text such as political vs non-political;
sentiment (positive/negative/neutral); or place text on a left-to-right ideology
scale using a predefined rubric.

- 4: Thematic analysis or deeper qualitative coding (latent themes/relations)
Examples: identify underlying themes; relate concepts across segments; group
surface codes into higher-order themes or frames; connect patterns across
multiple segments or documents.

- 5: Deep Interpretation (hermeneutic inference, novel conceptual framing)
Examples: construct new typologies; propose and justify causal accounts beyond
text; theory-building or interpretive claims that go beyond predefined labels.

- NR

Note (rule-of-thumb for 3 vs 4 vs 5): If the task applies predefined, surface-

level

labels to segments, code 3. If it requires discovering or organizing latent

themes/relations across segments, code 4. If it requires novel conceptual framing

or theorizing beyond the given text/codes, code 5.

Q1i1 (select one): Understanding linguistic ambiguity required by the task. Code
what the task requires, not what could occur.
- 0: None (literal content suffices for correctness)
Examples: tables, forms, assigning topic labels to text like whether news
articles are about sports or not.
- 1: To some extent; occasional figurative language matters
Examples: some sarcasm/metaphor affects correctness on some items.
- 2: To a large extent; complex ambiguous language is central
Examples: irony detection; nuanced stance or insinuation.

39


===== PAGE BREAK =====

- NR

Q12 (select one): External context required beyond the immediate prompt (minimum

needed to complete the task)

- 0: None (all required facts in the prompt)

Examples: translate provided sentence; extract a number from pasted text.

- 1: Minor background (everyday/K-12 knowledge)

Examples: knowing UTC is a time standard; basic country regions.

- 2: Domain context (terms or conventions)

Examples: knowing CEDAW is a UN convention; disciplinary jargon.

- 3: Substantial specific context (external document/rubric/case facts not provided)
Examples: write a literature review without providing the papers; apply a rubric
only described but not given verbatim.

- NR

Q13 (select one): Reasoning required (minimum needed; ignore whether the model
actually had the external context)
- 0: Retrieval/formatting (copy/restate explicit content)
Examples: extract a date; reformat a table.
- 1: Single-rule transformation
Examples: unit conversion; apply a stated formula; paraphrase once.
- 2: Multi-step procedural reasoning
Examples: chain a few steps; apply multiple given rules; assign codes using a
provided rubric.
- 3: Abductive/unstated-assumption inference
Examples: infer implicit relations; resolve conflicting clues; code without a
fully explicit rubric.
- 4: Integrative/generative synthesis
Examples: synthesize across items; design/justify solutions; weigh trade-offs.
- NR

Q14 (select one): Was the analysis framework predefined or emergent?
- 1: Fully predefined (deductive)
Examples: fixed codebook applied; no new codes allowed.
- 2: Somewhat predefined (mixed)
Examples: seed schema with permission to add/refine codes.
- 3: Fully emergent (inductive)
Examples: grounded open coding; categories generated from data.
- NR

Q15 (select one): Primary unit of analysis for the LLM task (use mapping rules above)
- 1: Word/Token (examples: POS tags, NER)

36


===== PAGE BREAK =====

Sentence (examples: sentiment per sentence)

: Paragraph/Chunk (examples: code a tweet or a chunk; summarize a section)
Single document (examples: a full article or full interview processed as one)
: Multiple documents / Corpus (examples: cross-document synthesis; literature
review)

NR

oF WN

Part 4: Autonomy & Human Oversight (Scored; primary use)

Q16 (select one): Human scaffolding of the task. Score end-to-end pipeline.

0: Not decomposed (model plans end-to-end)

Example: agentic workflow given overall goal.

1: Small extent (high-level objective; model plans most steps)

Example: "identify three themes and give quotes."

2: Moderate extent (outline provided; some freedom)

Example: "follow this outline [collect -> clean -> model -> evaluate]; choose
suitable methods."

3: Large extent (detailed step-by-step; fixed checklist/codebook)

Example: strict per-item form; explicit rule-by-rule application.

NR

Q17 (select one): Human supervision of the LLM's work
- 0: None (review only at the end)

1: Occasional (spot checks on small samples)

2: Regular (scheduled checkpoints with possible edits)
3: Intensive (approval required at each step)

NR

Q18 (select one): How were instructions (prompts) given?

Interactive chat (manual, ad-hoc conversation and refinement)

Fixed prompt or template (same structure applied systematically, often via script)
Agentic (autonomous framework with tools/planning)

NR

Q19 (select one): Did the study explicitly prompt the LLM to show its reasoning
- process? Unless the prompt asks for CoT or a 'thinking' model is used, choose NO

f

or classifiers

Yes, Chain-of-Thought prompting (e.g., "think step by step")
Yes, reasoning/thinking model (e.g., o1; Claude with thinking)
Yes, both (reasoning model and explicit CoT)

No (no explicit reasoning requested and no reasoning model used)
Not reported/Unclear

37


===== PAGE BREAK =====

Q20 (select one): Was the LLM asked to provide justification or rationale for its
outputs?
- Yes (requested explanations/justifications)
- No
Example: outputs are labels only and no explanations are requested.
- Not reported/Unclear

Q20 (select one): Were reasoning examples provided to guide the LLM?
- Yes (few-shot examples showing reasoning steps)

- No

- Not reported/Unclear

Q22 (select one): Iterative refinement between human and LLM

- 0: Single-pass (no mid-process feedback)

- 1: Minimal iteration (minor prompt tweaks then re-run)

- 2: Moderate iteration (multiple rounds; schema refined; re-coding)
- 3: Intensive iteration (continuous back-and-forth adjustment)

- NR

Part 5: Technical Specification & Reproducibility (Descriptive; primary use unless
marked)

Q23 (select one): How was the model identified?

- 0: Vague/Unspecified (example: "an LLM")

- 1: Model family only (example: "GPT", "Claude-Sonnet")

- 2: Exact name/version (example: "GPT-4o-mini"), no release

- 3: Exact name, version, and release (example: "gpt-4-1106-preview")
- NR

Q24 (open text; paper-level): List all model names/versions/releases mentioned
(example: "[gpt-4-1106-preview; claude-2.1]")

Q25 (select one): Were model settings (hyperparameters) reported?
- NO: Not reported

- YES: Yes (example: temperature, top_p)

- NA: Interface did not allow setting (example: basic chat UI)

Q26 (open text): If reported, list specific parameters and values (example:
"gpt-4.1-mini, temperature=0.7; claude-3.5-haiku, temperature=1.0")

Q27 (select one): Were the prompts made available (for the primary use)?

38


===== PAGE BREAK =====

- Yes, verbatim in paper or appendix (templates with placeholders count)
- Yes, in repository or supplements (templates with placeholders count)
Partially (structure/excerpts, but not full text)

- No (neither shared nor described)

Q28 (open text): If available, paste the full, verbatim prompt(s), including
system instructions and few-shot examples.

Q29 (select all that apply; NONE is exclusive; paper-level): What materials were
made available?

- 1: Prompts used to instruct the LLM

- 2: Code or notebooks

- 3: Dataset the LLM analyzed

Example: if replication repo with raw data => select [1,2,3].

NONE: None of the above were shared

- NR

Part 6: Evaluation & Validation (Descriptive; primary use unless marked)

Q30 (select all that apply; NONE is exclusive): How was the quality of the LLM's
output evaluated?

- 1: Comparison to human standard (>= half of outputs compared)

- 2: Qualitative review/spot-checking (small subset reviewed)

- 3: Only using other LLMs as judges (no human comparison)

- NONE: No formal evaluation described

- NR

Q31 (select one): Was the LLM's performance compared against a benchmark?
- NO: No (analyzed on its own)
- YES: Yes (compared to human or non-LLM method)
Example: Reported performance against human gold labels.
- NA: Not applicable (purely exploratory)
- NR: Not reported/Unclear

Q32 (select one): Did authors discuss limitations/biases of their LLM approach?
- NO: No discussion
- BRIEF: Mentioned briefly
Example: The paper contains one sentence which mentions limitations.
- DETAILED: Dedicated discussion
Example: At least one paragraph dedicated to the discussion of limitations
- NR: Not reported/Unclear

39


===== PAGE BREAK =====

Q33 (select one; paper-level): Were reliability/agreement statistics reported?
- None: no agreement or performance vs human reported

- Human-human reliability only (example: Cohen's kappa, Krippendorff's alpha)
- Human-LLM reliability only (example: model-vs-human metrics like F1, kappa)
- Both human-human and human-LLM reported

B. Letter 53

For the constitutionalism experiment, we performed the study with three different orches-
trations. Following are raw final results. All studies have been performed with gpt-5 (“gpt-
5-2025-08-07”), under high reasoning, and medium verbosity, no explicity token limit, and
other parameters are fixed by the model.

B.1 Baseline (No Decomposition)

For the baseline, we asked them model to extract elements of constitutionalism from the
letter, without giving the model the elements or giving it web access. We iterated a few
times until the model performed the task we were asking it to do in what appears on the
surface to be what was asked.*

Below is a concise extraction of constitutionalism elements articulated in Imam Ali’s
Letter 53 to Malik al-Ashtar. Each entry lists name, short definition, directly quoted evidence
from the letter (short, verbatim), brief rationale, and a confidence score.

Name: Supremacy of higher law Definition: Executive action must conform to a higher, binding law (Qur’an and
Sunnah). Evidence: "Refer back to God and His Messenger whatever weighs upon you.”® ; "The referral to God is
taking the decisive of His Book.”!° Rationale: Directs the governor to resolve hard cases by authoritative sources,
placing higher law above executive discretion—a core rule-of-law constraint. Confidence: 0.95

4. This is exact prompt used with the letter injected between the Letter tags:

Task: Extract elements of constitutionalism from 'Letter 53: An order to Malik al-Ashtar'
which is a letter from Imam Ali to Malik al-Ashtar, his governor for Egypt in year AD 659.

Deliverables:
- A concise list of constitutionalism elements present in the letter, each with:
name, definition (1-2 lines), evidence (short quote[s]), rationale (2-4 lines),
and confidence (0-1).
- Keep quotes verbatim and short.
- Cite textual evidence only from the letter.
Formatting: Provide a readable structured output.
-We want to see whether and to what extent the letter is one of the earliest texts in human history
that has introduced essential elements of a constitution. Focus on the core principles and not
on more cosmetic matters like federal/centralized governance.
<Letter> RAW ARABIC TEXT OF THE LETTER HERE </Letter>

40


===== PAGE BREAK =====

2. Name: Limited government (no autocratic command) Definition: Authority is not absolute; command must
be justified, not merely obeyed. Evidence: "Do not say: 'l am empowered—I command and | am obeyed’.”!4
Rationale: Explicitly rejects the “because | command” paradigm, limiting executive power to lawful, reasoned
action. Confidence: 0.94

3. Name: Equality and human dignity Definition: Equal worth and protection for all, regardless of creed or
status. Evidence: "Either your brother in religion, or your peer in creation.”!? ; "Bind the right upon whoever
it is due to, whether near or far.”!3 Rationale: Affirms universal dignity and equality before the law, including
non-co-religionists, and mandates equal application to kin and strangers. Confidence: 0.95

4. Name: Impartial justice; no favoritism Definition: Justice must not be skewed by kinship or personal inter-
est. Evidence: "Do justice ... against yourself, and against the special among your household.”!* ; "And [do
justice against] those among your subjects toward whom you have a liking.”!° Rationale: Requires impartiality
even against one’s own circle and preferences—an anti-nepotism, anti-partiality principle central to constitutional
justice. Confidence: 0.92

5. Name: Independent, competent judiciary Definition: Judges must be highly qualified, impartial, and institu-
tionally supported. Evidence: "Choose for judging between people the best of your subjects."1° ; "Frequently
oversee his judgments, and make ample provision for him.”!” Rationale: Stipulates stringent judicial qualities and
independence via resources/status, shielding adjudication from influence—key to the separation of judging from
ruling. Confidence: 0.90

6. Name: Procedural fairness (verification, privacy, restraint) Definition: Verify accusations, protect privacy, and
avoid hasty or celebratory punishment. Evidence: "Do not be hasty to believe a talebearer.”1® ; "The governor is
the one most entitled to cover them.”!® Rationale: Skepticism toward informers and protection of hidden faults
deter arbitrary sanctions; urges deliberation and restraint—core due-process values. Confidence: 0.88

7. Name: Protection of life and accountability for state violence Definition: Unlawful killing is forbidden; redress is
due to victims’ families. Evidence: "Beware blood and its shedding without its due right.”2° ; "So give the slain’s
guardians their due.”?! Rationale: Sanctifies life, prohibits illegitimate force, and compels accountability—placing
the ruler under legal constraint for lethal force. Confidence: 0.95

8. Name: Right to petition and public hearing Definition: Guaranteed access for people to present needs and
grievances. Evidence: "Set aside a time for those with needs from you."2* ; "And sit for them in a public
assembly.”2° Rationale: Institutionalizes an open audience for petitions, enabling direct redress and participation—
an early due-process and participatory safeguard. Confidence: 0.95

9. Name: Transparency; avoidance of seclusion Definition: The ruler should remain accessible; secrecy impairs
governance. Evidence: "So do not prolong your seclusion from your subjects.”24 ; "Seclusion from them cuts
them off from knowledge of what you are secluded behind.””° Rationale: Open governance preserves information
flow and corrects errors, enabling accountability and informed decision-making. Confidence: 0.90

10. Name: Consultation and deliberation with qualified advisors Definition: Decisions should be informed by
experts; exclude advisors with biasing vices. Evidence: "And increase your study with the scholars and your
converse with the sages.”2° ; "And do not admit into your council a miser.”2” Rationale: Embeds consultative
governance and standards for counsel quality—a deliberative check on executive discretion. Confidence: 0.85

11. Name: Institutional differentiation of state functions Definition: Distinct roles (military, judiciary, adminis-
tration, revenue, commerce, vulnerable) are recognized and interdependent. Evidence: "Know that the subjects
are classes; some are not set right except by others.”?° Rationale: Describes a structured polity with specialized
functions—an antecedent to constitutional ordering of state organs. Confidence: 0.78

12. Name: Merit-based appointments; anti-nepotism Definition: Offices filled by competence and testing, not fa-
voritism. Evidence: "So appoint them by testing.”2° ; "And do not appoint them out of partiality and favoritism.”2°
Rationale: A professional civil service reduces patronage and abuse, anchoring impartial administration under law.
Confidence: 0.92

13. Name: Oversight and anti-corruption enforcement Definition: Independent monitoring and firm penalties for
breach of trust. Evidence: "And dispatch observers from those of truthfulness and loyalty over them.”*! ; "And

Al


===== PAGE BREAK =====

brand him with betrayal.’°? Rationale: Audits plus sanctions deter corruption and hold officials to account—
statutory checks within the executive. Confidence: 0.93

14. Name: Public interest over elite preference Definition: Prioritize welfare of the many over the few. Evidence:
"The anger of the common people overwhelms the pleasure of the elite.”°3 ; "The anger of the elite is forgiven
with the satisfaction of the common people.’*4 Rationale: Treats the common good as the governing criterion,
curbing elite capture of policy—an early majoritarian principle. Confidence: 0.87

15. Name: Social welfare duties; equal aid to the vulnerable Definition: The state owes support to the poor,
elderly, disabled, and needy. Evidence: "Fear God, fear God, regarding the lowest class.” ; "And set aside for
them a share from your public treasury.’°° Rationale: Mandates a public safety net financed from the treasury;
embeds socio-economic rights within the constitutional order. Confidence: 0.95

16. Name: Fiscal constitutionalism (fair taxation; development-first) Definition: Tax policy must serve public
welfare and prioritize" “ (productive development). Evidence: "Look after the matter of revenue in what sets
its people right.”2" ; "Let your attention to the cultivation of the land be greater.”** Rationale: Rejects extractive
taxation; ties revenue to economic vitality and citizens’ well-being—constraints typical of constitutional finance.
Confidence: 0.90

17. Name: Market regulation; anti-monopoly and fair pricing Definition: Prevent hoarding; enforce fair weights

and non-exploitative prices. Evidence: "So prevent hoarding.”*® ; "With just scales and prices that do not injure.”*°

Rationale: Authorizes regulatory safeguards against private market abuses—protecting economic rights and the
public interest. Confidence: 0.90

18. Name: Integrity of public resources; ban on privileges Definition: No private grants/monopolies for cronies at
public expense. Evidence: "And do not grant any of your entourage ... an estate.”4! ; "And let none covet from
you the establishment of a contract.”4? Rationale: Forbids elite capture of land/commons; enforces equality and
stewardship of public assets—a core anti-corruption norm. Confidence: 0.92

19. Name: Treaty fidelity and good faith Definition: Honor covenants; reject perfidy and trickery in agreements.
Evidence: "So protect your covenant with fidelity, and guard your pledge with trustworthiness.’*? ; "And do not
betray your pledge.’44 Rationale: Binds the executive to keep agreements—an essential rule-of-law commitment
in external and internal relations. Confidence: 0.93

20. Name: Respect for precedent and legal continuity Definition: Preserve beneficial settled practices; avoid
harmful innovations. Evidence: "Do not overturn a sound (established) tradition."*° ; "And do not introduce a
practice that harms.”4° Rationale: Stabilizes governance through continuity and community consensus, constrain-
ing arbitrary legal change—hallmarks of constitutional order. Confidence: 0.90

Summary note: The letter articulates a rule-of-law-bound, accountable executive; an independent judiciary; proce-
dural safeguards; equality; public-interest primacy; socio-economic duties; fiscal and market constraints; integrity

of public assets; and treaty fidelity—together forming a robust early blueprint of constitutional governance.

B.2 Two-Stage (Two-level Decomposition)

First, elements of costitutionalism are extracted from the ‘Constitutionalism’ entry of Stan-
ford Encyclopedia of Philosophy.(Waluchow and Kyritsis 2023) This is iterated with human
feedback, until we have an acceptable set of elements.

Second, the elements and the raw text of the letter are given to the model to extract
elements, give scores, and provide verbatim quotations supporting the decisions.

B.2.1 Prompts Used

Prompt 1: Element Extraction from Stanford Encyclopedia of Philosophy

42


===== PAGE BREAK =====

Task: From the full article below (enclosed in <SEP>),

extract a practical list of core constitutionalism elements for use in textual
analysis; limit the list to between 10 to 20 most important elements.

Note that this is for a text that is more than 1000 years old.

Deliverable:

-a JSON list of elements: { dimensions: [ { element_key, element_label,
short_definition, identification_rubric, evidence_expectations} ] }

- identification_rubric: 2-4 bullet criteria to identify the element in a
primary text.

- evidence_expectations: 1-2 bullets describing acceptable textual evidence.

#Important requirement 1: all inner quotations in the json part of the output
must be properly escaped. This json is going to be read by computer code.
#Important requirement 2: we want to do this for an old text and we want to see
whether and to what extent that text is one of the earliest texts in human
history that has introduce essential elements of a constitution. Focus on the
core principles and not on more cosmetic matters like federal/centralized
governance.

<SEP>

[Stanford Encyclopedia of Philosophy entry on Constitutionalism]

</SEP>

Prompt 2: Analysis of Letter 53 Against Extracted Elements
task: produce evidence of constitutional elements in an ancient text

elements are as follow:
<elements>{elements}</elements>

your task is to go through all elements and analyze the text you are given
according to each element.

the text to be analyzed is: <text>{letter}</text>

deliverable:

for each element, provide a short explanation of whether that element is
absent or present in the document, and if it is present, provide direct
verbatim quotations that support your claim.

Finally, give it a strength of presence score. Give a score of 0 for when
this element is totally absent, and 10, when this element has the strongest
presence imaginable.

43


===== PAGE BREAK =====

Structure the output as:

- <explanation> ... </explanation>
- <quotations> <quote1> ... </quote1>, <quote2> ....<quote2>, .... </quotations>
- <score> ... </score>

B.2.2 Results

[1] Legal limits on rulers’ powers - <explanation>Present. The letter repeatedly subordinates the governor to
binding higher norms (God’s law, the Book and Sunnah) and forbids autocratic fiat. It frames office as a trust
with moral-legal constraints the ruler must obey.</explanation> - <quotations> <quotel>"He commanded him
to fear God ... and to follow what He commanded in His Book: His obligations and His sunan.”</quotel>*”
<quote2>"Do not say: 'l am empowered—I command and | am obeyed'”</quote2>4° <quote3>"For you are
above them; the authority over you is above you; and God is above the one who appointed you.”</quote3>*9
<quote4>"Do justice to God and do justice to the people, against yourself."</quote4>°° </quotations> -

<score>9< /score>

[2] Sovereignty versus government offices - <explanation>Present. Ultimate authority is located in God’s law
and the Prophet’s Sunnah, distinct from the governor's day-to-day power; obedience framework places “God and
His Messenger” above rulers.</explanation> - <quotations> <quotel>”O you who believe! Obey God and
obey the Messenger and those in authority among you; and if you disagree about anything, refer it to God and
the Messenger.”</quotel>°! <quote2>"For you are above them; the authority over you is above you; and God
is above the one who appointed you.”</quote2>°? <quote3>"And each one, God has named his share ... in
His Book or the Sunna of His Prophet ... a covenant from Him kept with us."</quote3>°? </quotations> -
<score>8< /score>

[3] Entrenchment - <explanation>Present. Foundational norms are treated as settled and inviolable through
strong language on “sunnah,” covenants, and the sacred duty to keep oaths and treaties.</explanation> -
<quotations> <quotel>"Do not overturn a sound tradition practiced by the leaders of this community ... and
do not introduce a practice that harms anything of those past traditions.”</quotel>°* <quote2>"Make yourself
a shield for what you have granted.”</quote2>°° <quote3>"For there is nothing among the obligations of God
... greater than magnifying fidelity to covenants.”</quote3>°° </quotations> - <score>7</score>

[4] Writtenness and custom - <explanation>Present. The document is itself a written  (charter/instruction),
and it grounds authority in the written Book and the Prophet's recorded Sunnah.</explanation> - <quotations>
<quotel>"This is what the servant of God, Ali, the Commander of the Faithful, ordered ... in his covenant to
him."</quotel>°’ <quote2>"The referral to God is taking the decisive of His Book, and the referral to the
Messenger is taking his Sunna.”</quote2>°8 <quote3>"Do not overturn a sound tradition .... and do not
introduce a practice.”</quote3>°? </quotations> - <score>9</score>

[5] Allocation and checks of power - <explanation>Present. The text differentiates functions (army, judges,
tax, scribes, traders, poor) and installs checks: careful appointments, supervision, independent judges, and secret
oversight of officials.< /explanation> - <quotations> <quotel>"And know that the subjects are classes ... among
them are the soldiers of God ... the scribes of the common and the elite ... the judges of justice ... the officials
of equity ... the people of jizya and kharaj ... the traders ... the lowest class."</quotel>°° <quote2>"Then
choose for judging between people the best of your subjects.” </quote2>°! <quote3>"Then inspect their deeds,
and dispatch observers from those of truthfulness and loyalty over them.”</quote3>°? <quote4>"And do not
appoint them out of partiality and favoritism.”</quote4>°? </quotations> - <score>9</score>

[6] Supremacy of constitutional norms - <explanation>Present. The Book and Sunnah are supreme standards; per-
sonal commands must yield to these higher norms and to <explanation/>". “ - <quotations> <quotel>"And
if you disagree about anything, refer it to God and the Messenger.”</quotel>°* <quote2>"And God is above
the one who appointed you.”</quote2>°° <quote3>"Bind the right upon whoever it is due to, whether near
or far."</quote3>°° <quote4>"Do not say: 'l am empowered—I command and | am obeyed'.”</quote4>°%7
</quotations> - <score>8</score>

44


===== PAGE BREAK =====

[7] Rights as limits on power - <explanation>Present. The letter protects life, fair treatment, the weak and poor,
access to the ruler, fair markets, and bars favoritism and confiscatory grants—functioning as rights constraints on
authority.</explanation> - <quotations> <quotel>"Then fear God, fear God, regarding the lowest class ... and
set aside for them a share from your public treasury.’</quotel>°*% <quote2>"‘A nation will never be sanctified
in which the weak cannot take his right from the strong without stammering.”"</quote2>°? <quote3>” Beware
blood and its shedding without its due right.”</quote3>"° <quote4>"Let the sale be an easy sale .... and
prices that do not injure either party."</quote4>7! <quote5>"And do not grant to any one of your entourage

an estate ... so that the enjoyment of that is theirs without you, and its blame upon you.”</quote5>”
</quotations> - <score>8</score>

[8] Procedural limits - <explanation>Present. Specifies procedures for consultation, adjudication, public audience,
appointments by merit, evidentiary standards for disciplining officials, and measured punishment. </explanation>
- <quotations> <quotel>"Set aside a time for those with needs ... and sit for them in a public assembly

. seat away from them your soldiers and your helpers.”</quotel>"? <quote2>"Then look into the affairs of
your officials: appoint them by testing, and do not appoint them out of partiality and favoritism.”</quote2>"4
<quote3>"If any one of them extends his hand to treachery ... that suffices you as a witness; so you inflict
punishment upon him.”</quote3>"° <quote4>"And if you disagree about anything, refer it to God and the
Messenger.”</quote4>"° </quotations> - <score>9</score>

[9] Jurisdictional limits - <explanation>Partly present. The text carves out commons and shared resources
from private appropriation, constrains war/peace discretion by divine-justice criteria, and forbids monopolistic
practices—placing subject-matter limits on the governor.</explanation> - <quotations> <quotel>” Beware
appropriating to yourself what the people share equally."</quotel>’” <quote2>"Do not grant ... in a water-
right or a common enterprise.” </quote2>"8 <quote3>"Do not reject a peace to which your enemy calls you
in which there is God's pleasure.’</quote3>"? <quote4>"So prevent hoarding; for the Messenger of God ...
prohibited it."</quote4>°° </quotations> - <score>6</score>

[10] Amendment rules - <explanation>Weak/mostly absent. The letter urges preservation of good established
practices and avoidance of harmful innovations but does not specify a formal procedure to amend foundational
norms.</explanation> - <quotations> <quotel>”Do not overturn a sound tradition ... and do not introduce a
practice that harms.”</quotel>*! </quotations> - <score>2</score>

[11] Interpretation and enforcement - <explanation>Present. It establishes adjudicative offices with detailed qual-
ifications, directs disputes to “God and the Messenger,” and empowers the ruler to investigate and punish official
misconduct.</explanation> - <quotations> <quotel>”"Then choose for judging between people the best of your
subjects.”</quotel>* <quote2>"Then frequently oversee his judgments.”</quote2>°? <quote3>"And refer
back to God and His Messenger whatever weighs upon you."</quote3>*4 <quote4>"If any one of them extends
his hand to treachery ... so you inflict bodily punishment upon him ... and brand him with betrayal.”</quote4>®°
</quotations> - <score>8</score>

[12] Binding political conventions - <explanation>Present. Good ancestral practices (_ ) are treated as binding
conventions that rulers must not break because they sustain social cohesion and good governance. </explanation>
- <quotations> <quotel>”"Do not overturn a sound tradition practiced by the leaders of this community, by which
affection has been joined together.”</quotel>°®° <quote2>"And it is obligatory upon you to remember what has
passed for those who preceded you: of a just government, or a virtuous practice.”</quote2>°" </quotations> -
<score>7</score>

[13] Due process and fair adjudication - <explanation>Present. Emphasizes impartial, patient judges; public
access to the ruler; avoidance of hasty punishment; measured sanctions; and hearing complaints without intimi-
dation.</explanation> - <quotations> <quotel>"Least bored by the litigant’s repeated approach ... and most
patient in uncovering matters."</quotel>°° <quote2>"Set aside a time for those with needs ... a public as-
sembly ... so that their speaker speaks to you without stammering.’</quote2>°? <quote3>"Do not hasten to a
sudden [punitive] act when you find an alternative to it.”</quote3>°° <quote4>"Then punish him exemplarily,
and punish without excess.”</quote4>°! </quotations> - <score>8</score>

[14] Consent in lawmaking - <explanation>Weak. Although it stresses governing with the satisfaction of the

45


===== PAGE BREAK =====

populace and preserving practices accepted by the community, it does not require formal consent by assemblies for
legislation or taxation.</explanation> - <quotations> <quotel>”Let the most beloved matters to you be those
most centered in right ... and most unifying of the subjects’ satisfaction.”</quotel>°* <quote2>"For the anger
of the common people overwhelms the pleasure of the elite.”</quote2>9? <quote3>"Do not overturn a sound
tradition ... upon which the subjects have been set right.”</quote3>%+ </quotations> - <score>3</score>

[15] Stability and continuity - <explanation>Present. Strong emphasis on continuity with prior just govern-
ments and established practices, aiming for lasting social order and cohesion.</explanation> - <quotations>
<quotel>"Do not overturn a sound tradition ... by which affection has been joined together, and upon which
the subjects have been set right.”</quotel>9° <quote2>"And it is obligatory upon you to remember what has
passed for those who preceded you: of a just government, or a virtuous practice.” </quote2>%° </quotations> -
<score>7</score>

[16] Abstract commitments enabling adaptation - <explanation>Present and strong. The letter is filled with gen-
eral moral commitments—justice, mercy, equity, right, moderation—whose application can evolve. </explanation>
- <quotations> <quotel>"Let the most beloved matters to you be those most centered in right, and most
comprehensive in justice."</quotel>°” <quote2>"Imbue your heart with mercy for the subjects.”</quote2>%°
<quote3>"Do justice to God and do justice to the people, against yourself."</quote3>°? </quotations> -
<score>9< /score>

[17] Remedies for constitutional breach - <explanation>Present. Specifies concrete sanctions for officials’ cor-
ruption, market abuses, and unlawful killings, including bodily punishment, public disgrace, restitution, and
qisas.</explanation> - <quotations> <quotel>"If one of them extends his hand to treachery ... that suffices
as a witness; so you inflict bodily punishment upon him ... then set him up in the place of humiliation, and brand
him with betrayal.”</quotel>!°° <quote2>"Whoever commits hoarding after your prohibition, then punish him

101

exemplarily, and punish without excess.”</quote2>*°' <quote3>"And there is no excuse for you ... in deliberate

killing, for in it is retaliation against the body.”</quote3>1!0? </quotations> - <score>8</score>

B.3 Multi-Stage (Horizontal and Vertical Decomposition)

First, elements of costitutionalism are extracted from the ‘Constitutionalism’ entry of Stan-
ford Encyclopedia of Philosophy.(Waluchow and Kyritsis 2023) This is iterated with human
feedback, until we have an acceptable set of elements.

Second, the elements and the raw text of the letter are given to the model, in parallel,
where for each element, there is one separate run of the model. This is iterated until the
model performs what is expected.

Third, the evidence collected from the second step are synthesized into a final report.
This is iterated until the result is satisfactory.

B.3.1 Prompts Used

Prompt 1: Element Extraction from Stanford Encyclopedia of Philosophy
Task: From the full article below (enclosed in <SEP>),
extract a practical list of core constitutionalism elements for use in textual

analysis; limit the list to between 10 to 20 most important elements.
Note that this is for a text that is more than 1000 years old.

46


===== PAGE BREAK =====

Deliverable:

-a JSON list of elements: { dimensions: [ { element_key, element_label,
short_definition, identification_rubric, evidence_expectations} ] }

- identification_rubric: 2-4 bullet criteria to identify the element in a
primary text.

- evidence_expectations: 1-2 bullets describing acceptable textual evidence.

#Important requirement 1: all inner quotations in the json part of the output
must be properly escaped. This json is going to be read by computer code.
#Important requirement 2: we want to do this for an old text and we want to see
whether and to what extent that text is one of the earliest texts in human
history that has introduce essential elements of a constitution. Focus on the
core principles and not on more cosmetic matters like federal/centralized
governance.

<SEP>

[Stanford Encyclopedia of Philosophy entry on Constitutionalism]

</SEP>

Prompt 2: Individual Element Analysis
task: produce evidence of constitutional elements in an ancient text

elements are as follow:
<elements>{elements}</elements>

your task is to focus on element number {i} which is [{elm}]

the text to be analyzed is: <text>{letter}</text>

deliverable:

provide a short explanation of whether this element is absent or present in the
document, and if it is present, provide direct verbatim quotations that support
your claim. Finally, give it a strength of presence score. Give a score of 0 for
when this element is totally absent, and 10, when this element has the strongest
presence imaginable.

Structure the output as:

- <explanation> ... </explanation>
- <quotations> <quote1> ... </quote1>, <quote2> ....<quote2>, .... </quotations>
- <score> ... </score>

Prompt 3: Synthesis of All Elements

task: produce evidence of constitutional elements in an ancient text

AT


===== PAGE BREAK =====

We have broken the task down into 14 elements. for each element, we have produced
a short report with an explanation (provided in <explanation> tags),

quotations from the text (provided in <quotation> tags), and a 0-to-10 score
(provided in <score> tags).

Your job is to synthesize all of the elements you are given into a final report.
In the final report you need to provide a comprehensive discussion about

the absence or existence (and strength) of each element of constitutionalism in
the text support with direct quotations.

for quotations, write an English translation and then inside parentheses give the
exact verbatim quotation. In the end, produce a summary table.

Here is the text: <text>{letter}</text> which is a letter from Imam Ali to Malik
al-Ashtar, his governor for Egypt in year AD 659.

The elements we use for understanding constitutionalism are provided in <elements>
tags followed by the analysis we have obtained for each element in <analysis> tags:
{results}

B.3.2 Results

Final report: constitutional elements evidenced in Imam Ali's Letter to Malik al-Ashtar (AD 659)

1) Legal limits on rulers’ powers (limited government) — Present, strong - The governor's authority is repeat-
edly and explicitly bounded by higher, pre-existing norms (God’s Book, the Prophet's Sunna, established sound
practices), with direct prohibitions against arbitrary rule, self-assertion, favoritism, monopolization, and unlawful
bloodshed. - Selected evidence: - "He commanded him to fear God, to prefer His obedience, and to follow what
He commanded in His Book: His obligations and His sunan.”!93. - "For you are above them; the authority over
you is above you; and God is above the one who appointed you."!4. - "Do not say: 'l am empowered—| command
and | am obeyed’.”!0°. - "Beware blood and its shedding without its due right.”1°°. - Score: 9

2) Sovereignty versus government offices — Present, strong - The text locates ultimate authority above the
officeholder—in God, His Book, the Prophet’s Sunna, and binding communal norms—treating the governor as a
delegate accountable to that source. - Selected evidence: - "For you are above them; the authority over you is
above you; and God is above the one who appointed you."°7. - "Refer back to God and His Messenger whatever
weighs upon you ... the referral to God is taking the decisive of His Book, and the referral to the Messenger is
taking his unifying Sunna."1°8. - "Beware vying with God in His greatness and resembling Him in His might.”1°9.
- Score: 9

3) Entrenchment of constraints — Present, substantive-sacral, not procedural - Foundational norms are framed
as covenants and sacred obligations that cannot be undone at will; the letter forbids overturning established
righteous practices and requires strict fidelity to covenants even under pressure. No formal amendment procedure
is set out, but the language entrenches the constraints. - Selected evidence: - "Do not overturn a sound tradition
practiced by the leaders of this community .. and do not introduce a practice that harms anything of those past
traditions.”!!9, - "And each one, God has named his share and set its limit and obligation in His Book or the
Prophet's Sunna—a covenant from Him kept with us.”!!!. - "If you conclude a covenant ... then protect your
covenant with fidelity ... and make yourself a shield for what you have granted.”!1?. - Score: 7

4) Writtenness and custom (constitutional norms written or unwritten) — Present, strong - The letter presents
itself as a formal “covenant” (Cahd), and binds governance to a superior written source (the Book) and author-
itative customary source (Sunna), instructing rulers to adjudicate by them and to preserve established sound

48


===== PAGE BREAK =====

practices. - Selected evidence: - "This is what the Commander of the Faithful ordered .. in his covenant to
him.”!!8, - "Follow what He commanded in His Book: His obligations and His sunan.”!!4. - "Do not overturn a
sound tradition ... and do not introduce a practice that harms earlier traditions.”!!°. - Score: 9

5) Allocation and checks of power — Present, strong - The text distributes governmental functions (military,
scribes, judges, fiscal/administrative officials, market regulation) and embeds checks: judicial independence,
oversight through inspectors (“eyes”), open petition sessions, merit-based appointments, and subordination to
higher law. - Selected evidence: - "Know that the populace are classes .. among them the soldiers of God, the
scribes of the common and the elite, the judges of justice, and the officials of equity and gentleness.”11°. - "Then
choose for judging between people the best among your subjects ..."'!7. - "Then inspect their deeds, and dispatch
observers from those of truthfulness and loyalty over them.”!!8. - "Set aside a time for those with needs ... sit for
them in a public assembly ... until their speaker speaks to you without stammering.”!19. - Score: 8

6) Supremacy of higher law — Present, strong - Higher law (Book and Sunna) prevails over ordinary commands;
disputed matters must be referred to it; the governor cannot claim his office places him above it. - Selected
evidence: - "Refer back to God and His Messenger ... the referral to God is taking the decisive of His Book, and
the referral to the Messenger is taking his unifying Sunna.”!2°. - "For you are above them; the authority over you
is above you; and God is above the one who appointed you.”!2!. - "Do not overturn a sound tradition ... then the
reward is for the one who established it, and the burden upon you for what you broke.”!??. - Score: 9

7) Rights as limits on power (substantive rights against the state) — Present, strong - The letter constrains state
action in rights-protective terms: bans on oppression, arbitrary punishment, unlawful killing; guarantees of access
to justice; equality of obligation on near and far; protection against monopolies and economic abuse. - Selected

evidence: - "Do not be over them a ravening beast, coveting their consumption."!73. - "Beware blood and its
shedding without right .. and there is no excuse for you ... in deliberate killing, for in it is retaliation against the
body.”!74, - "Set aside a time for those with needs ... ‘A nation will never be sanctified in which the weak cannot

take his right from the strong without stammering.”!2°. - "Prevent hoarding; let trade be easy, with just scales

and prices that do not injure either party."!2°. - "Bind the right upon whoever it is due to, whether near or
far."127_ - Score: 8

8) Procedural constraints on governance — Present, strong - The letter prescribes the manner of official action:
who may be consulted, how to appoint/supervise judges and officials, how to verify accusations, how to hold open
audiences, how to formalize treaties, how to proceed against market abuses, how to lighten taxes upon complaint,
and how to publicly justify contested acts. - Selected evidence: - "Do not admit into your council a miser ... nor
a coward ... nor a greedy person.”!78. - "Do not be quick to believe a talebearer."!79. - "Set aside a time for
those with needs ... sit for them in a public assembly ... until their speaker speaks to you without stammering.”!°°.
- "Whoever commits hoarding after your prohibition, punish him, and punish without excess."!°!. - "Do not
conclude a covenant where defects can pass; do not rely on insinuation after confirmation and attestation.”!°. -
"If they complain of burden or injury ... lighten from them what you hope will rectify their affairs."1°3. - Score: 9

9) Jurisdictional competence limits — Present, strong - The letter defines the office’s remit and bars interference
with what is outside it (e.g., hidden/private faults), places common resources and God-defined fiscal shares beyond
alteration, and makes treaties non-revocable at will. - Selected evidence: - "When he appointed him over Egypt:
the collection of its revenue, fighting its enemy, the reform of its people, and the building of its lands.”!3*.
"In people there are faults; the governor is the one most entitled to cover them. Do not uncover what is hidden
from you; your duty is to purify what appears; God judges what is hidden from you."13°. - "And each one, God
has named his share and set its limits ..."1°°. - "And do not grant to any of your entourage an estate ... in a
water-right or a common work ... whose burden they shift onto others."!°7. - "Do not betray your covenant ...
and do not let the straitness of an affair in which God’s covenant binds you call you to seek its rescission without
right."188. - Score: 8

10) Amendment meta-rules — Absent - The letter contains no rule specifying who or how foundational norms
may be amended. It counsels preserving sound established practices (entrenchment), but sets no amendment
procedure. - Score: 0

11) Interpretation and enforcement mechanisms — Present, strong - The letter creates and empowers adjudication

49


===== PAGE BREAK =====

(judges), stands up an interpretive hierarchy (Book and Sunna), requires resources and protection for judges,
institutionalizes complaint sessions, and prescribes official oversight and punishment for breaches. - Selected
evidence: - "Then choose for judging between people the best among your subjects ..."1°9. - "Then frequently
oversee his judgments; give him what removes his need ... and grant him status with you.”!4°. - "Refer matters to
God and His Messenger ..."'4. - "Dispatch observers ... if one extends his hand to treachery and your observers’
reports concur, punish him in his body ... and brand him with betrayal.”!4?. - Score: 9

12) Constitutional conventions (binding political practice) — Present, strong - “Sound sunan” and established ways
of governance are treated as binding constraints; the governor is urged to preserve what prior rulers and society
found upright. - Selected evidence: - "Do not overturn a sound tradition ... do not introduce a practice that harms
past traditions.”!43. - "Increase your study with scholars and converse with sages, to stabilize what your land's
affairs have been set right by, and to maintain what people before you found upright.”!44. - "Remember those
who preceded you—just government, virtuous practice, and what came down from our Prophet or a prescription
in God's Book.”!4°. - Score: 8

13) Due process and fair adjudication — Present, strong - The letter requires impartial judges with defined virtues;
patience with litigants and scrutiny of evidence; avoidance of precipitous punishment; lawful process in matters of
life; and unhindered public access to seek redress. - Selected evidence: - "Then choose for judging .. one whom
adversaries do not fluster .. most patient in uncovering matters ... whom praise does not bedazzle nor inducement
sway.”!46, - "Do not rush to a sudden [punitive] act when you have an alternative.”!4". - "Beware blood ... there
is no excuse ... in willful killing, for it entails retaliation.”!48. - "Sit for them in a public audience ... ‘A nation will
never be sanctified in which the weak cannot take his right from the strong without stammering."!49. - Score: 8

14) Consent and participation in lawmaking — Partially present (indirect) - The text promotes seeking the public’s
satisfaction, empowering “the common people,” hearing petitions in open audience, and adjusting fiscal burdens
upon complaint. But it does not condition enactments or taxes on the formal assent of an assembly or estates;
taxes and shares are treated as fixed by the higher law. - Selected evidence: - "Let the most beloved matters to you
be those most centered in right, most comprehensive in justice, and most unifying of the subjects’ satisfaction—for
the public's anger overwhelms the elite’s pleasure.”!°°. - "The common people are the pillar of religion ... so let
your inclination be toward them.”!°1. - "If they complain of burdens ... lighten for them.”!°7. - Score: 2

15) Stability and continuity across generations — Present, strong - The governor must preserve time-tested
norms, anchor decisions in enduring sources (the Book and the Prophet’s Sunnah), emulate just predecessors,
and cultivate conditions that prolong stable rule. - Selected evidence: - "Do not overturn a sound tradition
"153 _ "Increase your study with scholars ... to stabilize what your land's affairs have been set right by ...”1°4. -

"Remember those who preceded you—just government, virtuous practice ..."!°°. - Score: 8

16) Abstract commitments enabling adaptation — Present, strong - The charter articulates general moral
standards—mercy, justice, equality, fidelity, sanctity of life—whose concrete application can evolve with cir-
cumstances. - Selected evidence: - "Imbue your heart with mercy for the subjects .. for they are either your
brothers in religion or your peers in creation.”!°°. - "Let the most beloved matters to you be those most centered
in right and most comprehensive in justice."°7. - "Do justice to God and to people against yourself.”!°°.
"Beware blood and its shedding without right."1°9. - Score: 9

17) Remedies for constitutional breach — Present, substantial - The document prescribes concrete remedies and
sanctions for breaches by officials and others: investigative oversight and evidentiary use of informants, bodily
punishment, restitution, public shaming for embezzlement; penalties for market manipulation; qisas (retaliation)
and delivering the due right to heirs in cases of unlawful killing; and general redress for the oppressed. However, it
does not articulate a general doctrine of nullity of ultra vires acts, nor a systematic removal-from-office rule, so the
presence is strong but not maximal. - Selected evidence: - "If one of them extends his hand to treachery ... that
suffices as a witness; so you inflict bodily punishment upon him ... then set him up in the place of humiliation, and

| "160

brand him with betraya      - "Whoever commits hoarding after your prohibition, then punish him exemplarily,

and punish without excess.” !®!.

"162

- "Do not let the pride of your authority prevent you from giving the slain’s

guardians their due.      - "For it will be taken from you for others ... and the wronged will be vindicated against

50


===== PAGE BREAK =====

you.”163_ _ "Whoever wrongs God's servants, God will be his adversary ..."!°4. - Score: 7

Element                             Status Score Notes

Legal limits on rulers’ powers     Present 9       Power bound by Book, Sunna, prohibitions on
arbitrariness and bloodshed.

Sovereignty vs. government of- Present 9      God/higher law above office; governor as dele-

fices                                                     gate.

Entrenchment of constraints        Present 7          Sacred covenants and preserved sunan; no proce-
dural entrenchment.

Writtenness and custom          Present 9        Formal “covenant” (ahd); Book and Sunna; es-
tablished practices.

Allocation and checks of power     Present 8         Functional differentiation; inspectors; open peti-
tions; judicial independence.

Supremacy of higher law             Present 9          Disputes referred to Book/Sunna; ruler not above
law.

Rights against the state             Present 8         Bans on oppression, unlawful killing; equality; ac-
cess to justice; anti-monopoly.

Procedural constraints                Present 9          Consultation rules, appointment /oversight proce-
dures, public hearings, treaty formalities.

Jurisdictional limits                   Present 8          Defined remit; hidden matters off-limits; common
rights protected; covenants binding.

Amendment meta-rules             Absent 0         No procedure for changing foundational norms.

Interpretation and enforcement    Present 9         Judges empowered and supported; oversight;
grievance sessions; higher-law hierarchy.

Constitutional conventions        Present 8       Binding force of sound sunan and predecessors’
practices.

Due process and fair adjudica- Present 8       Impartial judges; evidence and patience; no pre-

tion                                                     cipitous punishment; qisas.

Consent and participation in Partial 2       Public satisfaction and petitions encouraged; no

lawmaking                                                 formal consent requirement.

Stability and continuity            Present 8        Preserve tried-and-true norms; emulate just pre-
decessors; rely on enduring sources.

Abstract principles enabling Present 9         General standards (mercy, justice, equality, fi-

adaptation                                              delity, life) guide evolving application.

Remedies for breach                 Present 7         Sanctions for embezzlement /hoarding; qisas; vin-

dication for oppressed; no general nullity rule.

Table 5: Summary of constitutional elements in Multi-Stage (scores 0-10).

51


===== PAGE BREAK =====

GG

= Ine = a Fen irae  ste
“Cosy | Aran Nee

re recy

FD pO of rh Cifa¢ 22s

ogy 7   °                 72ers

K ee Ze foe

ne sit teg ame arise

pore     ane ge

eK rae O oh ap ° FKuiz

2 7 ¢0   4go7¢

Cf rire Ip Oe IP Boc

oer re Oe   rgrwe

Kanan ary  beael Rae

Pa  we ers core 8    ore g

aK tC Iie py,

ror genes  eo rere

o

INP | O om

t- 9 re rere

Reet ip ere By

ven

[Sf mer eam Fem & Pere,

ow ge re

ie Tre ge et Py

Zor rer mn

oO ig as ed 0 Pg
\ 0 ry? ca a ISI?
ag (no fr o rie Tear

orm vo aad

ine ar PP Fin ea On,

REE EC iC a,

Aon gem    7306

Its ip ine: nt oe 3

a a

ey re afar 92 crap ARR Rar? rear,

ge oO Range FSP I am HCD ope om Ber ED,

Tage Sarge rash A mR Cae O ef (per RO & 6 (ETO,

GaP 0 aS ae em rt Pe arya <P Ae ae ee,

2 (2 RS AO eet ae   J sf mer eye eR yO trey

ghd ome: in Bar Bry An ae a7 Oia,

RE TP iar te Rep as IP ie: ier PS ah G66 1P IP: Rar
RO IP AA? 3,

roge

S9JON


===== PAGE BREAK =====

eG

mm, $9 (RG og

yor ror me

do noe © os fete iP by ia

70 we roge   co rep go   vane?

a

Je jan: Ge> ieto i ord FF 9% 6

fe pe terry vee   ne 7° Zo      -o77 7a 8

erste ie? SP 9

oro fe or    \ee zo 8

Soy \0 jac ~ “fe nee 9 ieee qantas irene ar Ko is em apse “ mt,

zero tm om mr re     cee %  to 6 om rere  <7 ¥ 80         Boy   zoe    poe

RO RI RE Toe

aay I iar ed gh CIP IE IK IEP on

Boy «oe    conn        Boy en

Fe aie ah Jo EDD MIO AED et OD aAr# TP pc

v   rog  v5 6 e¢e

do OO Fx 6 JEP Myer O oa 9 APE oe

rag ae  ove     vor em ee    0 70 8 Ore  ory

Kf wep =R FO PTO cg

rere er er gm g 7 4 Borer

°

oe

KR Oe Ie BE we EO nO AD Og

4 7 Age  one 7 ler 7 4 6g €          BD <ere9 0

C9 Pn cieve Pgh fmm Beene Ary ow arg won
dar FCO IRA ate Fem? Ae,  oer ‘Kize

4 ime VM frp ar IK? os fo atal  S fete 1D WF iP re

3                      THe 70 x voge   o ep ¢     , a

\_53t

“y

2   2

I [me A [YO PHF og

yp FO CHP IA aire €a7? Ain, <0 RG 5y

verge        ver rere    yor ror me

3 =Sey

Rae: 6 SA AN

\Ze AD \nees 9 4 128 *® 3  eal er Cues

ee ee                   oe   re7

Roo on oy

od eer oe9

KR SIEO me toy

nee   fee 5
woe

FR ero an

LV

a)

ey are fae 12 cap ane Pep

Ayo rere ere yer mee  Bee

Ramo ap Pens ar SS

CR Rar © arti ey
(00 aps fiat k Eon

rior

7070

AS AGP a Ke ?..

Keo rege                  Bore

oer (iP 5 et

wpe Zo    7 ¢° Bee

GaP Hom OS thay

7 070 “go

ba rn As

me   ger

ap nt te 2 Fa yg

oy or  ergo   yer @


===== PAGE BREAK =====

VG

CBs? =  Cae ah 8 ets G24 O ler P ag

ree tem            rece         cB ome    ore

A> ar 10 Sa 2 gen:  Dasher JEN |F eA Tgg

Zoe   ae ee Cee  roowmne se   6504 4 Been

CR ame on a (eee ° INGE FRED IP iF ee

vy age  one 7     zee.    Beg eer 0 vee

CR aeeO oe ees Capen 21% If ty,

vy age  S07 2     44770 4ar

fo ap ins SO pact

OL AO FIMO 6
‘RE yrs ip nee Lo ANAS 06

44

Gat 1 aon sy age Pane ag ee

zoere               eome   vn fem re gfomgge rer gro

eh shy ae nee Kate P somo i

a ee ee        Bowes vw fo 9

A= Fr 10 ES OO sree: aon IPH [Fo Neg

Zoe   ae ee Cee  roowmne se  eee ee Zo re

CR are om ater sf 4 ork ope Sc (jsp AE toe

vv age  ne 20 er ee eg      zoerrre   Ferg

ard ine ee IP See eID sil oe Cae Weg

B-§ eve er reg     wee ee tee oe  re recy

70 wvroge   °  a 2   vane?

De =r any eg

fete ee ge oe

21 BS ig In? FP eg

ere Fe vee    Borer -

\ Dan

>

(ae on sie Roo Eg

ry 7 ge  coe 7          mt eters”

gee OR do OD he AG

°K rel “T71 SAC if reg rv e or

yore             2      rege

Rate epee PA af Ge,

“Ze          Zoo  eer

Ag § Aneta 5 hel er re,

ore 6      3° -s

08

+ \t

i

40 neo? § Q os cho ip \wr | ‘|  “Poy

70 wvroge   co ep ge 7

a ep re | Fae sate hee merp erq> a pate,

eee eee ergo      error       2 wre 7 reo ogg oe

Piet Oe ange grate ray eR SY aie At,

fe oge       4 7070 ogg       oom 8 gee gg Bers

\29uy
ce)

a

44

Set CF ge ap mye ary ag oY rg (FIP 6,

zoere                   gome  eo 6 rege gore eZ0re7e

CR mae Kar © actor         0 dy cp HY hyp Far oF,

4007 24  aeemaed rrogg r0 7

os - me mares om aD Ape,
Tag sirne mesh th,

GO sre (oe Lap AD Oh ar O gh $e Pr,4

ro eer BBs  vere    e478 7 mM ver gre

aa    me O itr men FSP A omy OF Po

ne      zero rg0 erg 0 «A

RCE API? 1719

“4-2       m

are ire ” (vr 0 i Fog

738  orm 20 reg      ve


===== PAGE BREAK =====

GG

do afin Fate ara ot FS 9 PR Fe

CK ser oer) AC I> RED FP RP Ar ips fie

Cae Se Fr Ae THe SP EDO FIMO 1

GaP 1 AAD ae ey Sr? Par ay <P Age gh a me og

ER aI erO Boe

ER arate O rhe A RAY KR gc

9 AO Cor OI Oe,

ex 0 Ragen FP \ ™~ a} CO ors mah Per pe oo

GSP PE AAS op em Oa pe ar A aay oF 1G a ey 0c

Tae Fittens Cray a mp ER ar 9 arr Ir Rar) O ef (prs RO & Fe Oye

ER SEE apd ty 9 oe | a

CR mre ee eee BO RL TE hy EO oP EO eet

dae FA 649 IR Ae Far Gin OO RE re

ASIP jor ker gee FP har: IK ES gh? GEE TP IP: Rar Moe
ge? 6 Ao a my  Car et am ay  Digi ag! i a

Paar ayes (> io Oo? ere Fa Hy,

OT 10 Vf Ae Pa th BF ms GS gee Aeneer Oh eme verpr A np RIO Ly

CR are ome eae OR eh oe A OA BD [Oe

a8 VIO gi O fey Form,

qi or ier AP joe ees ANF OAD Ret O Pre Pre,

C0 area Bye O82 on ap aren ep ig Afar GaP wre en 9 Dy,

ee a I" whey Caw of) are 6 rey © gi oon Be ary ara =n,

°K ae meat of Hy ar€ ere ine orl ome a Ss On sip me, 1

Tage Sere jor © sarees Fee OP HF 0

RIE AP par ote 9 epee oO opm gs IP oe: Ir Ss FACT IEP: IR me A gor

dye FP 64D RS oF Kar? Gin KOO REV o,

Tag Grae Fa igor

KEEP EAI? QT eo1

dap FP 64D | of Kar Gir ORE,

[78 FAD ore FA aewe Heid AYO giv: oO ker Cor,

al

al

OT
ER Cape O ef peers RO & FE [101

ores                  eee ore

ale <¥e ee Ae Tae es? ae 8 FiO.

ro ree Ferg oe ooo oe me

0 jar oY iver ire ip An" [Seo Feae tier derep> oe ip a intone Petey Syd me Cas F i Xoor

eo Beg oye ee reg                         or we ogg oe       fore ere a  oree ve vere

\ 3

“et sie Cx (A.,

aes  pore om mn


===== PAGE BREAK =====

9G

CO af AC Ie 80 I SOY ED AEH 9,

ge ats ae Cee yp TP eo1

a I? ip Ae mR HO 10 SP IP A AP PY 29,

PO See Pp Tae OL 7 EDO HIM O64

imp FOP saa | satp tere merp sme apy pete © feos Fetter See arte Foe Ao g1
Tag Airey Fray cer

PO or A [OO mp oc

CRSP IRM tO 1? Vo OTP rc

Get ae ieee dd ome: fq j2 ae Or 9 Oe O AO ge

MAS FP 10 aS 1D WP arya: O mse acter |Cmme gee ce]

Ek orn, pry OID 9 pe oF 1 AE er

OR srEO me pe

Ca 386 [NO mee Rees aS? kG he CD oP,

SO <A IRR rm Ot? ah O rps Ge Fe ie? dO eT eae RAO IAA pe1
,          Car? gt ary gy Par oe Bap RD Oh ay gO oH Pg,

6 Fag Gitar Rare ae 8 ef por KO & £9 (TO gp1

ER tO IP Ae rm oh olny

PERS ie pee? ap ened AP age ROH ADR Comte fae (REI Pont
=O AP [OSE DPE area: oO mpiey get ome gee IE AO Fy EO IM [thep
Sk ori ype Coen, AGH OD 9 oe ote 1? ACE? Aare qm & A AP pa

,               CR ore oe ape OR ee oe OO I Oey,
ob ioe Fre IP sya gee oy ipentte Ofer: Casey AF
Kee IP itr Cobre

Pst mer eer he pO erp AEP oe Some OR on

AG AO Freee OR Reap 2D A Corp br Ae IP ATO I Poe

CR an? Rar oO arign Cap er OF 6 af on ate hom P Fe,

i                            fs er ir oy a P are FH oe

dO iO hp IP OP ep ge gsr? aad aap th dn ate a a 9? Ain BP VAS Pee
IDE R0 els Hg Shy Fae ore Frege? othr Fae Ao Mpe

BD [Or do jr

)


===== PAGE BREAK =====

References

Aguda, Toyin, Erik Wilson, Allan Anzagira, Simerjot Kaur, and Charese Smiley. 2025. Con-
servative bias in large language models: measuring relation predictions. In Findings of
the association for computational linguistics: acl 2025, 18989-18998. Vienna, Austria,
July.

Anthropic. 2025. Tracing the thoughts of a large language model, March 27, 2025. Accessed
September 6, 2025. https: //www-.anthropic.com/research/tracing-thoughts-language-
model.

Archer, Pete, and Oli Elliott. 2025. Representation of bbc news content in ai assistants. Tech-
nical report. Research by the BBC Responsible AI Team. London, UK: BBC, February.

Bai, X., A. Wang, I. Sucholutsky, and T. L. Griffiths. 2025. Explicitly unbiased large language
models still form biased associations. Proceedings of the National Academy of Sciences
of the United States of America 122 (8): 1-9.

Barrie, Christopher, Elli Palaiologou, and Petter Tornberg. 2025. Prompt stability scoring
for text annotation with large language models. arXiv: 2407.02039 [cs.CL].

Barros, Caua Ferreira, Bruna Borges Azevedo, Valdemar Vicente Graciano Neto, Mohamad
Kassab, Marcos Kalinowski, Hugo Alexandre D. Do Nascimento, and Michelle C.G.S.P.
Bandeira. 2025. Large language model for qualitative research: a systematic mapping
study. In 2025 ieee/acm international workshop on methodological issues with empirical
studies in software engineering (wsese), 48-55. IEEE.

Berelson, Bernard. 1952. Content analysis in communication research. The Free Press.

Betley, Jan, Xuchan Bao, Martin Soto, Anna Sztyber-Betley, James Chua, and Owain Evans.
2025. Tell me about yourself: LLMs are aware of their learned behaviors. In The thir-
teenth international conference on learning representations.

Bojic, Ljubisa, Olga Zagovora, Asta Zelenkauskaite, Vuk Vukovic, Milan Cabarkapa, Selma
Veseljevic Jerkovic, Ana Jovancevic, et al. 2025. Comparing large language models and
human annotators in latent content analysis of sentiment, political leaning, emotional
intensity and sarcasm. Scientific Reports 15:Article 11477.

Borgeaud, Sebastian, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie
Millican, George Bm Van Den Driessche, et al. 2022. Improving language models by
retrieving from trillions of tokens. In Proceedings of the 39th international conference on
machine learning, 162:2206—-2240. Proceedings of Machine Learning Research. PMLR.

Brown, Tom B, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, et al. 2020. Language models are few-shot learners.
Advances in Neural Information Processing Systems (NeurIPS).

57


===== PAGE BREAK =====

Chen, Yanda, Joe Benton, Ansh Radhakrishnan, Jonathan Uesato, Carson Denison, John

Schulman, Arushi Somani, et al. 2025. Reasoning models don’t always say what they
think. arXiv: 2505.05410 [ces.CL].

Chew, Robert, John Bollenbacher, Michael Wenger, Jessica Speer, and Annice Kim. 2023.
Llm-assisted content analysis: using large language models to support deductive coding.
arXiv: 2306.14924 [cs.CL].

Chowdhery, Aakanksha, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra,
Adam Roberts, Paul Barham, et al. 2023. Palm: scaling language modeling with path-
ways. Journal of Machine Learning Research 24 (240): 1-113.

Chu, KuanChao, Yi-Pei Chen, and Hideki Nakayama. 2024. A better Ilm evaluator for text
generation: the impact of prompt output sequencing and optimization. Graduate School
of Information Science and Technology, The University of Tokyo.

Chung, Hyung Won, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunx-
uan Li, et al. 2022. Scaling instruction-finetuned language models. arXiv: 2210.11416
[cs.LG].

Corbin, Juliet, and Anselm Strauss. 2014. Basics of qualitative research: techniques and
procedures for developing grounded theory. Sage publications.

Creswell, John W., and J. David Creswell. 2022. Research design: qualitative, quantitative,
and mixed methods approaches. SAGE Publications.

Cui, Ruixiang, Seolhwa Lee, Daniel Hershcovich, and Anders Sdgaard. 2023. What does the
failure to reason with “respectively” in zero/few-shot settings tell us about language
models? In Proceedings of the 61st annual meeting of the association for computational
linguistics (acl 2023), 8786-8800. Fine-tuned NLI models struggle with understanding
such respective readings. We demonstrate that LMs still lag behind humans in general-
izing to the long tail of linguistic constructions.

Dai, Shih-Chieh, Aiping Xiong, and Lun-Wei Ku. 2023. LLM-in-the-loop: leveraging large
language model for thematic analysis. In Findings of the association for computational
linguistics: emnlp 2023, edited by Houda Bouamor, Juan Pino, and Kalika Bali, 9993-
10001. Singapore: Association for Computational Linguistics, December.

Dentella, Vittoria, Fritz Giinther, Elliot Murphy, Gary Marcus, and Evelina Leivada. 2024.
Testing AI on language comprehension tasks reveals insensitivity to underlying meaning.
We discovered that LLMs perform at chance accuracy and waver considerably in their
answers. Quantitatively, the tested models are outperformed by humans, and qualita-
tively their answers showcase distinctly non-human errors in language understanding.
Scientific Reports 14 (28083).

Denzin, Norman K., and Yvonna 8. Lincoln. 2017. The sage handbook of qualitative research
[in English (US)]. 5th ed. United States: SAGE Publishing, February.

58


===== PAGE BREAK =====

Dey, Ian. 1993. Qualitative data analysis: a user friendly guide for social scientists. Routledge.

Dunivin, Zackary Okun. 2024. Scalable qualitative coding with llms: chain-of-thought reason-
ing matches human performance in some hermeneutic tasks. arXiv: 2401.15170 [cs.CL].

Errica, Federico, Davide Sanvito, Giuseppe Siracusano, and Roberto Bifulco. 2025. What
did i do wrong? quantifying Ilms’ sensitivity and consistency to prompt engineering.
In Proceedings of the 2025 conference of the nations of the americas chapter of the
association for computational linguistics: human language technologies (volume 1: long
papers), 1543-1558. Association for Computational Linguistics.

Eschrich, James, and Sarah Sterman. 2024. A framework for discussing llms as tools for
qualitative analysis. arXiv: 2407.11198 [cs.HC].

Friedman, Carli, Aleksa Owen, and Laura VanPuymbrouck. 2024. Should chatgpt help with
my research? a caution against artificial intelligence in qualitative analysis. Qualitative
Research 0 (0): 14687941241297375.

Gevers, Ine, Victor De Marez, Luna De Bruyne, and Walter Daelemans. 2025. Winowhat: a
parallel corpus of paraphrased winogrande sentences with common sense categorization.
In Proceedings of the 29th conference on computational natural language learning (conll
2025).

Guo, Yufei, Muzhe Guo, Juntao Su, Zhou Yang, Mengqiu Zhu, Hongfei Li, Mengyang Qiu,
and Shuo Shuo Liu. 2024. Bias in large language models: origin, evaluation, and miti-
gation. arXiv: 2411.10915 [cs.CL].

Hardt, Daniel. 2023a. Ellipsis-dependent reasoning: a new challenge for large language models
[in English]. In Proceedings of the 61st annual meeting of the association for computa-
tional linguistics, edited by Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki,
2:39-47. The 61st Annual Meeting of the Association for Computational Linguistics ;
Conference date: 09-07-2023 Through 14-07-2023. United States: Association for Com-
putational Linguistics.

. 2023b. Ellipsis-dependent reasoning: a new challenge for large language models. In
Proceedings of the 61st annual meeting of the association for computational linguistics
(acl 2023), vol. 2: Short Papers, 39-47. Test results show that the best models perform
well on non-elliptical examples but struggle with all but the simplest ellipsis structures.

. 2025. Sparks of pure competence in Ilms: the case of syntactic center embedding in
english. Society for Computation in Linguistics 8 (1).

He, Jia, Mukund Rungta, David Koleczek, Arshdeep Sekhon, Franklin X Wang, and Sadid
Hasan. 2024. Does prompt formatting have any impact on llm performance? arXiv:
2411.10541 [cs.CL].

Herndndez-Orallo, José, Fernando Martinez-Plumed, Shahar Avin, and Sedn O hEigeartaigh.
2024. Larger and more instructable language models become less reliable. Nature.

59


===== PAGE BREAK =====

Heseltine, Michael, and Bernhard Clemm von Hohenberg. 2024. Large language models as
a substitute for human experts in annotating political text. Research & Politics 11 (1):
20531680241 236239.

Huang, Yizheng, and Jimmy Huang. 2024. A survey on retrieval-augmented text generation
for large language models. V2, Aug 2024, arXiv, eprint: 2404.10981.

Izacard, Gautier, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick,
Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave. 2023. Atlas:
few-shot learning with retrieval augmented language models. Journal of Machine Learn-
ing Research 24 (251): 1-48.

Karimzadeh, Salim, and Ali Sanaei. 2025. Reconstructing pahlavi governance: leveraging
oral histories with retrieval-augmented generation. SSRN working paper, April 4, 2025.
SSRN: 5204971.

Karpinska, Marzena, Katherine Thai, Kyle Lo, Tanya Goyal, and Mohit Iyyer. 2024. One
thousand and one pairs: a “novel” challenge for long-context language models. In Pro-
ceedings of the 2024 conference on empirical methods in natural language processing,
17048-17085.

Kosinski, Michal. 2024. Evaluating large language models in theory of mind tasks. Proceedings
of the National Academy of Sciences 121 (45): e2405460121.

Kracauer, Siegfried. 1952. The challenge of qualitative content analysis. Public Opinion Quar-
terly.

Lewis, Patrick, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman
Goyal, Heinrich Kiittler, et al. 2020. Retrieval-augmented generation for knowledge-
intensive nlp tasks. In Advances in neural information processing systems 38, 9459-
9474.

Lou, Renze, Kai Zhang, and Wenpeng Yin. 2024. Large language model instruction following:
a survey of progresses and challenges. Computational Linguistics (Cambridge, MA) 50,
no. 3 (September): 1053-1095.

Manikantan, Kawshik, Makarand Tapaswi, Vineet Gandhi, and Shubham Toshniwal. 2025.
IdentifyMe: a challenging long-context mention resolution benchmark for LLMs. In Pro-
ceedings of the 2025 conference of the nations of the americas chapter of the association
for computational linguistics: human language technologies (volume 2: short papers),
edited by Luis Chiruzzo, Alan Ritter, and Lu Wang, 768-777. Albuquerque, New Mex-
ico: Association for Computational Linguistics, April.

McCoy, R Thomas, Shunyu Yao, Dan Friedman, Mathew D Hardy, and Thomas L Griffiths.
2024. When a language model is optimized for reasoning, does it still show embers of
autoregression? an analysis of openai ol. arXiv: 2410.01792 [cs.CL].

60


===== PAGE BREAK =====

McCoy, R. Thomas, Shunyu Yao, Dan Friedman, Matthew Hardy, and Thomas L. Grif-
fiths. 2023. Embers of autoregression: understanding large language models through the
problem they are trained to solve. arXiv.

Ouyang, Long, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin,
Chong Zhang, et al. 2022. Training language models to follow instructions with human
feedback. In Proceedings of the 36th international conference on neural information
processing systems. NIPS ’22. New Orleans, LA, USA: Curran Associates Inc.

Rasheed, Zeeshan, Waseem Muhammad, Aakash Ahmad, Kai-Kristian Kemell, Xiaofeng
Wang, Anh NguyenDuc, and Pekka Abrahamsson. 2025. Can large language models

serve as data analysts? a multi-agent assisted approach for qualitative data analysis.
SSRN Working Paper.

Roberts, John, Max Baker, and Jane Andrew. 2024. Artificial intelligence and qualitative
research: the promise and perils of large language model (llm) assistance. Critical Per-
spectives on Accounting 99:102722.

Salinas, Abel, and Fred Morstatter. 2024. The butterfly effect of altering prompts: how small
changes and jailbreaks affect large language model performance. arXiv: 2401 .03729
[cs.CL].

Schroeder, Hope, Marianne Aubin Le Quéré, Casey Randazzo, David Mimno, and Sarita
Schoenebeck. 2025. Large language models in qualitative research: uses, tensions, and
intentions. In Proceedings of the 2025 chi conference on human factors in computing
systems. ACM.

Sclar, Melanie, Yejin Choi, Yulia Tsvetkov, and Alane Suhr. 2024. Quantifying language
models’ sensitivity to spurious features in prompt design or: how i learned to start
worrying about prompt formatting. In The twelfth international conference on learning
representations.

al-Sharif al-Radhi. 1987. Nahj al-balaghah (peak of eloquence): sermons, letters and sayings.
Translated by Sayyid Ali Reza. See also online text for Letter 53 at Al-Islam.org. Qom:
Ansariyan Publications.

Sinha, Ravi, Idris Solola, Ha Nguyen, Hillary Swanson, and LuEttaMae Lawrence. 2024. The
role of generative ai in qualitative research: gpt-4’s contributions to a grounded theory

analysis. In Proceedings of the symposium on learning design and technology, 17-25.
Delft, Netherlands: ACM, June.

Stewart, Ian, Sameera Horawalavithana, Brendan Kennedy, Sai Munikoti, and Karl
Pazdernik. 2024. Surprisingly fragile: assessing and addressing prompt instability in
multimodal foundation models. arXiv: 2408.14595 [cs.CL].

61


===== PAGE BREAK =====

Su, Yu, Diyi Yang, Shunyu Yao, and Tao Yu. 2024. Language agents: foundations, prospects,
and risks. In Proceedings of the 2024 conference on empirical methods in natural language
processing: tutorial abstracts, edited by Jessy Li and Fei Liu, 17-24. Miami, Florida,
USA: Association for Computational Linguistics, November.

Subbiah, Melanie, Sean Zhang, Lydia B Chilton, and Kathleen McKeown. 2024. Reading
subtext: evaluating large language models on short story summarization with writers.
Transactions of the Association for Computational Linguistics 12:1290-1310.

Tang, Ruixiang, Dehan Kong, Longtao Huang, and Hui Xue. 2023. Large language models
can be lazy learners: analyze shortcuts in in-context learning. In Findings of the asso-
ciation for computational linguistics: acl 2023, edited by Anna Rogers, Jordan Boyd-
Graber, and Naoaki Okazaki, 4645-4657. Toronto, Canada: Association for Computa-
tional Linguistics, July.

Tesch, Renata. 1990. Qualitative research: analysis types and software tools. London: Falmer
Press.

Tie, Ylona Chun, Melanie Birks, and Karen Francis. 2019. Grounded theory research:
a design framework for novice researchers. PMID: 30637106, SAGE Open Medicine
7:2050312118822927.

Vaugrante, LaurALne, Mathias Niepert, and Thilo Hagendorff. 2024. A looming replication
crisis in evaluating behavior in language models? evidence and solutions. arXiv preprint
arXtv:2409. 20808.

Waluchow, Wil, and Dimitrios Kyritsis. 2023. Constitutionalism. In The Stanford encyclo-
pedia of philosophy, Summer 2023, edited by Edward N. Zalta and Uri Nodelman.
Metaphysics Research Lab, Stanford University.

Wei, Jason, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani
Yogatama, et al. 2022. Emergent abilities of large language models. arXiv: 2206.07682
[cs.CL].

Wei, Jason, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H.
Chi, Quoc V. Le, and Denny Zhou. 2022. Chain-of-thought prompting elicits reasoning
in large language models. In Proceedings of the 36th international conference on neural
information processing systems. NIPS ’22. New Orleans, LA, USA: Curran Associates
Inc.

Zhao, Sihang, Youliang Yuan, Xiaoying Tang, and Pinjia He. 2024. Difficult task yes but
simple task no: unveiling the laziness in multimodal Ilms. In Findings of the association
for computational linguistics: emnlp 2024, 7535-7548. Miami, Florida, USA: Association
for Computational Linguistics.

62
